{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conseecomer = pd.read_csv('consenergcom.csv', sep=';', encoding='latin-1', index_col='Data')\n",
    "conseeind = pd.read_csv('consumo energia eletrica industria.csv', sep=';', encoding='latin-1', index_col='Data')\n",
    "dolar = pd.read_csv('dolar.csv', sep=';', encoding='latin-1', index_col='Data')\n",
    "ibov = pd.read_csv('ibov.csv', sep=';', encoding='latin-1', index_col='Data')\n",
    "ipca = pd.read_csv('ipca.csv', sep=';', encoding='latin-1', index_col='Data')\n",
    "m1 = pd.read_csv('m1.csv', sep=';', encoding='latin-1', index_col='Data')\n",
    "pib = pd.read_csv('pib.csv', sep=';', encoding='latin-1', index_col='Data')\n",
    "cimento = pd.read_csv('cimento.csv', sep=';', encoding='latin-1', index_col='Data')\n",
    "saldoempregos = pd.read_csv('saldo empregos.csv', sep=';', encoding='latin-1', index_col='Data')\n",
    "vendcl = pd.read_csv('vendcl.csv', sep=';', encoding='latin-1', index_col='Data')\n",
    "vendasvarejoconscivil = pd.read_csv('vendasvarejoconscivil.csv', sep=';', encoding='latin-1', index_col='Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumo Energia Eletrica Comércio GWh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/1976</th>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29/02/1976</th>\n",
       "      <td>834.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/1976</th>\n",
       "      <td>829.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/1976</th>\n",
       "      <td>819.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/1976</th>\n",
       "      <td>813.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Consumo Energia Eletrica Comércio GWh\n",
       "Data                                             \n",
       "31/01/1976                                  858.0\n",
       "29/02/1976                                  834.5\n",
       "31/03/1976                                  829.0\n",
       "30/04/1976                                  819.6\n",
       "31/05/1976                                  813.4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conseecomer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumo Energia Eletrica Industria GWh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/1976</th>\n",
       "      <td>2816.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29/02/1976</th>\n",
       "      <td>2818.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/1976</th>\n",
       "      <td>2951.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/1976</th>\n",
       "      <td>2969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/1976</th>\n",
       "      <td>3075.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Consumo Energia Eletrica Industria GWh\n",
       "Data                                              \n",
       "31/01/1976                                  2816.8\n",
       "29/02/1976                                  2818.2\n",
       "31/03/1976                                  2951.5\n",
       "30/04/1976                                  2969.0\n",
       "31/05/1976                                  3075.6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conseeind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Taxa de Câmbio Comercial t+1</th>\n",
       "      <th>Taxa de Câmbio Comercial t+1 Corrigida</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>02/01/2001</th>\n",
       "      <td>1.959736</td>\n",
       "      <td>1.959736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/01/2001</th>\n",
       "      <td>1.965246</td>\n",
       "      <td>1.965246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/01/2001</th>\n",
       "      <td>1.957205</td>\n",
       "      <td>1.957205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05/01/2001</th>\n",
       "      <td>1.972200</td>\n",
       "      <td>1.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/01/2001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.972200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Taxa de Câmbio Comercial t+1  \\\n",
       "Data                                       \n",
       "02/01/2001                      1.959736   \n",
       "03/01/2001                      1.965246   \n",
       "04/01/2001                      1.957205   \n",
       "05/01/2001                      1.972200   \n",
       "06/01/2001                           NaN   \n",
       "\n",
       "            Taxa de Câmbio Comercial t+1 Corrigida  \n",
       "Data                                                \n",
       "02/01/2001                                1.959736  \n",
       "03/01/2001                                1.965246  \n",
       "04/01/2001                                1.957205  \n",
       "05/01/2001                                1.972200  \n",
       "06/01/2001                                1.972200  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dolar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ibovespa</th>\n",
       "      <th>Ibovespa Corrigido</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>04/07/1994</th>\n",
       "      <td>3580.8</td>\n",
       "      <td>3580.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05/07/1994</th>\n",
       "      <td>3564.3</td>\n",
       "      <td>3564.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/07/1994</th>\n",
       "      <td>3753.5</td>\n",
       "      <td>3753.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07/07/1994</th>\n",
       "      <td>3904.9</td>\n",
       "      <td>3904.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08/07/1994</th>\n",
       "      <td>4051.9</td>\n",
       "      <td>4051.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ibovespa  Ibovespa Corrigido\n",
       "Data                                    \n",
       "04/07/1994    3580.8              3580.8\n",
       "05/07/1994    3564.3              3564.3\n",
       "06/07/1994    3753.5              3753.5\n",
       "07/07/1994    3904.9              3904.9\n",
       "08/07/1994    4051.9              4051.9"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30/04/1995</th>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/1995</th>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/06/1995</th>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/07/1995</th>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/08/1995</th>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            IPCA\n",
       "Data            \n",
       "30/04/1995  2.43\n",
       "31/05/1995  2.67\n",
       "30/06/1995  2.26\n",
       "31/07/1995  2.36\n",
       "31/08/1995  0.99"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M1 - depósitos à vista - fim período - R$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/12/2001</th>\n",
       "      <td>52735.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/01/2002</th>\n",
       "      <td>49052.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2002</th>\n",
       "      <td>48947.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2002</th>\n",
       "      <td>47804.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2002</th>\n",
       "      <td>50621.914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            M1 - depósitos à vista - fim período - R$\n",
       "Data                                                 \n",
       "31/12/2001                                  52735.716\n",
       "31/01/2002                                  49052.110\n",
       "28/02/2002                                  48947.550\n",
       "31/03/2002                                  47804.589\n",
       "30/04/2002                                  50621.914"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIB - R$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/12/1990</th>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/01/1991</th>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/1991</th>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/1991</th>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/1991</th>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PIB - R$\n",
       "Data                \n",
       "31/12/1990       1.8\n",
       "31/01/1991       2.1\n",
       "28/02/1991       2.4\n",
       "31/03/1991       2.5\n",
       "30/04/1991       3.1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pib.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Produção - cimento - qde. - Tonelada</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/1970</th>\n",
       "      <td>707737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/1970</th>\n",
       "      <td>629760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/1970</th>\n",
       "      <td>702676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/1970</th>\n",
       "      <td>699254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/1970</th>\n",
       "      <td>767208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Produção - cimento - qde. - Tonelada\n",
       "Data                                            \n",
       "31/01/1970                                707737\n",
       "28/02/1970                                629760\n",
       "31/03/1970                                702676\n",
       "30/04/1970                                699254\n",
       "31/05/1970                                767208"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cimento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Empregados - saldo - Pessoa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/05/1999</th>\n",
       "      <td>97182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/06/1999</th>\n",
       "      <td>58109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/07/1999</th>\n",
       "      <td>8057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/08/1999</th>\n",
       "      <td>13306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/09/1999</th>\n",
       "      <td>7207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Empregados - saldo - Pessoa\n",
       "Data                                   \n",
       "31/05/1999                        97182\n",
       "30/06/1999                        58109\n",
       "31/07/1999                         8057\n",
       "31/08/1999                        13306\n",
       "30/09/1999                         7207"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saldoempregos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vendas nominais - varejo - combustíveis e lubrificantes - índice (média 2014 = 100)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2000</th>\n",
       "      <td>32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29/02/2000</th>\n",
       "      <td>31.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2000</th>\n",
       "      <td>33.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2000</th>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2000</th>\n",
       "      <td>33.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Vendas nominais - varejo - combustíveis e lubrificantes - índice (média 2014 = 100) \n",
       "Data                                                                                            \n",
       "31/01/2000                                               32.5                                   \n",
       "29/02/2000                                               31.2                                   \n",
       "31/03/2000                                               33.7                                   \n",
       "30/04/2000                                               33.3                                   \n",
       "31/05/2000                                               33.1                                   "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vendcl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>58.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)\n",
       "Data                                                                                   \n",
       "31/01/2003                                               63.4                          \n",
       "28/02/2003                                               60.5                          \n",
       "31/03/2003                                               58.6                          \n",
       "30/04/2003                                               58.3                          \n",
       "31/05/2003                                               61.1                          "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vendasvarejoconscivil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conseecomer_ = conseecomer[conseecomer.index.isin(vendasvarejoconscivil.index)]\n",
    "conseeind_ = conseeind[conseeind.index.isin(vendasvarejoconscivil.index)]\n",
    "dolar_ = dolar[dolar.index.isin(vendasvarejoconscivil.index)]\n",
    "ibov_ = ibov[ibov.index.isin(vendasvarejoconscivil.index)]\n",
    "ipca_ = ipca[ipca.index.isin(vendasvarejoconscivil.index)]\n",
    "pib_ = pib[pib.index.isin(vendasvarejoconscivil.index)]\n",
    "m1_ = m1[m1.index.isin(vendasvarejoconscivil.index)]\n",
    "cimento_ = cimento[cimento.index.isin(vendasvarejoconscivil.index)]\n",
    "saldoempregos_ = saldoempregos[saldoempregos.index.isin(vendasvarejoconscivil.index)]\n",
    "vendcl_ = vendcl[vendcl.index.isin(vendasvarejoconscivil.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conseecomer_ 199\n",
      "conseeind_ 199\n",
      "dolar_ 199\n",
      "ibov_ 199\n",
      "pib_ 199\n",
      "ipca_ 199\n",
      "m1_ 199\n",
      "cimento_ 192\n",
      "saldoempregos_ 199\n",
      "vendcl_ 199\n",
      "vendasvarejoconscivil 199\n"
     ]
    }
   ],
   "source": [
    "print('conseecomer_',conseecomer_.shape[0])\n",
    "print('conseeind_',conseeind_.shape[0])\n",
    "print('dolar_',dolar_.shape[0])\n",
    "print('ibov_',ibov_.shape[0])\n",
    "print('pib_',pib_.shape[0])\n",
    "print('ipca_',ipca_.shape[0])\n",
    "print('m1_',m1_.shape[0])\n",
    "print('cimento_',cimento_.shape[0])\n",
    "print('saldoempregos_',saldoempregos_.shape[0])\n",
    "print('vendcl_',vendcl_.shape[0])\n",
    "print('vendasvarejoconscivil',vendasvarejoconscivil.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "conseecomer_ = conseecomer[conseecomer.index.isin(cimento_.index)]\n",
    "conseeind_ = conseeind[conseeind.index.isin(cimento_.index)]\n",
    "dolar_ = dolar[dolar.index.isin(cimento_.index)]\n",
    "ibov_ = ibov[ibov.index.isin(cimento_.index)]\n",
    "ipca_ = ipca[ipca.index.isin(cimento_.index)]\n",
    "pib_ = pib[pib.index.isin(cimento_.index)]\n",
    "m1_ = m1[m1.index.isin(cimento_.index)]\n",
    "vendasvarejoconscivil_ = vendasvarejoconscivil[vendasvarejoconscivil.index.isin(cimento_.index)]\n",
    "saldoempregos_ = saldoempregos[saldoempregos.index.isin(cimento_.index)]\n",
    "vendcl_ = vendcl[vendcl.index.isin(cimento_.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conseecomer_ 192\n",
      "conseeind_ 192\n",
      "dolar_ 192\n",
      "ibov_ 192\n",
      "pib_ 192\n",
      "ipca_ 192\n",
      "m1_ 192\n",
      "cimento_ 192\n",
      "saldoempregos_ 192\n",
      "vendcl_ 192\n",
      "vendasvarejoconscivil 192\n"
     ]
    }
   ],
   "source": [
    "print('conseecomer_',conseecomer_.shape[0])\n",
    "print('conseeind_',conseeind_.shape[0])\n",
    "print('dolar_',dolar_.shape[0])\n",
    "print('ibov_',ibov_.shape[0])\n",
    "print('pib_',pib_.shape[0])\n",
    "print('ipca_',ipca_.shape[0])\n",
    "print('m1_',m1_.shape[0])\n",
    "print('cimento_',cimento_.shape[0])\n",
    "print('saldoempregos_',saldoempregos_.shape[0])\n",
    "print('vendcl_',vendcl_.shape[0])\n",
    "print('vendasvarejoconscivil',vendasvarejoconscivil_.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "conseecomer_['Retornos Consumo Energia Eletrica Comércio GWh'] = ((conseecomer_['Consumo Energia Eletrica Comércio GWh']/conseecomer_['Consumo Energia Eletrica Comércio GWh'].shift())-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumo Energia Eletrica Comércio GWh</th>\n",
       "      <th>Retornos Consumo Energia Eletrica Comércio GWh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>4182.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>4153.0</td>\n",
       "      <td>-0.006934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>4221.0</td>\n",
       "      <td>0.016374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>3948.0</td>\n",
       "      <td>-0.064677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>3938.0</td>\n",
       "      <td>-0.002533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Consumo Energia Eletrica Comércio GWh  \\\n",
       "Data                                                \n",
       "31/01/2003                                 4182.0   \n",
       "28/02/2003                                 4153.0   \n",
       "31/03/2003                                 4221.0   \n",
       "30/04/2003                                 3948.0   \n",
       "31/05/2003                                 3938.0   \n",
       "\n",
       "            Retornos Consumo Energia Eletrica Comércio GWh  \n",
       "Data                                                        \n",
       "31/01/2003                                             NaN  \n",
       "28/02/2003                                       -0.006934  \n",
       "31/03/2003                                        0.016374  \n",
       "30/04/2003                                       -0.064677  \n",
       "31/05/2003                                       -0.002533  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conseecomer_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumo Energia Eletrica Industria GWh</th>\n",
       "      <th>Retornos Consumo Energia Eletrica Industria GWh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>10345.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>10471.0</td>\n",
       "      <td>0.012180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>10565.0</td>\n",
       "      <td>0.008977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>10850.0</td>\n",
       "      <td>0.026976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>10750.0</td>\n",
       "      <td>-0.009217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Consumo Energia Eletrica Industria GWh  \\\n",
       "Data                                                 \n",
       "31/01/2003                                 10345.0   \n",
       "28/02/2003                                 10471.0   \n",
       "31/03/2003                                 10565.0   \n",
       "30/04/2003                                 10850.0   \n",
       "31/05/2003                                 10750.0   \n",
       "\n",
       "            Retornos Consumo Energia Eletrica Industria GWh  \n",
       "Data                                                         \n",
       "31/01/2003                                              NaN  \n",
       "28/02/2003                                         0.012180  \n",
       "31/03/2003                                         0.008977  \n",
       "30/04/2003                                         0.026976  \n",
       "31/05/2003                                        -0.009217  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conseeind_['Retornos Consumo Energia Eletrica Industria GWh'] = (conseeind_['Consumo Energia Eletrica Industria GWh']/conseeind_['Consumo Energia Eletrica Industria GWh'].shift())-1\n",
    "\n",
    "conseeind_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolar_ = dolar_.drop('Taxa de Câmbio Comercial t+1', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Taxa de Câmbio Comercial t+1 Corrigida</th>\n",
       "      <th>Retornos Taxa de Câmbio Comercial t+1</th>\n",
       "      <th>Indice Câmbial 100 = média de 2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>3.531619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.740047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>3.561660</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>151.013780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>3.360902</td>\n",
       "      <td>-0.056366</td>\n",
       "      <td>142.501675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>2.889000</td>\n",
       "      <td>-0.140409</td>\n",
       "      <td>122.493110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>2.951093</td>\n",
       "      <td>0.021493</td>\n",
       "      <td>125.125843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Taxa de Câmbio Comercial t+1 Corrigida  \\\n",
       "Data                                                 \n",
       "31/01/2003                                3.531619   \n",
       "28/02/2003                                3.561660   \n",
       "31/03/2003                                3.360902   \n",
       "30/04/2003                                2.889000   \n",
       "31/05/2003                                2.951093   \n",
       "\n",
       "            Retornos Taxa de Câmbio Comercial t+1  \\\n",
       "Data                                                \n",
       "31/01/2003                                    NaN   \n",
       "28/02/2003                               0.008506   \n",
       "31/03/2003                              -0.056366   \n",
       "30/04/2003                              -0.140409   \n",
       "31/05/2003                               0.021493   \n",
       "\n",
       "            Indice Câmbial 100 = média de 2014  \n",
       "Data                                            \n",
       "31/01/2003                          149.740047  \n",
       "28/02/2003                          151.013780  \n",
       "31/03/2003                          142.501675  \n",
       "30/04/2003                          122.493110  \n",
       "31/05/2003                          125.125843  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dolar_['Retornos Taxa de Câmbio Comercial t+1'] = (dolar_['Taxa de Câmbio Comercial t+1 Corrigida']/dolar_['Taxa de Câmbio Comercial t+1 Corrigida'].shift()) -1\n",
    "media_dol = dolar_['Taxa de Câmbio Comercial t+1 Corrigida'][132:144].mean()\n",
    "dolar_['Indice Câmbial 100 = média de 2014'] = (dolar_['Taxa de Câmbio Comercial t+1 Corrigida']/media_dol) * 100\n",
    "dolar_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ibovespa Corrigido</th>\n",
       "      <th>Retornos Ibovespa</th>\n",
       "      <th>Indice Ibovespa 100 = média de 2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>10941.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.781614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>10280.0</td>\n",
       "      <td>-0.060415</td>\n",
       "      <td>19.526093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>11273.0</td>\n",
       "      <td>0.096595</td>\n",
       "      <td>21.412223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>12556.0</td>\n",
       "      <td>0.113812</td>\n",
       "      <td>23.849186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>13421.0</td>\n",
       "      <td>0.068891</td>\n",
       "      <td>25.492189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ibovespa Corrigido  Retornos Ibovespa  \\\n",
       "Data                                                \n",
       "31/01/2003             10941.0                NaN   \n",
       "28/02/2003             10280.0          -0.060415   \n",
       "31/03/2003             11273.0           0.096595   \n",
       "30/04/2003             12556.0           0.113812   \n",
       "31/05/2003             13421.0           0.068891   \n",
       "\n",
       "            Indice Ibovespa 100 = média de 2014  \n",
       "Data                                             \n",
       "31/01/2003                            20.781614  \n",
       "28/02/2003                            19.526093  \n",
       "31/03/2003                            21.412223  \n",
       "30/04/2003                            23.849186  \n",
       "31/05/2003                            25.492189  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibov_['Ibovespa Corrigido'] = np.float64(ibov_['Ibovespa Corrigido'])\n",
    "ibov_ = ibov_.drop('Ibovespa', axis = 1)\n",
    "\n",
    "media_ibov = ibov_['Ibovespa Corrigido'][132:144].mean()\n",
    "ibov_['Indice Ibovespa 100 = média de 2014'] = (ibov_['Ibovespa Corrigido']/media_ibov) * 100\n",
    "ibov_.head()\n",
    "\n",
    "ibov_['Retornos Ibovespa'] = (ibov_['Ibovespa Corrigido']/ibov_['Ibovespa Corrigido'].shift()) - 1\n",
    "ibov_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA</th>\n",
       "      <th>Retornos IPCA</th>\n",
       "      <th>Indice IPCA 100 = Média de 2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>2.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433.386838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>1.57</td>\n",
       "      <td>-0.302222</td>\n",
       "      <td>302.407705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>1.23</td>\n",
       "      <td>-0.216561</td>\n",
       "      <td>236.918138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>0.97</td>\n",
       "      <td>-0.211382</td>\n",
       "      <td>186.837881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>0.61</td>\n",
       "      <td>-0.371134</td>\n",
       "      <td>117.495987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            IPCA  Retornos IPCA  Indice IPCA 100 = Média de 2014\n",
       "Data                                                            \n",
       "31/01/2003  2.25            NaN                       433.386838\n",
       "28/02/2003  1.57      -0.302222                       302.407705\n",
       "31/03/2003  1.23      -0.216561                       236.918138\n",
       "30/04/2003  0.97      -0.211382                       186.837881\n",
       "31/05/2003  0.61      -0.371134                       117.495987"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipca_['Retornos IPCA'] = np.where((ipca_['IPCA'] != 0) & \n",
    "                                  (ipca_['IPCA'].shift() != 0)\n",
    "    ,(ipca_['IPCA']/ipca_['IPCA'].shift()) -1,0)\n",
    "ipca_media = ipca_['IPCA'][132:144].mean()\n",
    "ipca_['Indice IPCA 100 = Média de 2014'] = (ipca_['IPCA']/ipca_media) * 100\n",
    "ipca_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M1 - depósitos à vista - fim período - R$</th>\n",
       "      <th>Retornos M1 Final do Período</th>\n",
       "      <th>Índice M1 100 = Média de 2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>58027.664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.704050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>57415.063</td>\n",
       "      <td>-0.010557</td>\n",
       "      <td>33.348234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>56687.240</td>\n",
       "      <td>-0.012677</td>\n",
       "      <td>32.925495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>54955.139</td>\n",
       "      <td>-0.030555</td>\n",
       "      <td>31.919443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>53712.908</td>\n",
       "      <td>-0.022604</td>\n",
       "      <td>31.197922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            M1 - depósitos à vista - fim período - R$  \\\n",
       "Data                                                    \n",
       "31/01/2003                                  58027.664   \n",
       "28/02/2003                                  57415.063   \n",
       "31/03/2003                                  56687.240   \n",
       "30/04/2003                                  54955.139   \n",
       "31/05/2003                                  53712.908   \n",
       "\n",
       "            Retornos M1 Final do Período  Índice M1 100 = Média de 2014  \n",
       "Data                                                                     \n",
       "31/01/2003                           NaN                      33.704050  \n",
       "28/02/2003                     -0.010557                      33.348234  \n",
       "31/03/2003                     -0.012677                      32.925495  \n",
       "30/04/2003                     -0.030555                      31.919443  \n",
       "31/05/2003                     -0.022604                      31.197922  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_['Retornos M1 Final do Período'] = (m1_['M1 - depósitos à vista - fim período - R$']/m1_['M1 - depósitos à vista - fim período - R$'].shift())-1\n",
    "m1_media = m1_.iloc[:,0:1][132:144].mean()\n",
    "m1_['Índice M1 100 = Média de 2014'] = (m1_.iloc[:,0:1]/m1_media) * 100\n",
    "m1_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Produção - cimento - qde. - Tonelada</th>\n",
       "      <th>Retornos Produção de Cimeto qdt em Toneladas</th>\n",
       "      <th>Indice Cimento 100 = Média de 2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>2752763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.359692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>2738342</td>\n",
       "      <td>-0.005239</td>\n",
       "      <td>46.116826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>2899598</td>\n",
       "      <td>0.058888</td>\n",
       "      <td>48.832562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>2676340</td>\n",
       "      <td>-0.076996</td>\n",
       "      <td>45.072641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>3009998</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>50.691825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Produção - cimento - qde. - Tonelada  \\\n",
       "Data                                               \n",
       "31/01/2003                               2752763   \n",
       "28/02/2003                               2738342   \n",
       "31/03/2003                               2899598   \n",
       "30/04/2003                               2676340   \n",
       "31/05/2003                               3009998   \n",
       "\n",
       "            Retornos Produção de Cimeto qdt em Toneladas  \\\n",
       "Data                                                       \n",
       "31/01/2003                                           NaN   \n",
       "28/02/2003                                     -0.005239   \n",
       "31/03/2003                                      0.058888   \n",
       "30/04/2003                                     -0.076996   \n",
       "31/05/2003                                      0.124670   \n",
       "\n",
       "            Indice Cimento 100 = Média de 2014  \n",
       "Data                                            \n",
       "31/01/2003                           46.359692  \n",
       "28/02/2003                           46.116826  \n",
       "31/03/2003                           48.832562  \n",
       "30/04/2003                           45.072641  \n",
       "31/05/2003                           50.691825  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cimento_['Retornos Produção de Cimeto qdt em Toneladas'] = (cimento_.iloc[:,0:1]/cimento_.iloc[:,0:1].shift())-1\n",
    "cimento_media = cimento_.iloc[:,0:1][132:144].mean()\n",
    "cimento_['Indice Cimento 100 = Média de 2014'] = (cimento_.iloc[:,0:1]/cimento_media) * 100\n",
    "cimento_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)</th>\n",
       "      <th>Retornos Vendas Materiais de Construção</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>63.4</td>\n",
       "      <td>-0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>60.5</td>\n",
       "      <td>-0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>58.6</td>\n",
       "      <td>-0.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>58.3</td>\n",
       "      <td>-0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>61.1</td>\n",
       "      <td>-0.389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)  \\\n",
       "Data                                                                                      \n",
       "31/01/2003                                               63.4                             \n",
       "28/02/2003                                               60.5                             \n",
       "31/03/2003                                               58.6                             \n",
       "30/04/2003                                               58.3                             \n",
       "31/05/2003                                               61.1                             \n",
       "\n",
       "            Retornos Vendas Materiais de Construção  \n",
       "Data                                                 \n",
       "31/01/2003                                   -0.366  \n",
       "28/02/2003                                   -0.395  \n",
       "31/03/2003                                   -0.414  \n",
       "30/04/2003                                   -0.417  \n",
       "31/05/2003                                   -0.389  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vendasvarejoconscivil_['Retornos Vendas Materiais de Construção'] = (vendasvarejoconscivil_.iloc[:,0:1] - 100)/100\n",
    "vendasvarejoconscivil_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2014</th>\n",
       "      <td>102.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2014</th>\n",
       "      <td>99.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2014</th>\n",
       "      <td>95.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2014</th>\n",
       "      <td>94.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2014</th>\n",
       "      <td>101.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/06/2014</th>\n",
       "      <td>89.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/07/2014</th>\n",
       "      <td>102.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/08/2014</th>\n",
       "      <td>101.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/09/2014</th>\n",
       "      <td>103.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/10/2014</th>\n",
       "      <td>110.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/11/2014</th>\n",
       "      <td>103.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/12/2014</th>\n",
       "      <td>96.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)\n",
       "Data                                                                                   \n",
       "31/01/2014                                              102.5                          \n",
       "28/02/2014                                               99.7                          \n",
       "31/03/2014                                               95.4                          \n",
       "30/04/2014                                               94.4                          \n",
       "31/05/2014                                              101.5                          \n",
       "30/06/2014                                               89.3                          \n",
       "31/07/2014                                              102.5                          \n",
       "31/08/2014                                              101.3                          \n",
       "30/09/2014                                              103.2                          \n",
       "31/10/2014                                              110.4                          \n",
       "30/11/2014                                              103.6                          \n",
       "31/12/2014                                               96.1                          "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vendasvarejoconscivil_.iloc[:,0:1][132:144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indice Cambial - 100 = Média de 2014</th>\n",
       "      <th>Indice Ibovespa - 100 = Média de 2014</th>\n",
       "      <th>Indice IPCA - 100 = Média de 2014</th>\n",
       "      <th>Índice M1 - 100 = Média de 2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>149.740047</td>\n",
       "      <td>20.781614</td>\n",
       "      <td>433.386838</td>\n",
       "      <td>33.704050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>151.013780</td>\n",
       "      <td>19.526093</td>\n",
       "      <td>302.407705</td>\n",
       "      <td>33.348234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>142.501675</td>\n",
       "      <td>21.412223</td>\n",
       "      <td>236.918138</td>\n",
       "      <td>32.925495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>122.493110</td>\n",
       "      <td>23.849186</td>\n",
       "      <td>186.837881</td>\n",
       "      <td>31.919443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>125.125843</td>\n",
       "      <td>25.492189</td>\n",
       "      <td>117.495987</td>\n",
       "      <td>31.197922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Indice Cambial - 100 = Média de 2014  \\\n",
       "Data                                               \n",
       "31/01/2003                            149.740047   \n",
       "28/02/2003                            151.013780   \n",
       "31/03/2003                            142.501675   \n",
       "30/04/2003                            122.493110   \n",
       "31/05/2003                            125.125843   \n",
       "\n",
       "            Indice Ibovespa - 100 = Média de 2014  \\\n",
       "Data                                                \n",
       "31/01/2003                              20.781614   \n",
       "28/02/2003                              19.526093   \n",
       "31/03/2003                              21.412223   \n",
       "30/04/2003                              23.849186   \n",
       "31/05/2003                              25.492189   \n",
       "\n",
       "            Indice IPCA - 100 = Média de 2014  Índice M1 - 100 = Média de 2014  \n",
       "Data                                                                            \n",
       "31/01/2003                         433.386838                        33.704050  \n",
       "28/02/2003                         302.407705                        33.348234  \n",
       "31/03/2003                         236.918138                        32.925495  \n",
       "30/04/2003                         186.837881                        31.919443  \n",
       "31/05/2003                         117.495987                        31.197922  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x = pd.concat((dolar_['Indice Câmbial 100 = média de 2014'],\n",
    "                      ibov_['Indice Ibovespa 100 = média de 2014'],\n",
    "                      ipca_['Indice IPCA 100 = Média de 2014'],\n",
    "                      m1_['Índice M1 100 = Média de 2014']), axis = 1)\n",
    "dataset_x = dataset_x.fillna(value = 0)\n",
    "dataset_x.columns = ['Indice Cambial - 100 = Média de 2014','Indice Ibovespa - 100 = Média de 2014',\n",
    "                    'Indice IPCA - 100 = Média de 2014','Índice M1 - 100 = Média de 2014']\n",
    "dataset_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset_x.iloc[:,2:3][10:11].values.ravel()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indice Cimento 100 = Média de 2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>46.359692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>46.116826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>48.832562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>45.072641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>50.691825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Indice Cimento 100 = Média de 2014\n",
       "Data                                          \n",
       "31/01/2003                           46.359692\n",
       "28/02/2003                           46.116826\n",
       "31/03/2003                           48.832562\n",
       "30/04/2003                           45.072641\n",
       "31/05/2003                           50.691825"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retornos_cimento = cimento_.iloc[:,2:3]\n",
    "retornos_cimento = retornos_cimento.fillna(value = 0)\n",
    "retornos_cimento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>58.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)\n",
       "Data                                                                                   \n",
       "31/01/2003                                               63.4                          \n",
       "28/02/2003                                               60.5                          \n",
       "31/03/2003                                               58.6                          \n",
       "30/04/2003                                               58.3                          \n",
       "31/05/2003                                               61.1                          "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retornos_vendas = vendasvarejoconscivil_.iloc[:,0:1]\n",
    "retornos_vendas = retornos_vendas.fillna(value = 0)\n",
    "retornos_vendas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cimento = sm.OLS(retornos_cimento, dataset_x.iloc[:,0:1]).fit()\n",
    "model_vendas = sm.OLS(retornos_vendas, dataset_x.iloc[:,0:1]).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    OLS Regression Results                                    \n",
      "==============================================================================================\n",
      "Dep. Variable:     Indice Cimento 100 = Média de 2014   R-squared:                       0.866\n",
      "Model:                                            OLS   Adj. R-squared:                  0.865\n",
      "Method:                                 Least Squares   F-statistic:                     1232.\n",
      "Date:                                Thu, 03 Oct 2019   Prob (F-statistic):           3.16e-85\n",
      "Time:                                        15:24:20   Log-Likelihood:                -915.74\n",
      "No. Observations:                                 192   AIC:                             1833.\n",
      "Df Residuals:                                     191   BIC:                             1837.\n",
      "Df Model:                                           1                                         \n",
      "Covariance Type:                            nonrobust                                         \n",
      "========================================================================================================\n",
      "                                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Indice Cambial - 100 = Média de 2014     0.6597      0.019     35.100      0.000       0.623       0.697\n",
      "==============================================================================\n",
      "Omnibus:                      118.450   Durbin-Watson:                   0.048\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               12.732\n",
      "Skew:                          -0.078   Prob(JB):                      0.00172\n",
      "Kurtosis:                       1.748   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(model_cimento.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         OLS Regression Results                                                        \n",
      "=======================================================================================================================================\n",
      "Dep. Variable:     Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)   R-squared:                       0.906\n",
      "Model:                                                                                     OLS   Adj. R-squared:                  0.906\n",
      "Method:                                                                          Least Squares   F-statistic:                     1842.\n",
      "Date:                                                                         Thu, 03 Oct 2019   Prob (F-statistic):          5.02e-100\n",
      "Time:                                                                                 15:24:20   Log-Likelihood:                -888.65\n",
      "No. Observations:                                                                          192   AIC:                             1779.\n",
      "Df Residuals:                                                                              191   BIC:                             1783.\n",
      "Df Model:                                                                                    1                                         \n",
      "Covariance Type:                                                                     nonrobust                                         \n",
      "========================================================================================================\n",
      "                                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Indice Cambial - 100 = Média de 2014     0.7005      0.016     42.914      0.000       0.668       0.733\n",
      "==============================================================================\n",
      "Omnibus:                      133.482   Durbin-Watson:                   0.085\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               12.921\n",
      "Skew:                           0.003   Prob(JB):                      0.00156\n",
      "Kurtosis:                       1.729   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(model_vendas.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cimentoB = sm.OLS(retornos_cimento, dataset_x.iloc[:,1:2]).fit()\n",
    "model_vendasB = sm.OLS(retornos_vendas, dataset_x.iloc[:,1:2]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    OLS Regression Results                                    \n",
      "==============================================================================================\n",
      "Dep. Variable:     Indice Cimento 100 = Média de 2014   R-squared:                       0.926\n",
      "Model:                                            OLS   Adj. R-squared:                  0.926\n",
      "Method:                                 Least Squares   F-statistic:                     2403.\n",
      "Date:                                Thu, 03 Oct 2019   Prob (F-statistic):          3.84e-110\n",
      "Time:                                        15:24:38   Log-Likelihood:                -858.11\n",
      "No. Observations:                                 192   AIC:                             1718.\n",
      "Df Residuals:                                     191   BIC:                             1721.\n",
      "Df Model:                                           1                                         \n",
      "Covariance Type:                            nonrobust                                         \n",
      "=========================================================================================================\n",
      "                                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Indice Ibovespa - 100 = Média de 2014     0.7311      0.015     49.018      0.000       0.702       0.761\n",
      "==============================================================================\n",
      "Omnibus:                       13.142   Durbin-Watson:                   0.114\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               14.605\n",
      "Skew:                          -0.671   Prob(JB):                     0.000674\n",
      "Kurtosis:                       2.839   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "===============================================================\n",
      "                                                         OLS Regression Results                                                        \n",
      "=======================================================================================================================================\n",
      "Dep. Variable:     Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)   R-squared:                       0.931\n",
      "Model:                                                                                     OLS   Adj. R-squared:                  0.930\n",
      "Method:                                                                          Least Squares   F-statistic:                     2565.\n",
      "Date:                                                                         Thu, 03 Oct 2019   Prob (F-statistic):          1.18e-112\n",
      "Time:                                                                                 15:24:38   Log-Likelihood:                -859.43\n",
      "No. Observations:                                                                          192   AIC:                             1721.\n",
      "Df Residuals:                                                                              191   BIC:                             1724.\n",
      "Df Model:                                                                                    1                                         \n",
      "Covariance Type:                                                                     nonrobust                                         \n",
      "=========================================================================================================\n",
      "                                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Indice Ibovespa - 100 = Média de 2014     0.7605      0.015     50.643      0.000       0.731       0.790\n",
      "==============================================================================\n",
      "Omnibus:                       19.185   Durbin-Watson:                   0.146\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):                6.723\n",
      "Skew:                          -0.134   Prob(JB):                       0.0347\n",
      "Kurtosis:                       2.123   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(model_cimentoB.summary())\n",
    "print('===============================================================')\n",
    "print(model_vendasB.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    OLS Regression Results                                    \n",
      "==============================================================================================\n",
      "Dep. Variable:     Indice Cimento 100 = Média de 2014   R-squared:                       0.649\n",
      "Model:                                            OLS   Adj. R-squared:                  0.647\n",
      "Method:                                 Least Squares   F-statistic:                     353.1\n",
      "Date:                                Thu, 03 Oct 2019   Prob (F-statistic):           2.70e-45\n",
      "Time:                                        15:24:38   Log-Likelihood:                -1008.0\n",
      "No. Observations:                                 192   AIC:                             2018.\n",
      "Df Residuals:                                     191   BIC:                             2021.\n",
      "Df Model:                                           1                                         \n",
      "Covariance Type:                            nonrobust                                         \n",
      "=====================================================================================================\n",
      "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Indice IPCA - 100 = Média de 2014     0.5653      0.030     18.792      0.000       0.506       0.625\n",
      "==============================================================================\n",
      "Omnibus:                       67.003   Durbin-Watson:                   0.394\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              258.877\n",
      "Skew:                          -1.331   Prob(JB):                     6.10e-57\n",
      "Kurtosis:                       8.027   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "===============================================================\n",
      "                                                         OLS Regression Results                                                        \n",
      "=======================================================================================================================================\n",
      "Dep. Variable:     Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)   R-squared:                       0.659\n",
      "Model:                                                                                     OLS   Adj. R-squared:                  0.657\n",
      "Method:                                                                          Least Squares   F-statistic:                     369.4\n",
      "Date:                                                                         Thu, 03 Oct 2019   Prob (F-statistic):           1.60e-46\n",
      "Time:                                                                                 15:24:38   Log-Likelihood:                -1012.3\n",
      "No. Observations:                                                                          192   AIC:                             2027.\n",
      "Df Residuals:                                                                              191   BIC:                             2030.\n",
      "Df Model:                                                                                    1                                         \n",
      "Covariance Type:                                                                     nonrobust                                         \n",
      "=====================================================================================================\n",
      "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Indice IPCA - 100 = Média de 2014     0.5913      0.031     19.220      0.000       0.531       0.652\n",
      "==============================================================================\n",
      "Omnibus:                       53.322   Durbin-Watson:                   0.427\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              180.277\n",
      "Skew:                          -1.078   Prob(JB):                     7.14e-40\n",
      "Kurtosis:                       7.230   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_cimentoC = sm.OLS(retornos_cimento, dataset_x.iloc[:,2:3]).fit()\n",
    "model_vendasC = sm.OLS(retornos_vendas, dataset_x.iloc[:,2:3]).fit()\n",
    "\n",
    "print(model_cimentoC.summary())\n",
    "print('===============================================================')\n",
    "print(model_vendasC.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    OLS Regression Results                                    \n",
      "==============================================================================================\n",
      "Dep. Variable:     Indice Cimento 100 = Média de 2014   R-squared:                       0.977\n",
      "Model:                                            OLS   Adj. R-squared:                  0.977\n",
      "Method:                                 Least Squares   F-statistic:                     8048.\n",
      "Date:                                Thu, 03 Oct 2019   Prob (F-statistic):          4.34e-158\n",
      "Time:                                        15:24:38   Log-Likelihood:                -747.15\n",
      "No. Observations:                                 192   AIC:                             1496.\n",
      "Df Residuals:                                     191   BIC:                             1500.\n",
      "Df Model:                                           1                                         \n",
      "Covariance Type:                            nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Índice M1 - 100 = Média de 2014     0.9758      0.011     89.712      0.000       0.954       0.997\n",
      "==============================================================================\n",
      "Omnibus:                       22.433   Durbin-Watson:                   0.359\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.459\n",
      "Skew:                          -0.872   Prob(JB):                     1.80e-06\n",
      "Kurtosis:                       3.514   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "===============================================================\n",
      "                                                         OLS Regression Results                                                        \n",
      "=======================================================================================================================================\n",
      "Dep. Variable:     Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)   R-squared:                       0.976\n",
      "Model:                                                                                     OLS   Adj. R-squared:                  0.976\n",
      "Method:                                                                          Least Squares   F-statistic:                     7697.\n",
      "Date:                                                                         Thu, 03 Oct 2019   Prob (F-statistic):          2.77e-156\n",
      "Time:                                                                                 15:24:38   Log-Likelihood:                -758.47\n",
      "No. Observations:                                                                          192   AIC:                             1519.\n",
      "Df Residuals:                                                                              191   BIC:                             1522.\n",
      "Df Model:                                                                                    1                                         \n",
      "Covariance Type:                                                                     nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Índice M1 - 100 = Média de 2014     1.0122      0.012     87.735      0.000       0.989       1.035\n",
      "==============================================================================\n",
      "Omnibus:                        5.086   Durbin-Watson:                   0.462\n",
      "Prob(Omnibus):                  0.079   Jarque-Bera (JB):                4.804\n",
      "Skew:                           0.331   Prob(JB):                       0.0905\n",
      "Kurtosis:                       2.596   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_cimentoD = sm.OLS(retornos_cimento, dataset_x.iloc[:,3:4]).fit()\n",
    "model_vendasD = sm.OLS(retornos_vendas, dataset_x.iloc[:,3:4]).fit()\n",
    "\n",
    "print(model_cimentoD.summary())\n",
    "print('===============================================================')\n",
    "print(model_vendasD.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>58.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)\n",
       "Data                                                                                   \n",
       "31/01/2003                                               63.4                          \n",
       "28/02/2003                                               60.5                          \n",
       "31/03/2003                                               58.6                          \n",
       "30/04/2003                                               58.3                          \n",
       "31/05/2003                                               61.1                          "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retornos_vendas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int((dataset_x.shape[0] * 0.7) - 2)\n",
    "treino_x = dataset_x[:cut].values\n",
    "treino_y = retornos_vendas[:cut].shift(-1).values\n",
    "teste_x = dataset_x[cut:].values\n",
    "teste_y = retornos_vendas[cut:].shift(-1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_y = np.nan_to_num(treino_y)\n",
    "teste_y = np.nan_to_num(teste_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_x = treino_x[:130]\n",
    "treino_y = treino_y[:130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_x = teste_x[:58]\n",
    "teste_y = teste_y[:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 27.8783\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 26.7171\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - ETA: 0s - loss: 22.99 - 1s 4ms/step - loss: 23.0662\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 21.5589\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 21.8196\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 19.9523\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 17.6912\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 15.0945: 0s - loss: 14.28\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 17.0865\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 16.8906\n",
      "Epoch 11/100\n",
      " 10/132 [=>............................] - ETA: 0s - loss: 11.2825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.144008). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 2ms/step - loss: 17.3937\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 16.2703\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 16.8404\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 15.9664\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 15.1352\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 16.3932\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 14.7123\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 14.6776\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 13.4643\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 14.3985\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 13.5578\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.9093\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.7908\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 14.5300\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 727us/step - loss: 14.6241\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 13.0206\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.0751: 0s - loss: 12.24\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.2642\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 14.5399\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.6871\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.7045\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 11.9128\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.8091\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.4347\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.2082\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.3558\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.2666\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.6447\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.9608\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.8258\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.0839\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 11.5521\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.8098\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.6443\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.0478\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.3849\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.1243\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.1019\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.6918\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 11.5008\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.0786\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.1879\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 11.1007\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.9140A: 0s - loss: 9.852\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.3098\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.7926\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.6671\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.6604A: 0s - loss: 9.8\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.8818\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.3180\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.0243\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.5011\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.7785\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.1979\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.9425\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.6259\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.4234\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.1710\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.9463\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.8216\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.0969\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.1691\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.4599\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.3736\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 894us/step - loss: 8.4199\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.2726\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.5083\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.1504\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.4753\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 11.2824\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.1314\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.6031\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.0935\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.6340\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.4080\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.6959\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.4415\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 8.4020\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.2855: 0s - loss: 10.\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.8112\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.9480\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.9260\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.6661\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.1760\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.5689\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.0980\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.2863\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.7443\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.8233\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.8740\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 32, input_dim = treino_x.shape[1], activation='elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1))\n",
    "model.compile(optimizer='adam', loss = 'mean_absolute_error')\n",
    "history = model.fit(treino_x,treino_y, batch_size=10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 900us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.815733718872071"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.evaluate(teste_x, teste_y)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.815733718872071"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Vendas Construção Civil - Reais  Vendas Construção Civil - Previstas\n",
      "0                             99.7                               78.875\n",
      "1                             95.4                               78.875\n",
      "2                             94.4                               78.875\n",
      "3                            101.5                               78.875\n",
      "4                             89.3                               78.875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backtest = pd.DataFrame(teste_y)\n",
    "backtest.columns = ['Vendas Construção Civil - Reais']\n",
    "backtest['Vendas Construção Civil - Previstas'] = model.predict(teste_x)\n",
    "print(backtest.head())\n",
    "plt.plot(backtest['Vendas Construção Civil - Reais'])\n",
    "plt.plot(backtest['Vendas Construção Civil - Previstas'])\n",
    "plt.legend()\n",
    "plt.title('Vendas Construção Civil - Reais x Previstas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = ['selu','elu','tanh','relu','linear','sigmoid', 'hard_sigmoid']\n",
    "def gen_random_inputs_nn (h_layers = 1, \n",
    "                          neurons_by_layer = 32, \n",
    "                          activation_function_hiddend = 6, \n",
    "                          neurons_entry = 1,\n",
    "                          activation_entry = 6,\n",
    "                         epochs = 100,\n",
    "                         batch_size = 100,\n",
    "                         pop = 100):\n",
    "    h_ly = np.random.randint(low = 1, high = h_layers, size = pop)\n",
    "    n_ly = np.random.randint(low = 1, high = neurons_by_layer, size = pop)\n",
    "    a_ly = np.random.randint(low = 0, high = activation_function_hiddend, size = pop)\n",
    "    n_entry = np.random.randint(low = 1, high = neurons_entry, size = pop)\n",
    "    a_entry = np.random.randint(low = 0, high = activation_entry, size = pop)\n",
    "    epc = np.random.randint(low = 1, high = epochs, size = pop)\n",
    "    bs = np.random.randint(low = 1,    high = batch_size, size = pop)\n",
    "    \n",
    "    h_ly = pd.DataFrame(h_ly)\n",
    "    n_ly = pd.DataFrame(n_ly)\n",
    "    a_ly = pd.DataFrame(a_ly)\n",
    "    n_entry = pd.DataFrame(n_entry)\n",
    "    a_entry = pd.DataFrame(a_entry)\n",
    "    epc = pd.DataFrame(epc)\n",
    "    bs = pd.DataFrame(bs)\n",
    "    \n",
    "    configs = pd.concat((h_ly,n_ly,a_ly,\n",
    "                         n_entry,a_entry,\n",
    "                         epc,bs), axis = 1)\n",
    "    configs.columns = ['Hidden Layers','Neurons in Hidden Layers',\n",
    "                       'Activation in Hidden Layers',\n",
    "                       'Neurons in Entry','Activation in Entry',\n",
    "                       'Epochs','Batch Size']\n",
    "    return(configs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nn(setup = None, train_x = None, train_y = None, test_x = None, test_y = None, activations = []):\n",
    "    acc = []\n",
    "    for i in range(len(setup)):\n",
    "        model = None\n",
    "        h_ly = setup.iloc[:,:1][i:i+1].values.ravel()[0]\n",
    "        n_ly = setup.iloc[:,1:2][i:i+1].values.ravel()[0]\n",
    "        a_ly = setup.iloc[:,2:3][i:i+1].values.ravel()[0]\n",
    "        n_entry = setup.iloc[:,3:4][i:i+1].values.ravel()[0]\n",
    "        a_entry = setup.iloc[:,4:5][i:i+1].values.ravel()[0]\n",
    "        epc = setup.iloc[:,5:6][i:i+1].values.ravel()[0]\n",
    "        bs = setup.iloc[:,6:7][i:i+1].values.ravel()[0]\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = n_entry, activation = activations[a_entry], input_dim = train_x.shape[1] ))\n",
    "        model.add(Dropout(0.2))\n",
    "        for l in range(1,h_ly):\n",
    "            model.add(Dense(units = n_ly, activation = activations[a_ly]))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(units = 1))\n",
    "        model.compile(optimizer='adam', loss = 'mean_absolute_error')\n",
    "        model.fit(train_x, train_y, epochs = epc, batch_size=bs)\n",
    "        result = model.evaluate(test_x, test_y)\n",
    "        acc.append(result)\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darwin_awards_nn(setup = None, split = 5, metrics = 'Acc'):\n",
    "    setup_ = setup.sort_values(metrics, ascending=True)\n",
    "    setup_ = setup_[:split]\n",
    "    var1 = setup_.iloc[:,0:1].values.ravel()\n",
    "    var2 = setup_.iloc[:,1:2].values.ravel()\n",
    "    var3 = setup_.iloc[:,2:3].values.ravel()\n",
    "    var4 = setup_.iloc[:,3:4].values.ravel()\n",
    "    var5 = setup_.iloc[:,4:5].values.ravel()\n",
    "    var6 = setup_.iloc[:,5:6].values.ravel()\n",
    "    var7 = setup_.iloc[:,6:7].values.ravel()\n",
    "    \n",
    "    var1 = var1.tolist()\n",
    "    var2 = var2.tolist()\n",
    "    var3 = var3.tolist()\n",
    "    var4 = var4.tolist()\n",
    "    var5 = var5.tolist()\n",
    "    var6 = var6.tolist()\n",
    "    var7 = var7.tolist()\n",
    "    \n",
    "    \n",
    "    var1.append(int(np.mean(var1)))\n",
    "    var2.append(int(np.mean(var2)))\n",
    "    var3.append(int(np.mean(var3)))\n",
    "    var4.append(int(np.mean(var4)))\n",
    "    var5.append(int(np.mean(var5)))\n",
    "    var6.append(int(np.mean(var6)))\n",
    "    var7.append(int(np.mean(var7)))\n",
    "    \n",
    "    var1.append(int(np.median(var1)))\n",
    "    var2.append(int(np.median(var2)))\n",
    "    var3.append(int(np.median(var3)))\n",
    "    var4.append(int(np.median(var4)))\n",
    "    var5.append(int(np.median(var5)))\n",
    "    var6.append(int(np.median(var6)))\n",
    "    var7.append(int(np.median(var7)))\n",
    "    \n",
    "    var1 = pd.DataFrame(var1)\n",
    "    var2 = pd.DataFrame(var2)\n",
    "    var3 = pd.DataFrame(var3)\n",
    "    var4 = pd.DataFrame(var4)\n",
    "    var5 = pd.DataFrame(var5)\n",
    "    var6 = pd.DataFrame(var6)\n",
    "    var7 = pd.DataFrame(var7)\n",
    "    \n",
    "    var1_ = var1.sample(len(var1)).values\n",
    "    var2_ = var1.sample(len(var2)).values\n",
    "    var3_ = var1.sample(len(var3)).values\n",
    "    var4_ = var1.sample(len(var4)).values\n",
    "    var5_ = var1.sample(len(var5)).values\n",
    "    var6_ = var1.sample(len(var6)).values\n",
    "    var7_ = var1.sample(len(var7)).values\n",
    "    bd_ = pd.concat((pd.DataFrame(var1_),pd.DataFrame(var2_),pd.DataFrame(var3_), \n",
    "                             pd.DataFrame(var4_),pd.DataFrame(var5_),\n",
    "                             pd.DataFrame(var6_),pd.DataFrame(var7_)), axis = 1)\n",
    "    \n",
    "    bd_.columns = ['Hidden Layers','Neurons in Hidden Layers',\n",
    "                       'Activation in Hidden Layers',\n",
    "                       'Neurons in Entry','Activation in Entry','Epochs','Batch Size']\n",
    "    \n",
    "    best_darwin = pd.concat((var1,var2,var3, var4,var5,var6,var7,\n",
    "                             ), axis = 1)\n",
    "    \n",
    "    best_darwin.columns = ['Hidden Layers','Neurons in Hidden Layers',\n",
    "                       'Activation in Hidden Layers',\n",
    "                       'Neurons in Entry','Activation in Entry','Epochs','Batch Size']\n",
    "    \n",
    "    final = pd.concat((best_darwin,bd_), axis = 0)\n",
    "    \n",
    "    \n",
    "    return(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filldarwin_nn(darwinset = None, pop = 100,  h_layers = 1, \n",
    "                          neurons_by_layer = 32, \n",
    "                          activation_function_hiddend = 6, \n",
    "                          neurons_entry = 1,\n",
    "                          activation_entry = 6,\n",
    "                         epochs = 100,\n",
    "                         batch_size = 100):\n",
    "    fill_pop = abs(darwinset.shape[0] - pop)\n",
    "    new_fill = gen_random_inputs_nn(pop = fill_pop, h_layers = h_layers,neurons_by_layer = neurons_by_layer, \n",
    "                activation_function_hiddend = activation_function_hiddend, neurons_entry = neurons_entry,\n",
    "                activation_entry = activation_entry,\n",
    "                         epochs = epochs,\n",
    "                         batch_size = batch_size)\n",
    "    new_fill_ = pd.concat((darwinset,new_fill), axis = 0)\n",
    "    return(new_fill_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ga_NN(start_pop = 100, generations = 100,h_layers = 1, neurons_by_layer = 32,\n",
    "          activation_function_hiddend = 6,neurons_entry = 1,\n",
    "        activation_entry = 6,epochs = 100,batch_size = 100):\n",
    "    \n",
    "    life_origin = gen_random_inputs_nn(h_layers = h_layers, \n",
    "                          neurons_by_layer = neurons_by_layer, \n",
    "                          activation_function_hiddend = activation_function_hiddend, \n",
    "                          neurons_entry = neurons_entry,\n",
    "                          activation_entry = activation_entry,\n",
    "                         epochs = epochs,\n",
    "                         batch_size = batch_size,\n",
    "                         pop = start_pop)\n",
    "    pop_ = life_origin\n",
    "    acc_best = []\n",
    "    acc_mean = []\n",
    "    for i in range(1,generations):\n",
    "        print('Generation:  ', i)\n",
    "        pop_['Acc'] = build_nn(pop_, train_x = treino_x, train_y = treino_y, \n",
    "                         test_x = teste_x, test_y = teste_y, activations = functions)\n",
    "        acc_best.append(max(pop_['Acc']))\n",
    "        acc_mean.append(np.mean(pop_['Acc'].values))\n",
    "        final_pop = pop_\n",
    "        best_darwin = darwin_awards_nn(setup=pop_)\n",
    "        pop_ = None\n",
    "        pop_ = filldarwin_nn(darwinset = best_darwin, pop = start_pop, h_layers = h_layers,neurons_by_layer = neurons_by_layer, \n",
    "                activation_function_hiddend = activation_function_hiddend, neurons_entry = neurons_entry,\n",
    "                activation_entry = activation_entry,\n",
    "                         epochs = epochs,\n",
    "                         batch_size = batch_size)\n",
    "        \n",
    "    return(final_pop, acc_best, acc_mean)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation:   1\n",
      "Epoch 1/235\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 70.5696\n",
      "Epoch 2/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 56.8447\n",
      "Epoch 3/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 48.9517\n",
      "Epoch 4/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 44.7456\n",
      "Epoch 5/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 42.2836\n",
      "Epoch 6/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 40.5293\n",
      "Epoch 7/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 39.1464\n",
      "Epoch 8/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 38.0208\n",
      "Epoch 9/235\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 36.9242\n",
      "Epoch 10/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 35.4517\n",
      "Epoch 11/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 34.4574\n",
      "Epoch 12/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 33.1719\n",
      "Epoch 13/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 31.9086\n",
      "Epoch 14/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 30.5499\n",
      "Epoch 15/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 29.4411\n",
      "Epoch 16/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 28.1825\n",
      "Epoch 17/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 27.0499\n",
      "Epoch 18/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 25.6821\n",
      "Epoch 19/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 24.5380\n",
      "Epoch 20/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 23.2372\n",
      "Epoch 21/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 22.2506\n",
      "Epoch 22/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 20.9865\n",
      "Epoch 23/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 20.0556\n",
      "Epoch 24/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 18.7554\n",
      "Epoch 25/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 17.7420\n",
      "Epoch 26/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 16.5693\n",
      "Epoch 27/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 15.9190\n",
      "Epoch 28/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 15.1468\n",
      "Epoch 29/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 14.6631\n",
      "Epoch 30/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 14.1515\n",
      "Epoch 31/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 13.9384\n",
      "Epoch 32/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 13.6064\n",
      "Epoch 33/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 13.4282\n",
      "Epoch 34/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 13.2954\n",
      "Epoch 35/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 13.1984\n",
      "Epoch 36/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 13.1251\n",
      "Epoch 37/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.9441\n",
      "Epoch 38/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.9321\n",
      "Epoch 39/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 13.0794\n",
      "Epoch 40/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.8664\n",
      "Epoch 41/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.9307\n",
      "Epoch 42/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 13.0672\n",
      "Epoch 43/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.9594\n",
      "Epoch 44/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.7877\n",
      "Epoch 45/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.9447\n",
      "Epoch 46/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.9895\n",
      "Epoch 47/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 13.0799\n",
      "Epoch 48/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.9650\n",
      "Epoch 49/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 13.1279\n",
      "Epoch 50/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.9033\n",
      "Epoch 51/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.9978\n",
      "Epoch 52/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.7569\n",
      "Epoch 53/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.9421\n",
      "Epoch 54/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.8309\n",
      "Epoch 55/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.9444\n",
      "Epoch 56/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 13.0058\n",
      "Epoch 57/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.8714\n",
      "Epoch 58/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 13.0223\n",
      "Epoch 59/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.8128\n",
      "Epoch 60/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 13.0820\n",
      "Epoch 61/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.6922\n",
      "Epoch 62/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 13.0352\n",
      "Epoch 63/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.9253\n",
      "Epoch 64/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.7636\n",
      "Epoch 65/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.8013\n",
      "Epoch 66/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.7508\n",
      "Epoch 67/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.8746\n",
      "Epoch 68/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.7440\n",
      "Epoch 69/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.7883\n",
      "Epoch 70/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.9033\n",
      "Epoch 71/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.7875\n",
      "Epoch 72/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.8323\n",
      "Epoch 73/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.8475\n",
      "Epoch 74/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.7052\n",
      "Epoch 75/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.6485\n",
      "Epoch 76/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.5064\n",
      "Epoch 77/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.5297\n",
      "Epoch 78/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.5387\n",
      "Epoch 79/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.7142\n",
      "Epoch 80/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.9804\n",
      "Epoch 81/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.6868\n",
      "Epoch 82/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.8580\n",
      "Epoch 83/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.7606\n",
      "Epoch 84/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.4701\n",
      "Epoch 85/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.7861\n",
      "Epoch 86/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.5612\n",
      "Epoch 87/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.5804\n",
      "Epoch 88/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.6362\n",
      "Epoch 89/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.4149\n",
      "Epoch 90/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.6528\n",
      "Epoch 91/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.2978\n",
      "Epoch 92/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.2760\n",
      "Epoch 93/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.4314\n",
      "Epoch 94/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.6992\n",
      "Epoch 95/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.5472\n",
      "Epoch 96/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.5867\n",
      "Epoch 97/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.3540\n",
      "Epoch 98/235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 2ms/step - loss: 12.7010\n",
      "Epoch 99/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.1323\n",
      "Epoch 100/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.3339\n",
      "Epoch 101/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.4019\n",
      "Epoch 102/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.4968\n",
      "Epoch 103/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.3067\n",
      "Epoch 104/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.1204\n",
      "Epoch 105/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.3202\n",
      "Epoch 106/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.1377\n",
      "Epoch 107/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.3930\n",
      "Epoch 108/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.3557\n",
      "Epoch 109/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.1927\n",
      "Epoch 110/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.3238\n",
      "Epoch 111/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.3721\n",
      "Epoch 112/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.2021\n",
      "Epoch 113/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.1952\n",
      "Epoch 114/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.1179\n",
      "Epoch 115/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.0932\n",
      "Epoch 116/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.1845\n",
      "Epoch 117/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.0269\n",
      "Epoch 118/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.1381\n",
      "Epoch 119/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.1594\n",
      "Epoch 120/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.0984\n",
      "Epoch 121/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.9622\n",
      "Epoch 122/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.8460\n",
      "Epoch 123/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.8155\n",
      "Epoch 124/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.9651\n",
      "Epoch 125/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 12.2028\n",
      "Epoch 126/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.7805\n",
      "Epoch 127/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.9091\n",
      "Epoch 128/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.8268\n",
      "Epoch 129/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.6576\n",
      "Epoch 130/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.6896\n",
      "Epoch 131/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.7446\n",
      "Epoch 132/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.9497\n",
      "Epoch 133/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.8400\n",
      "Epoch 134/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.5292\n",
      "Epoch 135/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.5799\n",
      "Epoch 136/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.3184\n",
      "Epoch 137/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.6787\n",
      "Epoch 138/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 11.2566\n",
      "Epoch 139/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.3987\n",
      "Epoch 140/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.2472\n",
      "Epoch 141/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.2648\n",
      "Epoch 142/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.2978\n",
      "Epoch 143/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.1657\n",
      "Epoch 144/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.4443\n",
      "Epoch 145/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.2581\n",
      "Epoch 146/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.3490\n",
      "Epoch 147/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 11.1855\n",
      "Epoch 148/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 11.1087\n",
      "Epoch 149/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.0743\n",
      "Epoch 150/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.0045\n",
      "Epoch 151/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.1607\n",
      "Epoch 152/235\n",
      "132/132 [==============================] - ETA: 0s - loss: 11.69 - 0s 1ms/step - loss: 11.0681\n",
      "Epoch 153/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.8506\n",
      "Epoch 154/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.8536\n",
      "Epoch 155/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.9937\n",
      "Epoch 156/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.9420\n",
      "Epoch 157/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.8827\n",
      "Epoch 158/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.2126\n",
      "Epoch 159/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.6436\n",
      "Epoch 160/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.7677\n",
      "Epoch 161/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.5318\n",
      "Epoch 162/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.6529\n",
      "Epoch 163/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.6793\n",
      "Epoch 164/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.5829\n",
      "Epoch 165/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.5965\n",
      "Epoch 166/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.5175\n",
      "Epoch 167/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.5307\n",
      "Epoch 168/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.7877\n",
      "Epoch 169/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.3439\n",
      "Epoch 170/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.4532\n",
      "Epoch 171/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.2909\n",
      "Epoch 172/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.2806\n",
      "Epoch 173/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.1484\n",
      "Epoch 174/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.1000\n",
      "Epoch 175/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.1202\n",
      "Epoch 176/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.0127\n",
      "Epoch 177/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.2260\n",
      "Epoch 178/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.8798\n",
      "Epoch 179/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.9463\n",
      "Epoch 180/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.8649\n",
      "Epoch 181/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.9950\n",
      "Epoch 182/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.9110\n",
      "Epoch 183/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.7000\n",
      "Epoch 184/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.3700\n",
      "Epoch 185/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.4357\n",
      "Epoch 186/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.8159\n",
      "Epoch 187/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.6813\n",
      "Epoch 188/235\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 9.3900\n",
      "Epoch 189/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.2669\n",
      "Epoch 190/235\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 9.3808\n",
      "Epoch 191/235\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 9.4538\n",
      "Epoch 192/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.3794\n",
      "Epoch 193/235\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 9.2097\n",
      "Epoch 194/235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 3ms/step - loss: 9.0242\n",
      "Epoch 195/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.8766\n",
      "Epoch 196/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.9947\n",
      "Epoch 197/235\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 8.9277\n",
      "Epoch 198/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.0400\n",
      "Epoch 199/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.7624\n",
      "Epoch 200/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.8595\n",
      "Epoch 201/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.6802\n",
      "Epoch 202/235\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 8.8283\n",
      "Epoch 203/235\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 8.8350\n",
      "Epoch 204/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.7209\n",
      "Epoch 205/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.4386\n",
      "Epoch 206/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.4098\n",
      "Epoch 207/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.5499\n",
      "Epoch 208/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.3968\n",
      "Epoch 209/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.3973\n",
      "Epoch 210/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.1699\n",
      "Epoch 211/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.1803\n",
      "Epoch 212/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.9699\n",
      "Epoch 213/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.1777\n",
      "Epoch 214/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.3845\n",
      "Epoch 215/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.3318\n",
      "Epoch 216/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.1767\n",
      "Epoch 217/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.0655\n",
      "Epoch 218/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.9755\n",
      "Epoch 219/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.8411\n",
      "Epoch 220/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.2111\n",
      "Epoch 221/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.0189\n",
      "Epoch 222/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.8269\n",
      "Epoch 223/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.8405\n",
      "Epoch 224/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.6314\n",
      "Epoch 225/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.8236\n",
      "Epoch 226/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.7510\n",
      "Epoch 227/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.7411\n",
      "Epoch 228/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.6237\n",
      "Epoch 229/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.6575\n",
      "Epoch 230/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.8638\n",
      "Epoch 231/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.8668\n",
      "Epoch 232/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.5451\n",
      "Epoch 233/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.6350\n",
      "Epoch 234/235\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.5908\n",
      "Epoch 235/235\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.2707\n",
      "60/60 [==============================] - 1s 9ms/step\n",
      "Epoch 1/943\n",
      "132/132 [==============================] - 2s 17ms/step - loss: 66.9848\n",
      "Epoch 2/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 20.5421\n",
      "Epoch 3/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 15.1617\n",
      "Epoch 4/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 24.2612\n",
      "Epoch 5/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 15.9740\n",
      "Epoch 6/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 19.6458\n",
      "Epoch 7/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.2817\n",
      "Epoch 8/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 12.8097\n",
      "Epoch 9/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 11.5130\n",
      "Epoch 10/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.6805\n",
      "Epoch 11/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.2155\n",
      "Epoch 12/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.6497\n",
      "Epoch 13/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.8783\n",
      "Epoch 14/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.8980\n",
      "Epoch 15/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.3718\n",
      "Epoch 16/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.1617\n",
      "Epoch 17/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.5375\n",
      "Epoch 18/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.1404\n",
      "Epoch 19/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.4274\n",
      "Epoch 20/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.3363\n",
      "Epoch 21/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.2570\n",
      "Epoch 22/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.9804\n",
      "Epoch 23/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.3012\n",
      "Epoch 24/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.4043\n",
      "Epoch 25/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.6441\n",
      "Epoch 26/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.7880\n",
      "Epoch 27/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.4245\n",
      "Epoch 28/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.7474\n",
      "Epoch 29/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.5874\n",
      "Epoch 30/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.9394\n",
      "Epoch 31/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.2654\n",
      "Epoch 32/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.6263\n",
      "Epoch 33/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.6296\n",
      "Epoch 34/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.7881\n",
      "Epoch 35/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.0711\n",
      "Epoch 36/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.2461\n",
      "Epoch 37/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.2456\n",
      "Epoch 38/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.3776\n",
      "Epoch 39/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.6683\n",
      "Epoch 40/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.4609\n",
      "Epoch 41/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.1899\n",
      "Epoch 42/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.4339\n",
      "Epoch 43/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.4629\n",
      "Epoch 44/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.3626\n",
      "Epoch 45/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.3837\n",
      "Epoch 46/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.5680\n",
      "Epoch 47/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.8063\n",
      "Epoch 48/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.4446\n",
      "Epoch 49/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.8886\n",
      "Epoch 50/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.7552\n",
      "Epoch 51/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.7019\n",
      "Epoch 52/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.1920\n",
      "Epoch 53/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.2518\n",
      "Epoch 54/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.1090\n",
      "Epoch 55/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.8972\n",
      "Epoch 56/943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 3ms/step - loss: 7.4084\n",
      "Epoch 57/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.2565\n",
      "Epoch 58/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.5983\n",
      "Epoch 59/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.2069\n",
      "Epoch 60/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.0403\n",
      "Epoch 61/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.7778\n",
      "Epoch 62/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.8224\n",
      "Epoch 63/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.5178\n",
      "Epoch 64/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.1956\n",
      "Epoch 65/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.6476\n",
      "Epoch 66/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.3607\n",
      "Epoch 67/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.0390\n",
      "Epoch 68/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.3548\n",
      "Epoch 69/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.4661\n",
      "Epoch 70/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.0623\n",
      "Epoch 71/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.3065\n",
      "Epoch 72/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.3672\n",
      "Epoch 73/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.1030\n",
      "Epoch 74/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.7880\n",
      "Epoch 75/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.7987\n",
      "Epoch 76/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.9509\n",
      "Epoch 77/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.8305\n",
      "Epoch 78/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.6946\n",
      "Epoch 79/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.5103\n",
      "Epoch 80/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.3055\n",
      "Epoch 81/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.7357\n",
      "Epoch 82/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.0529\n",
      "Epoch 83/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.1526\n",
      "Epoch 84/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.6408\n",
      "Epoch 85/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.3964\n",
      "Epoch 86/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.6002\n",
      "Epoch 87/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.4871\n",
      "Epoch 88/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.7511\n",
      "Epoch 89/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.9775\n",
      "Epoch 90/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.0876\n",
      "Epoch 91/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.6689\n",
      "Epoch 92/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.7402\n",
      "Epoch 93/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.5565\n",
      "Epoch 94/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.4797\n",
      "Epoch 95/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.0563\n",
      "Epoch 96/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.7844\n",
      "Epoch 97/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.8074\n",
      "Epoch 98/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.1777\n",
      "Epoch 99/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.1457\n",
      "Epoch 100/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.4459\n",
      "Epoch 101/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.5914\n",
      "Epoch 102/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.4993\n",
      "Epoch 103/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.4172\n",
      "Epoch 104/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.2413\n",
      "Epoch 105/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.7454\n",
      "Epoch 106/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.9442\n",
      "Epoch 107/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2440\n",
      "Epoch 108/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.0799\n",
      "Epoch 109/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.8830\n",
      "Epoch 110/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.2881\n",
      "Epoch 111/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.1518\n",
      "Epoch 112/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.8991\n",
      "Epoch 113/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.4927\n",
      "Epoch 114/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.7588\n",
      "Epoch 115/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.9555\n",
      "Epoch 116/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.3584\n",
      "Epoch 117/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.9684\n",
      "Epoch 118/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7858\n",
      "Epoch 119/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9183\n",
      "Epoch 120/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.5010\n",
      "Epoch 121/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.7709\n",
      "Epoch 122/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2880\n",
      "Epoch 123/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.1111\n",
      "Epoch 124/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.9888\n",
      "Epoch 125/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.7882\n",
      "Epoch 126/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.4731\n",
      "Epoch 127/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.4992\n",
      "Epoch 128/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.7430\n",
      "Epoch 129/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.5154\n",
      "Epoch 130/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.2421\n",
      "Epoch 131/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2897\n",
      "Epoch 132/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.7070\n",
      "Epoch 133/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.8204\n",
      "Epoch 134/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 8.1644\n",
      "Epoch 135/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.6447\n",
      "Epoch 136/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 6.0732\n",
      "Epoch 137/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.2053\n",
      "Epoch 138/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.7981\n",
      "Epoch 139/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.1468\n",
      "Epoch 140/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.0092\n",
      "Epoch 141/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.2327\n",
      "Epoch 142/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.2227\n",
      "Epoch 143/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.5832\n",
      "Epoch 144/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.1069\n",
      "Epoch 145/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.3042\n",
      "Epoch 146/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.6942\n",
      "Epoch 147/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.2335\n",
      "Epoch 148/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.9436\n",
      "Epoch 149/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.4944\n",
      "Epoch 150/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.3273\n",
      "Epoch 151/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.8578\n",
      "Epoch 152/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 6.8072\n",
      "Epoch 153/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.4027\n",
      "Epoch 154/943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 2ms/step - loss: 6.4680\n",
      "Epoch 155/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.9738\n",
      "Epoch 156/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.0363\n",
      "Epoch 157/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.4029\n",
      "Epoch 158/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.8345\n",
      "Epoch 159/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.7586\n",
      "Epoch 160/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.8172\n",
      "Epoch 161/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.1442\n",
      "Epoch 162/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9546\n",
      "Epoch 163/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.6421\n",
      "Epoch 164/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.3523\n",
      "Epoch 165/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2453\n",
      "Epoch 166/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9577\n",
      "Epoch 167/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.5825\n",
      "Epoch 168/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.3724\n",
      "Epoch 169/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.4144\n",
      "Epoch 170/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7688\n",
      "Epoch 171/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.5656\n",
      "Epoch 172/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9535\n",
      "Epoch 173/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.9411\n",
      "Epoch 174/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9396\n",
      "Epoch 175/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 7.0629\n",
      "Epoch 176/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2467\n",
      "Epoch 177/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2801\n",
      "Epoch 178/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.3901\n",
      "Epoch 179/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.8952\n",
      "Epoch 180/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.1423\n",
      "Epoch 181/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2439\n",
      "Epoch 182/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.7924\n",
      "Epoch 183/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5725\n",
      "Epoch 184/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.0801\n",
      "Epoch 185/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7709\n",
      "Epoch 186/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.0015\n",
      "Epoch 187/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.8845\n",
      "Epoch 188/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7528\n",
      "Epoch 189/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2098\n",
      "Epoch 190/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5536\n",
      "Epoch 191/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2860\n",
      "Epoch 192/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4400\n",
      "Epoch 193/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2394\n",
      "Epoch 194/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.9234\n",
      "Epoch 195/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7511\n",
      "Epoch 196/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9045\n",
      "Epoch 197/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.6697\n",
      "Epoch 198/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5514\n",
      "Epoch 199/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7745\n",
      "Epoch 200/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5711\n",
      "Epoch 201/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2944\n",
      "Epoch 202/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7461\n",
      "Epoch 203/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2491\n",
      "Epoch 204/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7036\n",
      "Epoch 205/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.8258\n",
      "Epoch 206/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.0658\n",
      "Epoch 207/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9930\n",
      "Epoch 208/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4621\n",
      "Epoch 209/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9876\n",
      "Epoch 210/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.4731\n",
      "Epoch 211/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.9503\n",
      "Epoch 212/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4669\n",
      "Epoch 213/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9982\n",
      "Epoch 214/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.8398\n",
      "Epoch 215/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.8678\n",
      "Epoch 216/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.4523\n",
      "Epoch 217/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.8521\n",
      "Epoch 218/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5912\n",
      "Epoch 219/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.7617\n",
      "Epoch 220/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.4036\n",
      "Epoch 221/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.3506\n",
      "Epoch 222/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7940\n",
      "Epoch 223/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.4478\n",
      "Epoch 224/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.9149\n",
      "Epoch 225/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.6367\n",
      "Epoch 226/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.9625\n",
      "Epoch 227/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9014\n",
      "Epoch 228/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.4581\n",
      "Epoch 229/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.5535\n",
      "Epoch 230/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.8179\n",
      "Epoch 231/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5872\n",
      "Epoch 232/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.2604\n",
      "Epoch 233/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4589\n",
      "Epoch 234/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9416\n",
      "Epoch 235/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.0310\n",
      "Epoch 236/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7089\n",
      "Epoch 237/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.6689\n",
      "Epoch 238/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.9931\n",
      "Epoch 239/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2620\n",
      "Epoch 240/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4005\n",
      "Epoch 241/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2844\n",
      "Epoch 242/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7564\n",
      "Epoch 243/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5063\n",
      "Epoch 244/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4551\n",
      "Epoch 245/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7256\n",
      "Epoch 246/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5717\n",
      "Epoch 247/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.1871\n",
      "Epoch 248/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.9099\n",
      "Epoch 249/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7382\n",
      "Epoch 250/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.0396\n",
      "Epoch 251/943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2059\n",
      "Epoch 252/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.3927\n",
      "Epoch 253/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.3653\n",
      "Epoch 254/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.1061\n",
      "Epoch 255/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.7554\n",
      "Epoch 256/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4644\n",
      "Epoch 257/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.1272\n",
      "Epoch 258/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.6015\n",
      "Epoch 259/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5192\n",
      "Epoch 260/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.3487\n",
      "Epoch 261/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.7966\n",
      "Epoch 262/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4459\n",
      "Epoch 263/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2724\n",
      "Epoch 264/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5265\n",
      "Epoch 265/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5159\n",
      "Epoch 266/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2998\n",
      "Epoch 267/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.8364\n",
      "Epoch 268/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 6.3578\n",
      "Epoch 269/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.6663\n",
      "Epoch 270/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4694\n",
      "Epoch 271/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2786\n",
      "Epoch 272/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.0779\n",
      "Epoch 273/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.9531\n",
      "Epoch 274/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2617\n",
      "Epoch 275/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2781\n",
      "Epoch 276/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4632\n",
      "Epoch 277/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.9360\n",
      "Epoch 278/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4893\n",
      "Epoch 279/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.5273\n",
      "Epoch 280/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.3271\n",
      "Epoch 281/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8800\n",
      "Epoch 282/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2398\n",
      "Epoch 283/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.1553\n",
      "Epoch 284/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.0372\n",
      "Epoch 285/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8059\n",
      "Epoch 286/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4999\n",
      "Epoch 287/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5091\n",
      "Epoch 288/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.1265\n",
      "Epoch 289/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.1946\n",
      "Epoch 290/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8713\n",
      "Epoch 291/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.9852\n",
      "Epoch 292/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6904\n",
      "Epoch 293/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8507\n",
      "Epoch 294/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4838\n",
      "Epoch 295/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4343\n",
      "Epoch 296/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.9895\n",
      "Epoch 297/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5986\n",
      "Epoch 298/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8097\n",
      "Epoch 299/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6620\n",
      "Epoch 300/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.0849\n",
      "Epoch 301/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.5680\n",
      "Epoch 302/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.6737\n",
      "Epoch 303/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2823\n",
      "Epoch 304/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.4156\n",
      "Epoch 305/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.2585\n",
      "Epoch 306/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.1328\n",
      "Epoch 307/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8350\n",
      "Epoch 308/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.7014\n",
      "Epoch 309/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6619\n",
      "Epoch 310/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.9013\n",
      "Epoch 311/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2523\n",
      "Epoch 312/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5216\n",
      "Epoch 313/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.9157\n",
      "Epoch 314/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.7667\n",
      "Epoch 315/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8976\n",
      "Epoch 316/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8691\n",
      "Epoch 317/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.9802\n",
      "Epoch 318/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.0883\n",
      "Epoch 319/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.9733\n",
      "Epoch 320/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.7697\n",
      "Epoch 321/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.0550\n",
      "Epoch 322/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4035\n",
      "Epoch 323/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.7375\n",
      "Epoch 324/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.2785\n",
      "Epoch 325/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.6555\n",
      "Epoch 326/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.2188\n",
      "Epoch 327/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8196\n",
      "Epoch 328/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.7807\n",
      "Epoch 329/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8971\n",
      "Epoch 330/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4428\n",
      "Epoch 331/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4260\n",
      "Epoch 332/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6621\n",
      "Epoch 333/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.3161\n",
      "Epoch 334/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8719\n",
      "Epoch 335/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4034\n",
      "Epoch 336/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.3768\n",
      "Epoch 337/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4134\n",
      "Epoch 338/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6514\n",
      "Epoch 339/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.6758\n",
      "Epoch 340/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8725\n",
      "Epoch 341/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.1020\n",
      "Epoch 342/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5776\n",
      "Epoch 343/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.3828\n",
      "Epoch 344/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.3648\n",
      "Epoch 345/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8786\n",
      "Epoch 346/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.9032\n",
      "Epoch 347/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6820\n",
      "Epoch 348/943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 3ms/step - loss: 5.5737\n",
      "Epoch 349/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.3438\n",
      "Epoch 350/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.4849\n",
      "Epoch 351/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.7561\n",
      "Epoch 352/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.3588\n",
      "Epoch 353/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6172\n",
      "Epoch 354/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8616\n",
      "Epoch 355/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8060\n",
      "Epoch 356/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.9940\n",
      "Epoch 357/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4537\n",
      "Epoch 358/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8647\n",
      "Epoch 359/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.7241\n",
      "Epoch 360/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.7599\n",
      "Epoch 361/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5609\n",
      "Epoch 362/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.3811\n",
      "Epoch 363/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6489\n",
      "Epoch 364/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2296\n",
      "Epoch 365/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8688\n",
      "Epoch 366/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.3047\n",
      "Epoch 367/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.7323\n",
      "Epoch 368/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2112\n",
      "Epoch 369/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4887\n",
      "Epoch 370/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.7194\n",
      "Epoch 371/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1858\n",
      "Epoch 372/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1747\n",
      "Epoch 373/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5286\n",
      "Epoch 374/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8419\n",
      "Epoch 375/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.9370\n",
      "Epoch 376/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.1969\n",
      "Epoch 377/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.7833\n",
      "Epoch 378/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.3336\n",
      "Epoch 379/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5158\n",
      "Epoch 380/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6824\n",
      "Epoch 381/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6362\n",
      "Epoch 382/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5365\n",
      "Epoch 383/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.9195\n",
      "Epoch 384/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5757\n",
      "Epoch 385/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8771\n",
      "Epoch 386/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5239\n",
      "Epoch 387/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6185\n",
      "Epoch 388/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8491\n",
      "Epoch 389/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5454\n",
      "Epoch 390/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.7700\n",
      "Epoch 391/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8571\n",
      "Epoch 392/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.7780\n",
      "Epoch 393/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5948\n",
      "Epoch 394/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.9521\n",
      "Epoch 395/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.7462\n",
      "Epoch 396/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.7007\n",
      "Epoch 397/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8635\n",
      "Epoch 398/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5462\n",
      "Epoch 399/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4822\n",
      "Epoch 400/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.3834\n",
      "Epoch 401/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5891\n",
      "Epoch 402/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.5208\n",
      "Epoch 403/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.1895\n",
      "Epoch 404/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.3713\n",
      "Epoch 405/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.0242\n",
      "Epoch 406/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.3937\n",
      "Epoch 407/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4851\n",
      "Epoch 408/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4249\n",
      "Epoch 409/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.5580\n",
      "Epoch 410/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.3778\n",
      "Epoch 411/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.5722\n",
      "Epoch 412/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.2893\n",
      "Epoch 413/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4462\n",
      "Epoch 414/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.9580\n",
      "Epoch 415/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6373\n",
      "Epoch 416/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.5301\n",
      "Epoch 417/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6195\n",
      "Epoch 418/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.8824\n",
      "Epoch 419/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2919\n",
      "Epoch 420/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.8979\n",
      "Epoch 421/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4605\n",
      "Epoch 422/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.9664\n",
      "Epoch 423/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.2695\n",
      "Epoch 424/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4283\n",
      "Epoch 425/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7847\n",
      "Epoch 426/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1850\n",
      "Epoch 427/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4848\n",
      "Epoch 428/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.3929\n",
      "Epoch 429/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 4.5204\n",
      "Epoch 430/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 4.3952\n",
      "Epoch 431/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 4.6343\n",
      "Epoch 432/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.3794\n",
      "Epoch 433/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.5412\n",
      "Epoch 434/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.4915\n",
      "Epoch 435/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.4601\n",
      "Epoch 436/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 4.0554\n",
      "Epoch 437/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 4.1609\n",
      "Epoch 438/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 4.2334\n",
      "Epoch 439/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 4.2711\n",
      "Epoch 440/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.4675\n",
      "Epoch 441/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 4.4090\n",
      "Epoch 442/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.8520\n",
      "Epoch 443/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.2386\n",
      "Epoch 444/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 4.6881\n",
      "Epoch 445/943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 1s 5ms/step - loss: 4.1268\n",
      "Epoch 446/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 4.2870\n",
      "Epoch 447/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.0341\n",
      "Epoch 448/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.2736\n",
      "Epoch 449/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 4.2107\n",
      "Epoch 450/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 4.2323\n",
      "Epoch 451/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2310\n",
      "Epoch 452/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5065\n",
      "Epoch 453/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.0954\n",
      "Epoch 454/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.2074\n",
      "Epoch 455/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.1872\n",
      "Epoch 456/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2616\n",
      "Epoch 457/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9874\n",
      "Epoch 458/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9887\n",
      "Epoch 459/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1311\n",
      "Epoch 460/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.3447\n",
      "Epoch 461/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.0500\n",
      "Epoch 462/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4272\n",
      "Epoch 463/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.9493\n",
      "Epoch 464/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.8815\n",
      "Epoch 465/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4186\n",
      "Epoch 466/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1087\n",
      "Epoch 467/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4320\n",
      "Epoch 468/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 5.2879\n",
      "Epoch 469/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1142\n",
      "Epoch 470/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1987\n",
      "Epoch 471/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9342\n",
      "Epoch 472/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2191\n",
      "Epoch 473/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1654\n",
      "Epoch 474/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.0995\n",
      "Epoch 475/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2402\n",
      "Epoch 476/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5142\n",
      "Epoch 477/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5813\n",
      "Epoch 478/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1852\n",
      "Epoch 479/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1380\n",
      "Epoch 480/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.0651\n",
      "Epoch 481/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9023\n",
      "Epoch 482/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1885\n",
      "Epoch 483/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1384\n",
      "Epoch 484/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1564\n",
      "Epoch 485/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2346\n",
      "Epoch 486/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2910\n",
      "Epoch 487/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2734\n",
      "Epoch 488/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5680\n",
      "Epoch 489/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9526\n",
      "Epoch 490/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2636\n",
      "Epoch 491/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.0586\n",
      "Epoch 492/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.3105\n",
      "Epoch 493/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.0395\n",
      "Epoch 494/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6225\n",
      "Epoch 495/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.5641\n",
      "Epoch 496/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.7891\n",
      "Epoch 497/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4055\n",
      "Epoch 498/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2850\n",
      "Epoch 499/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.3498\n",
      "Epoch 500/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9250\n",
      "Epoch 501/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4244\n",
      "Epoch 502/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4124\n",
      "Epoch 503/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.0515\n",
      "Epoch 504/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.8963\n",
      "Epoch 505/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9528\n",
      "Epoch 506/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9305\n",
      "Epoch 507/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.0111\n",
      "Epoch 508/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.6268\n",
      "Epoch 509/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.0224\n",
      "Epoch 510/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.7197\n",
      "Epoch 511/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9463\n",
      "Epoch 512/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4144\n",
      "Epoch 513/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1725\n",
      "Epoch 514/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2152\n",
      "Epoch 515/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.4906\n",
      "Epoch 516/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9270\n",
      "Epoch 517/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.0097\n",
      "Epoch 518/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.7126\n",
      "Epoch 519/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2243\n",
      "Epoch 520/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1930\n",
      "Epoch 521/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9054\n",
      "Epoch 522/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4626\n",
      "Epoch 523/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.2496\n",
      "Epoch 524/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9360\n",
      "Epoch 525/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9763\n",
      "Epoch 526/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9947\n",
      "Epoch 527/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.4116\n",
      "Epoch 528/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1000\n",
      "Epoch 529/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.5171\n",
      "Epoch 530/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.7457\n",
      "Epoch 531/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.6094\n",
      "Epoch 532/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.6442\n",
      "Epoch 533/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.5104\n",
      "Epoch 534/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 4.1049\n",
      "Epoch 535/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9615\n",
      "Epoch 536/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.7827\n",
      "Epoch 537/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.9586\n",
      "Epoch 538/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 4.0244\n",
      "Epoch 539/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.8425\n",
      "Epoch 540/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.7083\n",
      "Epoch 541/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.6916\n",
      "Epoch 542/943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 1s 5ms/step - loss: 4.3135\n",
      "Epoch 543/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6282\n",
      "Epoch 544/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 4.1715\n",
      "Epoch 545/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.2000\n",
      "Epoch 546/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.9118\n",
      "Epoch 547/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.9345\n",
      "Epoch 548/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6415\n",
      "Epoch 549/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.4784\n",
      "Epoch 550/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.5793\n",
      "Epoch 551/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.7400\n",
      "Epoch 552/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.5069\n",
      "Epoch 553/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.6928\n",
      "Epoch 554/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.6680\n",
      "Epoch 555/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.9131\n",
      "Epoch 556/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.7429\n",
      "Epoch 557/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.6133\n",
      "Epoch 558/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 4.0584\n",
      "Epoch 559/943\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 4.0240\n",
      "Epoch 560/943\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 3.5419\n",
      "Epoch 561/943\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 4.7286\n",
      "Epoch 562/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 4.2823\n",
      "Epoch 563/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 4.2160\n",
      "Epoch 564/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.9799\n",
      "Epoch 565/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.3058\n",
      "Epoch 566/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6130\n",
      "Epoch 567/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.6303\n",
      "Epoch 568/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.7534\n",
      "Epoch 569/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.7368\n",
      "Epoch 570/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.5804\n",
      "Epoch 571/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6842\n",
      "Epoch 572/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.1812\n",
      "Epoch 573/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.6287\n",
      "Epoch 574/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.9196\n",
      "Epoch 575/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.9529\n",
      "Epoch 576/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.7211\n",
      "Epoch 577/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7590\n",
      "Epoch 578/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.8274\n",
      "Epoch 579/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.1040\n",
      "Epoch 580/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 4.1188\n",
      "Epoch 581/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.7408\n",
      "Epoch 582/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.4945\n",
      "Epoch 583/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.0825\n",
      "Epoch 584/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.9494\n",
      "Epoch 585/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.3748\n",
      "Epoch 586/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.8423\n",
      "Epoch 587/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.3068\n",
      "Epoch 588/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.8133\n",
      "Epoch 589/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.8711\n",
      "Epoch 590/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.7815\n",
      "Epoch 591/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.4748\n",
      "Epoch 592/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.1431\n",
      "Epoch 593/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.9216\n",
      "Epoch 594/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.0743\n",
      "Epoch 595/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.1069\n",
      "Epoch 596/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7864\n",
      "Epoch 597/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7481\n",
      "Epoch 598/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.0100\n",
      "Epoch 599/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7394\n",
      "Epoch 600/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.9231\n",
      "Epoch 601/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.3486\n",
      "Epoch 602/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.0776\n",
      "Epoch 603/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.8322\n",
      "Epoch 604/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.4954\n",
      "Epoch 605/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7208\n",
      "Epoch 606/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7232\n",
      "Epoch 607/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7894\n",
      "Epoch 608/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.9829\n",
      "Epoch 609/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.8019\n",
      "Epoch 610/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.9258\n",
      "Epoch 611/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6302\n",
      "Epoch 612/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.3487\n",
      "Epoch 613/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.3086\n",
      "Epoch 614/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 4.0213\n",
      "Epoch 615/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.7358\n",
      "Epoch 616/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.6899\n",
      "Epoch 617/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6297\n",
      "Epoch 618/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.8130\n",
      "Epoch 619/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4131\n",
      "Epoch 620/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7211\n",
      "Epoch 621/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.0690\n",
      "Epoch 622/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.1635\n",
      "Epoch 623/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.0104\n",
      "Epoch 624/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.1880\n",
      "Epoch 625/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 2.9778\n",
      "Epoch 626/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.9018\n",
      "Epoch 627/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.4081\n",
      "Epoch 628/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.5969\n",
      "Epoch 629/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.7085\n",
      "Epoch 630/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.4713\n",
      "Epoch 631/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.3924\n",
      "Epoch 632/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6337\n",
      "Epoch 633/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.5349\n",
      "Epoch 634/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.8896\n",
      "Epoch 635/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7628\n",
      "Epoch 636/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.4601\n",
      "Epoch 637/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.3163\n",
      "Epoch 638/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.8115\n",
      "Epoch 639/943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 1s 4ms/step - loss: 3.3785\n",
      "Epoch 640/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.3958\n",
      "Epoch 641/943\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 3.2493\n",
      "Epoch 642/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.5266\n",
      "Epoch 643/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.6730\n",
      "Epoch 644/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.3151\n",
      "Epoch 645/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.6155\n",
      "Epoch 646/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.2052\n",
      "Epoch 647/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7515\n",
      "Epoch 648/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.7273\n",
      "Epoch 649/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.5805\n",
      "Epoch 650/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.8931\n",
      "Epoch 651/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.3062\n",
      "Epoch 652/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.1347\n",
      "Epoch 653/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 4.9257\n",
      "Epoch 654/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6670\n",
      "Epoch 655/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7858\n",
      "Epoch 656/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7859\n",
      "Epoch 657/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.2528\n",
      "Epoch 658/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.6727\n",
      "Epoch 659/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6584\n",
      "Epoch 660/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.8839\n",
      "Epoch 661/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6538\n",
      "Epoch 662/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6031\n",
      "Epoch 663/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.5687\n",
      "Epoch 664/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.4167\n",
      "Epoch 665/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.5808\n",
      "Epoch 666/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6033\n",
      "Epoch 667/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7609\n",
      "Epoch 668/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.8223\n",
      "Epoch 669/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.2268\n",
      "Epoch 670/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.7170\n",
      "Epoch 671/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.7596\n",
      "Epoch 672/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.6058\n",
      "Epoch 673/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.7146\n",
      "Epoch 674/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6861\n",
      "Epoch 675/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6891\n",
      "Epoch 676/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.9689\n",
      "Epoch 677/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.9047\n",
      "Epoch 678/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7889\n",
      "Epoch 679/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.6235\n",
      "Epoch 680/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.3784\n",
      "Epoch 681/943\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 3.6554\n",
      "Epoch 682/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.4459\n",
      "Epoch 683/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.4463\n",
      "Epoch 684/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.5891\n",
      "Epoch 685/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.9807\n",
      "Epoch 686/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.3940\n",
      "Epoch 687/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.9003\n",
      "Epoch 688/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.3771\n",
      "Epoch 689/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.9234\n",
      "Epoch 690/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.5476\n",
      "Epoch 691/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.9956\n",
      "Epoch 692/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.6600\n",
      "Epoch 693/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 4.0335\n",
      "Epoch 694/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.9005\n",
      "Epoch 695/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.0957\n",
      "Epoch 696/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.6053\n",
      "Epoch 697/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 4.1750\n",
      "Epoch 698/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.4737\n",
      "Epoch 699/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.7123\n",
      "Epoch 700/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.4658\n",
      "Epoch 701/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.7720\n",
      "Epoch 702/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.4214\n",
      "Epoch 703/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.4591\n",
      "Epoch 704/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.5182\n",
      "Epoch 705/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.6287\n",
      "Epoch 706/943\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 3.4400\n",
      "Epoch 707/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 4.1276\n",
      "Epoch 708/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.5583\n",
      "Epoch 709/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.5425\n",
      "Epoch 710/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.8053\n",
      "Epoch 711/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.4667\n",
      "Epoch 712/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.4193\n",
      "Epoch 713/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 4.0275\n",
      "Epoch 714/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.4767\n",
      "Epoch 715/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.4661\n",
      "Epoch 716/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.5357\n",
      "Epoch 717/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.8053\n",
      "Epoch 718/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.8060\n",
      "Epoch 719/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.0858\n",
      "Epoch 720/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6083\n",
      "Epoch 721/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 4.1788\n",
      "Epoch 722/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 4.0034\n",
      "Epoch 723/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.5750\n",
      "Epoch 724/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.9421\n",
      "Epoch 725/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.7282\n",
      "Epoch 726/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6535\n",
      "Epoch 727/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.9378\n",
      "Epoch 728/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.5997\n",
      "Epoch 729/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 4.1941\n",
      "Epoch 730/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.4436\n",
      "Epoch 731/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.7077\n",
      "Epoch 732/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.5306\n",
      "Epoch 733/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.4136\n",
      "Epoch 734/943\n",
      "132/132 [==============================] - ETA: 0s - loss: 3.514 - 0s 3ms/step - loss: 3.3525\n",
      "Epoch 735/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.5158\n",
      "Epoch 736/943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 1s 7ms/step - loss: 3.6938\n",
      "Epoch 737/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.4923\n",
      "Epoch 738/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.8271\n",
      "Epoch 739/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.0025\n",
      "Epoch 740/943\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 3.4607\n",
      "Epoch 741/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.4460\n",
      "Epoch 742/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.1051\n",
      "Epoch 743/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.2004\n",
      "Epoch 744/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.0754\n",
      "Epoch 745/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.4417\n",
      "Epoch 746/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.4355\n",
      "Epoch 747/943\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 3.5292\n",
      "Epoch 748/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.2130\n",
      "Epoch 749/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.3101\n",
      "Epoch 750/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.2443\n",
      "Epoch 751/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.7830\n",
      "Epoch 752/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.5063\n",
      "Epoch 753/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6418\n",
      "Epoch 754/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.3672\n",
      "Epoch 755/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.7025\n",
      "Epoch 756/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.5097\n",
      "Epoch 757/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.5143\n",
      "Epoch 758/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.9762\n",
      "Epoch 759/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6465\n",
      "Epoch 760/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.9501\n",
      "Epoch 761/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.5955\n",
      "Epoch 762/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.4099\n",
      "Epoch 763/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6966\n",
      "Epoch 764/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6412\n",
      "Epoch 765/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.0041\n",
      "Epoch 766/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.2185\n",
      "Epoch 767/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.7104\n",
      "Epoch 768/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.4613\n",
      "Epoch 769/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.4662\n",
      "Epoch 770/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.5770\n",
      "Epoch 771/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.4799\n",
      "Epoch 772/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.3196\n",
      "Epoch 773/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 2.9714\n",
      "Epoch 774/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6037\n",
      "Epoch 775/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.4000\n",
      "Epoch 776/943\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 3.2276\n",
      "Epoch 777/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.1948\n",
      "Epoch 778/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.5825\n",
      "Epoch 779/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.3385\n",
      "Epoch 780/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.4740\n",
      "Epoch 781/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.2596\n",
      "Epoch 782/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.7585\n",
      "Epoch 783/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.0937\n",
      "Epoch 784/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.3085\n",
      "Epoch 785/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.4935\n",
      "Epoch 786/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.2059\n",
      "Epoch 787/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.8471\n",
      "Epoch 788/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.5712\n",
      "Epoch 789/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.3059\n",
      "Epoch 790/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.2778\n",
      "Epoch 791/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.3010\n",
      "Epoch 792/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.3569\n",
      "Epoch 793/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.2577\n",
      "Epoch 794/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.8494\n",
      "Epoch 795/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.9723\n",
      "Epoch 796/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.2192\n",
      "Epoch 797/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.0045\n",
      "Epoch 798/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.5606\n",
      "Epoch 799/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6845\n",
      "Epoch 800/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.7282\n",
      "Epoch 801/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.3145\n",
      "Epoch 802/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.4618\n",
      "Epoch 803/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.7092\n",
      "Epoch 804/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.1928\n",
      "Epoch 805/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.4783\n",
      "Epoch 806/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.8644\n",
      "Epoch 807/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.3047\n",
      "Epoch 808/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.4676\n",
      "Epoch 809/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.5823\n",
      "Epoch 810/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.8957\n",
      "Epoch 811/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.3611\n",
      "Epoch 812/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.8676\n",
      "Epoch 813/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.8593\n",
      "Epoch 814/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.5316\n",
      "Epoch 815/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.4351\n",
      "Epoch 816/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.8336\n",
      "Epoch 817/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6550\n",
      "Epoch 818/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.0258\n",
      "Epoch 819/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.2971\n",
      "Epoch 820/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.1813\n",
      "Epoch 821/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.4418\n",
      "Epoch 822/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.1501\n",
      "Epoch 823/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.1716\n",
      "Epoch 824/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.1393\n",
      "Epoch 825/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.3123\n",
      "Epoch 826/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.2587\n",
      "Epoch 827/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.2752\n",
      "Epoch 828/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.0624\n",
      "Epoch 829/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.1791\n",
      "Epoch 830/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.7307\n",
      "Epoch 831/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.8707\n",
      "Epoch 832/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.8833\n",
      "Epoch 833/943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 1s 4ms/step - loss: 3.3568\n",
      "Epoch 834/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.0612\n",
      "Epoch 835/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.2181\n",
      "Epoch 836/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.0255\n",
      "Epoch 837/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.5435\n",
      "Epoch 838/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.9347\n",
      "Epoch 839/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.9479\n",
      "Epoch 840/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 2.8439\n",
      "Epoch 841/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.4196\n",
      "Epoch 842/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.0651\n",
      "Epoch 843/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.5881\n",
      "Epoch 844/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.9959\n",
      "Epoch 845/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.6563\n",
      "Epoch 846/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.9889\n",
      "Epoch 847/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.0325\n",
      "Epoch 848/943\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 3.1979\n",
      "Epoch 849/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.3062\n",
      "Epoch 850/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.7085\n",
      "Epoch 851/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.2101\n",
      "Epoch 852/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.4074\n",
      "Epoch 853/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 2.9373\n",
      "Epoch 854/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.1570\n",
      "Epoch 855/943\n",
      "132/132 [==============================] - ETA: 0s - loss: 2.764 - 0s 4ms/step - loss: 2.7679\n",
      "Epoch 856/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.0321\n",
      "Epoch 857/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.5030\n",
      "Epoch 858/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 2.6547\n",
      "Epoch 859/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.3315\n",
      "Epoch 860/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 2.9794\n",
      "Epoch 861/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 2.9163\n",
      "Epoch 862/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 2.7112\n",
      "Epoch 863/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.3821\n",
      "Epoch 864/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.2680\n",
      "Epoch 865/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 3.3191\n",
      "Epoch 866/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.8447\n",
      "Epoch 867/943\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 3.6060\n",
      "Epoch 868/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6940\n",
      "Epoch 869/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.3167\n",
      "Epoch 870/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.3994\n",
      "Epoch 871/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.5858\n",
      "Epoch 872/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.5676\n",
      "Epoch 873/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.4942\n",
      "Epoch 874/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.5440\n",
      "Epoch 875/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.2868\n",
      "Epoch 876/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.3878\n",
      "Epoch 877/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 4.4692\n",
      "Epoch 878/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.3805\n",
      "Epoch 879/943\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 3.2584\n",
      "Epoch 880/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.2239\n",
      "Epoch 881/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.6392\n",
      "Epoch 882/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.8828\n",
      "Epoch 883/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.7334\n",
      "Epoch 884/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.9849\n",
      "Epoch 885/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.4689\n",
      "Epoch 886/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.6370\n",
      "Epoch 887/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.0319\n",
      "Epoch 888/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.2578\n",
      "Epoch 889/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.2830\n",
      "Epoch 890/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.3725\n",
      "Epoch 891/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.2062\n",
      "Epoch 892/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.0913\n",
      "Epoch 893/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.1291\n",
      "Epoch 894/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.1913\n",
      "Epoch 895/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.1903\n",
      "Epoch 896/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.0062\n",
      "Epoch 897/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.2382\n",
      "Epoch 898/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.3588\n",
      "Epoch 899/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.8324\n",
      "Epoch 900/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.5550\n",
      "Epoch 901/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.1604\n",
      "Epoch 902/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 2.8654\n",
      "Epoch 903/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.3784\n",
      "Epoch 904/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.0970\n",
      "Epoch 905/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 2.8749\n",
      "Epoch 906/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.3236\n",
      "Epoch 907/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.1115\n",
      "Epoch 908/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.1705\n",
      "Epoch 909/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 2.9280\n",
      "Epoch 910/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 2.8913\n",
      "Epoch 911/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.1586\n",
      "Epoch 912/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.6049\n",
      "Epoch 913/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.0754\n",
      "Epoch 914/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.1792\n",
      "Epoch 915/943\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 2.6322\n",
      "Epoch 916/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.9493\n",
      "Epoch 917/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.9991\n",
      "Epoch 918/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.9992\n",
      "Epoch 919/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.7917\n",
      "Epoch 920/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.4174\n",
      "Epoch 921/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 2.7617\n",
      "Epoch 922/943\n",
      "132/132 [==============================] - ETA: 0s - loss: 3.356 - 0s 3ms/step - loss: 3.3315\n",
      "Epoch 923/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.2196\n",
      "Epoch 924/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.5539\n",
      "Epoch 925/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.0177\n",
      "Epoch 926/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.9288\n",
      "Epoch 927/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.9314\n",
      "Epoch 928/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.5123\n",
      "Epoch 929/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.1659\n",
      "Epoch 930/943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 3ms/step - loss: 3.1359\n",
      "Epoch 931/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 3.3075\n",
      "Epoch 932/943\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 3.0141\n",
      "Epoch 933/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.0493\n",
      "Epoch 934/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 3.0851\n",
      "Epoch 935/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.9510\n",
      "Epoch 936/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.9250\n",
      "Epoch 937/943\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.8253\n",
      "Epoch 938/943\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.8128\n",
      "Epoch 939/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 2.9787\n",
      "Epoch 940/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.1189\n",
      "Epoch 941/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 3.3959\n",
      "Epoch 942/943\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 2.8851\n",
      "Epoch 943/943\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.5074\n",
      "60/60 [==============================] - 1s 15ms/step\n",
      "Epoch 1/294\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 72.1250\n",
      "Epoch 2/294\n",
      "132/132 [==============================] - 0s 333us/step - loss: 69.8107\n",
      "Epoch 3/294\n",
      "132/132 [==============================] - 0s 364us/step - loss: 67.8864\n",
      "Epoch 4/294\n",
      "132/132 [==============================] - ETA: 0s - loss: 66.39 - 0s 1ms/step - loss: 66.5423\n",
      "Epoch 5/294\n",
      "132/132 [==============================] - 0s 977us/step - loss: 65.1274\n",
      "Epoch 6/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 63.3088\n",
      "Epoch 7/294\n",
      "132/132 [==============================] - 0s 523us/step - loss: 61.7567\n",
      "Epoch 8/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 59.9368\n",
      "Epoch 9/294\n",
      "132/132 [==============================] - 0s 955us/step - loss: 57.0570\n",
      "Epoch 10/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 54.4205\n",
      "Epoch 11/294\n",
      "132/132 [==============================] - 0s 371us/step - loss: 51.1399\n",
      "Epoch 12/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 47.0255\n",
      "Epoch 13/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 41.2238\n",
      "Epoch 14/294\n",
      "132/132 [==============================] - 0s 811us/step - loss: 33.4037\n",
      "Epoch 15/294\n",
      "132/132 [==============================] - 0s 886us/step - loss: 24.0529\n",
      "Epoch 16/294\n",
      "132/132 [==============================] - 0s 394us/step - loss: 17.6415\n",
      "Epoch 17/294\n",
      "132/132 [==============================] - 0s 902us/step - loss: 17.0478\n",
      "Epoch 18/294\n",
      "132/132 [==============================] - 0s 667us/step - loss: 21.9896\n",
      "Epoch 19/294\n",
      "132/132 [==============================] - 0s 803us/step - loss: 19.0577\n",
      "Epoch 20/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 18.5310\n",
      "Epoch 21/294\n",
      "132/132 [==============================] - 0s 326us/step - loss: 16.1632\n",
      "Epoch 22/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 15.8057\n",
      "Epoch 23/294\n",
      "132/132 [==============================] - 0s 386us/step - loss: 16.6162\n",
      "Epoch 24/294\n",
      "132/132 [==============================] - 0s 939us/step - loss: 18.4235\n",
      "Epoch 25/294\n",
      "132/132 [==============================] - 0s 386us/step - loss: 18.2684\n",
      "Epoch 26/294\n",
      "132/132 [==============================] - 0s 879us/step - loss: 16.5794\n",
      "Epoch 27/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 16.9607\n",
      "Epoch 28/294\n",
      "132/132 [==============================] - 0s 955us/step - loss: 14.5966\n",
      "Epoch 29/294\n",
      "132/132 [==============================] - 0s 326us/step - loss: 15.7911\n",
      "Epoch 30/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 15.7103\n",
      "Epoch 31/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 15.7930\n",
      "Epoch 32/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 15.4548\n",
      "Epoch 33/294\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 13.2513\n",
      "Epoch 34/294\n",
      "132/132 [==============================] - 0s 636us/step - loss: 15.3279\n",
      "Epoch 35/294\n",
      "132/132 [==============================] - 0s 659us/step - loss: 16.4759\n",
      "Epoch 36/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 14.3341\n",
      "Epoch 37/294\n",
      "132/132 [==============================] - 0s 758us/step - loss: 15.7205\n",
      "Epoch 38/294\n",
      "132/132 [==============================] - 0s 318us/step - loss: 14.7357\n",
      "Epoch 39/294\n",
      "132/132 [==============================] - 0s 652us/step - loss: 13.4822\n",
      "Epoch 40/294\n",
      "132/132 [==============================] - 0s 727us/step - loss: 15.2277\n",
      "Epoch 41/294\n",
      "132/132 [==============================] - 0s 356us/step - loss: 14.7795\n",
      "Epoch 42/294\n",
      "132/132 [==============================] - 0s 371us/step - loss: 15.3292\n",
      "Epoch 43/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 13.1223\n",
      "Epoch 44/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 14.1654\n",
      "Epoch 45/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 13.8449\n",
      "Epoch 46/294\n",
      "132/132 [==============================] - 0s 409us/step - loss: 16.9888\n",
      "Epoch 47/294\n",
      "132/132 [==============================] - 0s 318us/step - loss: 12.7812\n",
      "Epoch 48/294\n",
      "132/132 [==============================] - 0s 447us/step - loss: 12.4760\n",
      "Epoch 49/294\n",
      "132/132 [==============================] - 0s 470us/step - loss: 13.2636\n",
      "Epoch 50/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 13.1461\n",
      "Epoch 51/294\n",
      "132/132 [==============================] - 0s 409us/step - loss: 12.9298\n",
      "Epoch 52/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.3091\n",
      "Epoch 53/294\n",
      "132/132 [==============================] - 0s 553us/step - loss: 11.7054\n",
      "Epoch 54/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 13.0062\n",
      "Epoch 55/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 12.5178\n",
      "Epoch 56/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 12.6920\n",
      "Epoch 57/294\n",
      "132/132 [==============================] - 0s 538us/step - loss: 12.2788\n",
      "Epoch 58/294\n",
      "132/132 [==============================] - 0s 432us/step - loss: 12.9217\n",
      "Epoch 59/294\n",
      "132/132 [==============================] - 0s 424us/step - loss: 12.8326\n",
      "Epoch 60/294\n",
      "132/132 [==============================] - 0s 386us/step - loss: 12.1144\n",
      "Epoch 61/294\n",
      "132/132 [==============================] - 0s 409us/step - loss: 11.7106\n",
      "Epoch 62/294\n",
      "132/132 [==============================] - 0s 394us/step - loss: 11.5777\n",
      "Epoch 63/294\n",
      "132/132 [==============================] - 0s 386us/step - loss: 11.0200\n",
      "Epoch 64/294\n",
      "132/132 [==============================] - 0s 470us/step - loss: 12.5357\n",
      "Epoch 65/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 12.0491\n",
      "Epoch 66/294\n",
      "132/132 [==============================] - 0s 394us/step - loss: 11.4886\n",
      "Epoch 67/294\n",
      "132/132 [==============================] - 0s 409us/step - loss: 12.7846\n",
      "Epoch 68/294\n",
      "132/132 [==============================] - 0s 462us/step - loss: 12.3341\n",
      "Epoch 69/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 12.8727\n",
      "Epoch 70/294\n",
      "132/132 [==============================] - 0s 341us/step - loss: 11.3608\n",
      "Epoch 71/294\n",
      "132/132 [==============================] - 0s 394us/step - loss: 12.1755\n",
      "Epoch 72/294\n",
      "132/132 [==============================] - 0s 386us/step - loss: 11.7679\n",
      "Epoch 73/294\n",
      "132/132 [==============================] - 0s 341us/step - loss: 11.9402\n",
      "Epoch 74/294\n",
      "132/132 [==============================] - 0s 409us/step - loss: 11.0961\n",
      "Epoch 75/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 12.0168\n",
      "Epoch 76/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 13.2451\n",
      "Epoch 77/294\n",
      "132/132 [==============================] - 0s 386us/step - loss: 12.7911\n",
      "Epoch 78/294\n",
      "132/132 [==============================] - 0s 386us/step - loss: 11.2446\n",
      "Epoch 79/294\n",
      "132/132 [==============================] - 0s 394us/step - loss: 11.1511\n",
      "Epoch 80/294\n",
      "132/132 [==============================] - 0s 841us/step - loss: 10.8076\n",
      "Epoch 81/294\n",
      "132/132 [==============================] - 0s 636us/step - loss: 10.7847\n",
      "Epoch 82/294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 417us/step - loss: 11.0204\n",
      "Epoch 83/294\n",
      "132/132 [==============================] - 0s 371us/step - loss: 9.7883\n",
      "Epoch 84/294\n",
      "132/132 [==============================] - 0s 386us/step - loss: 11.2658\n",
      "Epoch 85/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 10.4137\n",
      "Epoch 86/294\n",
      "132/132 [==============================] - 0s 326us/step - loss: 11.1984\n",
      "Epoch 87/294\n",
      "132/132 [==============================] - 0s 402us/step - loss: 11.0940\n",
      "Epoch 88/294\n",
      "132/132 [==============================] - 0s 394us/step - loss: 10.0851\n",
      "Epoch 89/294\n",
      "132/132 [==============================] - 0s 341us/step - loss: 11.0156\n",
      "Epoch 90/294\n",
      "132/132 [==============================] - 0s 386us/step - loss: 10.9313\n",
      "Epoch 91/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 11.1208\n",
      "Epoch 92/294\n",
      "132/132 [==============================] - 0s 349us/step - loss: 10.6473\n",
      "Epoch 93/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 11.3892\n",
      "Epoch 94/294\n",
      "132/132 [==============================] - 0s 424us/step - loss: 9.4662\n",
      "Epoch 95/294\n",
      "132/132 [==============================] - 0s 326us/step - loss: 9.0122\n",
      "Epoch 96/294\n",
      "132/132 [==============================] - 0s 894us/step - loss: 10.2708\n",
      "Epoch 97/294\n",
      "132/132 [==============================] - 0s 667us/step - loss: 9.8658\n",
      "Epoch 98/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.0470\n",
      "Epoch 99/294\n",
      "132/132 [==============================] - 0s 750us/step - loss: 10.4145\n",
      "Epoch 100/294\n",
      "132/132 [==============================] - 0s 697us/step - loss: 11.0612\n",
      "Epoch 101/294\n",
      "132/132 [==============================] - 0s 356us/step - loss: 9.7499\n",
      "Epoch 102/294\n",
      "132/132 [==============================] - 0s 402us/step - loss: 9.8225\n",
      "Epoch 103/294\n",
      "132/132 [==============================] - 0s 462us/step - loss: 10.7949\n",
      "Epoch 104/294\n",
      "132/132 [==============================] - 0s 455us/step - loss: 10.9491\n",
      "Epoch 105/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.9138\n",
      "Epoch 106/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.0217\n",
      "Epoch 107/294\n",
      "132/132 [==============================] - 0s 750us/step - loss: 11.3560\n",
      "Epoch 108/294\n",
      "132/132 [==============================] - 0s 682us/step - loss: 10.3406\n",
      "Epoch 109/294\n",
      "132/132 [==============================] - 0s 326us/step - loss: 9.9997\n",
      "Epoch 110/294\n",
      "132/132 [==============================] - 0s 523us/step - loss: 10.9633\n",
      "Epoch 111/294\n",
      "132/132 [==============================] - 0s 432us/step - loss: 9.8669\n",
      "Epoch 112/294\n",
      "132/132 [==============================] - 0s 470us/step - loss: 10.2944\n",
      "Epoch 113/294\n",
      "132/132 [==============================] - 0s 538us/step - loss: 10.0415\n",
      "Epoch 114/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.3461\n",
      "Epoch 115/294\n",
      "132/132 [==============================] - 0s 402us/step - loss: 9.0795\n",
      "Epoch 116/294\n",
      "132/132 [==============================] - 0s 333us/step - loss: 10.9979\n",
      "Epoch 117/294\n",
      "132/132 [==============================] - 0s 599us/step - loss: 10.8079\n",
      "Epoch 118/294\n",
      "132/132 [==============================] - 0s 386us/step - loss: 10.1694\n",
      "Epoch 119/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.7115\n",
      "Epoch 120/294\n",
      "132/132 [==============================] - 0s 992us/step - loss: 10.4049\n",
      "Epoch 121/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.6739\n",
      "Epoch 122/294\n",
      "132/132 [==============================] - 0s 371us/step - loss: 9.0954\n",
      "Epoch 123/294\n",
      "132/132 [==============================] - 0s 811us/step - loss: 10.0254\n",
      "Epoch 124/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.3284\n",
      "Epoch 125/294\n",
      "132/132 [==============================] - 0s 977us/step - loss: 10.2813\n",
      "Epoch 126/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.6778\n",
      "Epoch 127/294\n",
      "132/132 [==============================] - 0s 417us/step - loss: 11.6344\n",
      "Epoch 128/294\n",
      "132/132 [==============================] - 0s 962us/step - loss: 9.4604\n",
      "Epoch 129/294\n",
      "132/132 [==============================] - 0s 879us/step - loss: 12.4630\n",
      "Epoch 130/294\n",
      "132/132 [==============================] - 0s 538us/step - loss: 13.5002\n",
      "Epoch 131/294\n",
      "132/132 [==============================] - 0s 341us/step - loss: 10.8688\n",
      "Epoch 132/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.0568\n",
      "Epoch 133/294\n",
      "132/132 [==============================] - 0s 508us/step - loss: 11.0349\n",
      "Epoch 134/294\n",
      "132/132 [==============================] - 0s 682us/step - loss: 11.3274\n",
      "Epoch 135/294\n",
      "132/132 [==============================] - 0s 409us/step - loss: 10.1635\n",
      "Epoch 136/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 10.5802\n",
      "Epoch 137/294\n",
      "132/132 [==============================] - 0s 485us/step - loss: 11.5637\n",
      "Epoch 138/294\n",
      "132/132 [==============================] - 0s 492us/step - loss: 10.2877\n",
      "Epoch 139/294\n",
      "132/132 [==============================] - 0s 462us/step - loss: 10.0135\n",
      "Epoch 140/294\n",
      "132/132 [==============================] - 0s 402us/step - loss: 10.7641\n",
      "Epoch 141/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.5370\n",
      "Epoch 142/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.4948\n",
      "Epoch 143/294\n",
      "132/132 [==============================] - 0s 530us/step - loss: 9.8418\n",
      "Epoch 144/294\n",
      "132/132 [==============================] - 0s 333us/step - loss: 11.0666\n",
      "Epoch 145/294\n",
      "132/132 [==============================] - 0s 765us/step - loss: 9.0656\n",
      "Epoch 146/294\n",
      "132/132 [==============================] - 0s 803us/step - loss: 9.3190\n",
      "Epoch 147/294\n",
      "132/132 [==============================] - 0s 477us/step - loss: 10.7907\n",
      "Epoch 148/294\n",
      "132/132 [==============================] - 0s 349us/step - loss: 10.5987\n",
      "Epoch 149/294\n",
      "132/132 [==============================] - 0s 379us/step - loss: 9.4400\n",
      "Epoch 150/294\n",
      "132/132 [==============================] - 0s 727us/step - loss: 9.1192\n",
      "Epoch 151/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.6505\n",
      "Epoch 152/294\n",
      "132/132 [==============================] - 0s 689us/step - loss: 10.0728\n",
      "Epoch 153/294\n",
      "132/132 [==============================] - 0s 402us/step - loss: 9.5361\n",
      "Epoch 154/294\n",
      "132/132 [==============================] - 0s 992us/step - loss: 9.8790\n",
      "Epoch 155/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 8.4822\n",
      "Epoch 156/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.5743\n",
      "Epoch 157/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 11.6487\n",
      "Epoch 158/294\n",
      "132/132 [==============================] - 0s 402us/step - loss: 10.4437\n",
      "Epoch 159/294\n",
      "132/132 [==============================] - 0s 599us/step - loss: 9.1715\n",
      "Epoch 160/294\n",
      "132/132 [==============================] - 0s 758us/step - loss: 13.5026\n",
      "Epoch 161/294\n",
      "132/132 [==============================] - 0s 811us/step - loss: 13.9820\n",
      "Epoch 162/294\n",
      "132/132 [==============================] - 0s 386us/step - loss: 12.1819\n",
      "Epoch 163/294\n",
      "132/132 [==============================] - 0s 515us/step - loss: 9.3667\n",
      "Epoch 164/294\n",
      "132/132 [==============================] - 0s 644us/step - loss: 11.2351\n",
      "Epoch 165/294\n",
      "132/132 [==============================] - 0s 606us/step - loss: 13.6917\n",
      "Epoch 166/294\n",
      "132/132 [==============================] - 0s 326us/step - loss: 14.5218\n",
      "Epoch 167/294\n",
      "132/132 [==============================] - 0s 826us/step - loss: 11.1498\n",
      "Epoch 168/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.6867\n",
      "Epoch 169/294\n",
      "132/132 [==============================] - 0s 841us/step - loss: 13.2983\n",
      "Epoch 170/294\n",
      "132/132 [==============================] - 0s 826us/step - loss: 13.6029\n",
      "Epoch 171/294\n",
      "132/132 [==============================] - 0s 636us/step - loss: 12.2439\n",
      "Epoch 172/294\n",
      "132/132 [==============================] - 0s 795us/step - loss: 9.9824\n",
      "Epoch 173/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.8467\n",
      "Epoch 174/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.4289\n",
      "Epoch 175/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.0848\n",
      "Epoch 176/294\n",
      "132/132 [==============================] - 0s 364us/step - loss: 9.8050\n",
      "Epoch 177/294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 727us/step - loss: 10.9843\n",
      "Epoch 178/294\n",
      "132/132 [==============================] - 0s 909us/step - loss: 12.4613\n",
      "Epoch 179/294\n",
      "132/132 [==============================] - 0s 500us/step - loss: 11.9736\n",
      "Epoch 180/294\n",
      "132/132 [==============================] - 0s 356us/step - loss: 10.7055\n",
      "Epoch 181/294\n",
      "132/132 [==============================] - 0s 470us/step - loss: 8.9707\n",
      "Epoch 182/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.4703\n",
      "Epoch 183/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.9837\n",
      "Epoch 184/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.0091\n",
      "Epoch 185/294\n",
      "132/132 [==============================] - 0s 356us/step - loss: 9.4884\n",
      "Epoch 186/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.0175\n",
      "Epoch 187/294\n",
      "132/132 [==============================] - 0s 932us/step - loss: 8.6149\n",
      "Epoch 188/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.4137\n",
      "Epoch 189/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.2343\n",
      "Epoch 190/294\n",
      "132/132 [==============================] - 0s 652us/step - loss: 10.0077\n",
      "Epoch 191/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.9418\n",
      "Epoch 192/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.0747\n",
      "Epoch 193/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.5093\n",
      "Epoch 194/294\n",
      "132/132 [==============================] - 0s 902us/step - loss: 9.5898\n",
      "Epoch 195/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.9073\n",
      "Epoch 196/294\n",
      "132/132 [==============================] - 0s 909us/step - loss: 10.0463\n",
      "Epoch 197/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.9795\n",
      "Epoch 198/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.2805\n",
      "Epoch 199/294\n",
      "132/132 [==============================] - 0s 333us/step - loss: 9.6007\n",
      "Epoch 200/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.6144\n",
      "Epoch 201/294\n",
      "132/132 [==============================] - 0s 811us/step - loss: 10.1935\n",
      "Epoch 202/294\n",
      "132/132 [==============================] - 0s 879us/step - loss: 9.0517\n",
      "Epoch 203/294\n",
      "132/132 [==============================] - 0s 364us/step - loss: 10.1175\n",
      "Epoch 204/294\n",
      "132/132 [==============================] - 0s 864us/step - loss: 9.5823\n",
      "Epoch 205/294\n",
      "132/132 [==============================] - 0s 833us/step - loss: 8.9644\n",
      "Epoch 206/294\n",
      "132/132 [==============================] - 0s 917us/step - loss: 9.4185\n",
      "Epoch 207/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.4918\n",
      "Epoch 208/294\n",
      "132/132 [==============================] - 0s 439us/step - loss: 10.8928\n",
      "Epoch 209/294\n",
      "132/132 [==============================] - 0s 652us/step - loss: 9.8546\n",
      "Epoch 210/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.1674\n",
      "Epoch 211/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.6968\n",
      "Epoch 212/294\n",
      "132/132 [==============================] - 0s 349us/step - loss: 10.4927\n",
      "Epoch 213/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 11.6413\n",
      "Epoch 214/294\n",
      "132/132 [==============================] - 0s 894us/step - loss: 9.8821\n",
      "Epoch 215/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.4504\n",
      "Epoch 216/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.0339\n",
      "Epoch 217/294\n",
      "132/132 [==============================] - 0s 515us/step - loss: 8.5087\n",
      "Epoch 218/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.9217\n",
      "Epoch 219/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.3800\n",
      "Epoch 220/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 7.2804\n",
      "Epoch 221/294\n",
      "132/132 [==============================] - 0s 485us/step - loss: 9.2717\n",
      "Epoch 222/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.6126\n",
      "Epoch 223/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.5685\n",
      "Epoch 224/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.1719\n",
      "Epoch 225/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.5605\n",
      "Epoch 226/294\n",
      "132/132 [==============================] - 0s 288us/step - loss: 9.5401\n",
      "Epoch 227/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.5417\n",
      "Epoch 228/294\n",
      "132/132 [==============================] - 0s 826us/step - loss: 8.7106\n",
      "Epoch 229/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 8.1395\n",
      "Epoch 230/294\n",
      "132/132 [==============================] - ETA: 0s - loss: 8.083 - 0s 1ms/step - loss: 8.6680\n",
      "Epoch 231/294\n",
      "132/132 [==============================] - 0s 394us/step - loss: 8.5571\n",
      "Epoch 232/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.0252\n",
      "Epoch 233/294\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 9.4605\n",
      "Epoch 234/294\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 9.1586\n",
      "Epoch 235/294\n",
      "132/132 [==============================] - 0s 341us/step - loss: 10.6685\n",
      "Epoch 236/294\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 10.3353\n",
      "Epoch 237/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.9614\n",
      "Epoch 238/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.1541\n",
      "Epoch 239/294\n",
      "132/132 [==============================] - 0s 311us/step - loss: 10.0539\n",
      "Epoch 240/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.9058\n",
      "Epoch 241/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.1001\n",
      "Epoch 242/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.6495\n",
      "Epoch 243/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.8841\n",
      "Epoch 244/294\n",
      "132/132 [==============================] - 0s 333us/step - loss: 9.3132\n",
      "Epoch 245/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.8753\n",
      "Epoch 246/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.0642\n",
      "Epoch 247/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.2053\n",
      "Epoch 248/294\n",
      "132/132 [==============================] - 0s 303us/step - loss: 10.4343\n",
      "Epoch 249/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.3036\n",
      "Epoch 250/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.5126\n",
      "Epoch 251/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.2394\n",
      "Epoch 252/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 11.1292\n",
      "Epoch 253/294\n",
      "132/132 [==============================] - 0s 492us/step - loss: 9.8986\n",
      "Epoch 254/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.8168\n",
      "Epoch 255/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.5115\n",
      "Epoch 256/294\n",
      "132/132 [==============================] - 0s 970us/step - loss: 8.7982\n",
      "Epoch 257/294\n",
      "132/132 [==============================] - 0s 432us/step - loss: 10.2150\n",
      "Epoch 258/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 10.0431\n",
      "Epoch 259/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.9942\n",
      "Epoch 260/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.3639\n",
      "Epoch 261/294\n",
      "132/132 [==============================] - 0s 970us/step - loss: 9.0189\n",
      "Epoch 262/294\n",
      "132/132 [==============================] - 0s 409us/step - loss: 9.7379\n",
      "Epoch 263/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.8211\n",
      "Epoch 264/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 11.0898\n",
      "Epoch 265/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.3795\n",
      "Epoch 266/294\n",
      "132/132 [==============================] - 0s 606us/step - loss: 8.7515\n",
      "Epoch 267/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.0424\n",
      "Epoch 268/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.8067\n",
      "Epoch 269/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.6042\n",
      "Epoch 270/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.4476\n",
      "Epoch 271/294\n",
      "132/132 [==============================] - 0s 424us/step - loss: 8.8893\n",
      "Epoch 272/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.7668\n",
      "Epoch 273/294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 1ms/step - loss: 9.8200\n",
      "Epoch 274/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.8437\n",
      "Epoch 275/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 8.5158\n",
      "Epoch 276/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.6705\n",
      "Epoch 277/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 9.8417\n",
      "Epoch 278/294\n",
      "132/132 [==============================] - 0s 985us/step - loss: 10.9903\n",
      "Epoch 279/294\n",
      "132/132 [==============================] - 0s 849us/step - loss: 8.9694\n",
      "Epoch 280/294\n",
      "132/132 [==============================] - 0s 682us/step - loss: 9.3510\n",
      "Epoch 281/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.8000\n",
      "Epoch 282/294\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 10.0718\n",
      "Epoch 283/294\n",
      "132/132 [==============================] - 0s 871us/step - loss: 9.8702\n",
      "Epoch 284/294\n",
      "132/132 [==============================] - 0s 992us/step - loss: 9.6473\n",
      "Epoch 285/294\n",
      "132/132 [==============================] - 0s 485us/step - loss: 9.4407\n",
      "Epoch 286/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 8.3892\n",
      "Epoch 287/294\n",
      "132/132 [==============================] - 0s 970us/step - loss: 9.3608\n",
      "Epoch 288/294\n",
      "132/132 [==============================] - 0s 962us/step - loss: 9.2178\n",
      "Epoch 289/294\n",
      "132/132 [==============================] - 0s 765us/step - loss: 9.3629\n",
      "Epoch 290/294\n",
      "132/132 [==============================] - 0s 523us/step - loss: 10.3067\n",
      "Epoch 291/294\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 9.9400\n",
      "Epoch 292/294\n",
      "132/132 [==============================] - 0s 864us/step - loss: 9.9372\n",
      "Epoch 293/294\n",
      "132/132 [==============================] - 0s 970us/step - loss: 9.9271\n",
      "Epoch 294/294\n",
      "132/132 [==============================] - 0s 402us/step - loss: 9.2706\n",
      "60/60 [==============================] - 2s 41ms/step\n",
      "Epoch 1/188\n",
      "132/132 [==============================] - 30s 225ms/step - loss: 16109231689.8300\n",
      "Epoch 2/188\n",
      "132/132 [==============================] - 25s 193ms/step - loss: 10984023708.6061\n",
      "Epoch 3/188\n",
      "132/132 [==============================] - 27s 206ms/step - loss: 92930080.0455\n",
      "Epoch 4/188\n",
      "132/132 [==============================] - 30s 226ms/step - loss: 9739757.5928\n",
      "Epoch 5/188\n",
      "132/132 [==============================] - 23s 176ms/step - loss: 9968900.9982\n",
      "Epoch 6/188\n",
      "132/132 [==============================] - 26s 194ms/step - loss: 171139526413281344.0000\n",
      "Epoch 7/188\n",
      "  7/132 [>.............................] - ETA: 31s - loss: 10381669053809819648.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-192-5b40994b8ef4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m melhor_pop, melhor_res, media_res = ga_NN(start_pop = 50, generations = 5,h_layers = 20, neurons_by_layer = 1024,\n\u001b[0;32m      2\u001b[0m           \u001b[0mactivation_function_hiddend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mneurons_entry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         activation_entry = 6,epochs = 1000,batch_size = 132)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-183-eb6e4df5ca2e>\u001b[0m in \u001b[0;36mga_NN\u001b[1;34m(start_pop, generations, h_layers, neurons_by_layer, activation_function_hiddend, neurons_entry, activation_entry, epochs, batch_size)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Generation:  '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         pop_['Acc'] = build_nn(pop_, train_x = treino_x, train_y = treino_y, \n\u001b[1;32m---> 19\u001b[1;33m                          test_x = teste_x, test_y = teste_y, activations = functions)\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0macc_best\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0macc_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-179-0fde7c4fad15>\u001b[0m in \u001b[0;36mbuild_nn\u001b[1;34m(setup, train_x, train_y, test_x, test_y, activations)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean_absolute_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2719\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2721\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2693\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "melhor_pop, melhor_res, media_res = ga_NN(start_pop = 50, generations = 5,h_layers = 20, neurons_by_layer = 1024,\n",
    "          activation_function_hiddend = 6,neurons_entry = 1024,\n",
    "        activation_entry = 6,epochs = 1000,batch_size = 132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.svm.SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing random float number using a numpy \n",
      "\n",
      "0.58130479826768 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_float = np.random.uniform(0, 1)\n",
    "print(\"printing random float number using a numpy \\n\")\n",
    "print(random_float,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_conf (range_c = 2000, range_degree = 1000, pop = 10000):\n",
    "    epsilon = np.random.uniform(low = 0, high= 100, size = pop)\n",
    "    degree = np.random.randint(low=3,high=range_degree, size = pop)\n",
    "    Cust = np.random.randint(low=1,high=20, size = pop)\n",
    "    \n",
    "    config = pd.concat((pd.DataFrame(Cust),pd.DataFrame(epsilon),pd.DataFrame(degree) ), axis =1)\n",
    "    config.columns = ['C', 'Epsilon', 'Degree']\n",
    "    \n",
    "    return(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>84.996365</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>67.440220</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>75.485200</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>10.808769</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>21.324203</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C    Epsilon  Degree\n",
       "0   3  84.996365     356\n",
       "1  18  67.440220     169\n",
       "2   6  75.485200     810\n",
       "3   8  10.808769     452\n",
       "4   8  21.324203     966"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = gen_conf()\n",
    "config.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.iloc[:,0:1][0:1].values.ravel()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_acc(dataset = None, treino_x = treino_x, treino_y = treino_y, teste_x = teste_x, teste_y = teste_y):\n",
    "    acc = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        print('==================================== Iniciando individuo ========================')\n",
    "        cust   = dataset.iloc[:,0:1][i:i+1].values.ravel()[0]\n",
    "        eps    = dataset.iloc[:,1:2][i:i+1].values.ravel()[0]\n",
    "        degree = dataset.iloc[:,2:3][i:i+1].values.ravel()[0]\n",
    "        \n",
    "        model = None\n",
    "        model = sklearn.svm.SVR(C = cust, epsilon = eps, degree = degree).fit(treino_x,treino_y.ravel())\n",
    "        acc.append(sklearn.metrics.mean_absolute_error(teste_y.ravel(), model.predict(teste_x)))\n",
    "        print('O resultado do individuo número: ', i, \" é: \", acc[i])\n",
    "        print('Próximo Individuo.........')\n",
    "        \n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M1 - depósitos à vista - fim período - R$</th>\n",
       "      <th>Retornos M1 Final do Período</th>\n",
       "      <th>Índice M1 100 = Média de 2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>58027.664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.704050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>57415.063</td>\n",
       "      <td>-0.010557</td>\n",
       "      <td>33.348234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>56687.240</td>\n",
       "      <td>-0.012677</td>\n",
       "      <td>32.925495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>54955.139</td>\n",
       "      <td>-0.030555</td>\n",
       "      <td>31.919443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>53712.908</td>\n",
       "      <td>-0.022604</td>\n",
       "      <td>31.197922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            M1 - depósitos à vista - fim período - R$  \\\n",
       "Data                                                    \n",
       "31/01/2003                                  58027.664   \n",
       "28/02/2003                                  57415.063   \n",
       "31/03/2003                                  56687.240   \n",
       "30/04/2003                                  54955.139   \n",
       "31/05/2003                                  53712.908   \n",
       "\n",
       "            Retornos M1 Final do Período  Índice M1 100 = Média de 2014  \n",
       "Data                                                                     \n",
       "31/01/2003                           NaN                      33.704050  \n",
       "28/02/2003                     -0.010557                      33.348234  \n",
       "31/03/2003                     -0.012677                      32.925495  \n",
       "30/04/2003                     -0.030555                      31.919443  \n",
       "31/05/2003                     -0.022604                      31.197922  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_B = m1_.iloc[:,0:1]\n",
    "m1_B.columns = ['M1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 1)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = m1_B[:cut].values\n",
    "teste = m1_B[(cut - 12):].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_x = []\n",
    "treino_y = []\n",
    "\n",
    "\n",
    "for i in range(12,len(treino)):\n",
    "    treino_x.append(treino[(i - 12):i,0])\n",
    "    treino_y.append(treino[i,0])\n",
    "    \n",
    "treino_x, treino_y = np.array(treino_x), np.array(treino_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_x = []\n",
    "teste_y = []\n",
    "\n",
    "\n",
    "for i in range(12,len(teste)):\n",
    "    teste_x.append(teste[(i - 12):i,0])\n",
    "    teste_y.append(teste[i,0])\n",
    "    \n",
    "teste_x, teste_y = np.array(teste_x), np.array(teste_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_x = np.reshape(treino_x, (treino_x.shape[0],treino_x.shape[1],1))\n",
    "teste_x = np.reshape(teste_x, (teste_x.shape[0],teste_x.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 121005.1432\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 121002.2598\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 120998.6663\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 120996.5384 0s - loss: 1\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 120995.3773\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 120994.3779\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 120993.4248\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 120992.5020\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 120991.6042\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 120990.7230\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 120989.8496\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 120988.9899\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 120988.1318\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 120987.2878\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 120986.4434\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 120985.6064\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 120984.7705\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 120983.9365\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 120983.1104\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 120982.2822\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 120981.4587\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 120980.6410\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 120979.8171\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 120978.9984\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 120978.1833\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 120977.3656\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 120976.5534\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 120975.7383\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 120974.9261\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 120974.1169\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 120973.3047\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 120972.4948\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 120971.6891\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 120970.8796\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 120970.0749\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 120969.2676\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 120968.4606\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 120967.6576\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 120966.8490\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 120966.0482\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 120965.2448\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 120964.4417\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 120963.6377\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 120962.8350\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 120962.0345\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 120961.2331\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 120960.4281\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 120959.6296\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 120958.8307\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 120958.0280\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 120957.2282\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 120956.4268\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 120955.6299\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 120954.8301\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 120954.0299\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 120953.2311 1s - los\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 120952.4339\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 120951.6354 2s - loss: 120 - ETA\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 120950.8369\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 120950.0384\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 120949.2406\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 120948.4434\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 120947.6475\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 120946.8447\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 120946.0492\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 120945.2546\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 120944.4580\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 120943.6582\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 120942.8636 0s - loss:\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 120942.0684\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 120941.2721\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 120940.4736\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 120939.6800\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 120938.8825 1s\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 120938.0882\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 120937.2926\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 120936.4967\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 120935.7015\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 120934.9076\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 120934.1120\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 120933.3138\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 120932.5208\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 120931.7249\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 120930.9303\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 120930.1348\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 120929.3418\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 120928.5456\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 120927.7516\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 120926.9551\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 120926.1611\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 120925.3691\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 2s 19ms/step - loss: 120924.5752\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 120923.7780\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 120922.9847\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 120922.1924\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 120921.3955\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 120920.6038\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 120919.8096\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 120919.0156\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 120918.2197\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 32, input_shape = [treino_x.shape[1],1], return_sequences=True))\n",
    "model.add(LSTM(units = 32, return_sequences=False))\n",
    "model.add(Dense(units = 1))\n",
    "model.compile(optimizer= 'adam', loss = 'mean_absolute_error')\n",
    "history = model.fit(treino_x, treino_y, batch_size=5, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = np.log(treino)\n",
    "teste = np.log(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.010613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.012758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.031032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.022864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.051349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "1 -0.010613\n",
       "2 -0.012758\n",
       "3 -0.031032\n",
       "4 -0.022864\n",
       "5  0.051349"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino = pd.DataFrame(treino)\n",
    "treino = treino.diff().dropna()\n",
    "treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.016607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.038321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "1  0.009237\n",
       "2  0.029708\n",
       "3 -0.016607\n",
       "4  0.016693\n",
       "5  0.038321"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = pd.DataFrame(teste)\n",
    "teste = teste.diff().dropna()\n",
    "teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.835242738175154\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.07559296032459\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.194395606691668\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -19.508216498700076\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -19.683154192928086\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -19.687119356802583\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -19.688803974746858\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -19.688910374536338\n",
      "Iteration:      9,   Func. Count:     48,   Neg. LLF: -19.688918786206234\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -19.68891880282168\n",
      "            Iterations: 9\n",
      "            Function evaluations: 48\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.654753034486546\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -18.839902533376048\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -18.942214890330163\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -19.243728570281025\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -19.537790697205242\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -19.546329938529087\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -19.549095122978887\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -19.549137575908706\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -19.549138027045057\n",
      "            Iterations: 8\n",
      "            Function evaluations: 43\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.642725719782085\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -18.838149209716242\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -18.97273087553461\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -19.422952172091904\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -19.704150099866546\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -19.726170283753124\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -19.734723874384333\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -19.73555353281556\n",
      "Iteration:      9,   Func. Count:     47,   Neg. LLF: -19.73557108212602\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -19.735571118834674\n",
      "            Iterations: 9\n",
      "            Function evaluations: 47\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.80788946971707\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.03807847425854\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.21083123114264\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -19.658624037850053\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -20.017211024945027\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -20.02240216065111\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -20.023959638181914\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -20.02401893153729\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -20.024019513833963\n",
      "            Iterations: 8\n",
      "            Function evaluations: 45\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.97084089038923\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.257004690055094\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.49410401177586\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -19.698234383265564\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -19.95771820894766\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -20.551936448619713\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -20.594368837461854\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -20.606804833825617\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -20.607383357654044\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -20.60740301708526\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -20.607403050736565\n",
      "            Iterations: 10\n",
      "            Function evaluations: 55\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -19.485370170518696\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.827777804654698\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -20.109663929757442\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -20.353043864890047\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -20.565195036628833\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -20.996553489685795\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -21.364043673334614\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -21.37845361606296\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -21.401341523942442\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -21.403579146983787\n",
      "Iteration:     11,   Func. Count:     61,   Neg. LLF: -21.40472864912901\n",
      "Iteration:     12,   Func. Count:     66,   Neg. LLF: -21.40473229178504\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -21.404732324421488\n",
      "            Iterations: 12\n",
      "            Function evaluations: 66\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -19.303331795540764\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.61964569086661\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.864198430295968\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -20.094204958404248\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -20.248183985455732\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -20.793492877071067\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -20.89393300006495\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -20.950240546484068\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -20.96213106213614\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -20.96636873275092\n",
      "Iteration:     11,   Func. Count:     59,   Neg. LLF: -20.966503330603175\n",
      "Iteration:     12,   Func. Count:     64,   Neg. LLF: -20.96650443103687\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -20.96650446027713\n",
      "            Iterations: 12\n",
      "            Function evaluations: 64\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.989740465328477\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.284889668664775\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.515700623598097\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -19.733614535914548\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -19.885438859492986\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -20.194463012364345\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -20.488498554564025\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -20.543460315055455\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -20.563446898519476\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -20.56738090615239\n",
      "Iteration:     11,   Func. Count:     59,   Neg. LLF: -20.56751286240711\n",
      "Iteration:     12,   Func. Count:     64,   Neg. LLF: -20.5675173433097\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -20.567517382212202\n",
      "            Iterations: 13\n",
      "            Function evaluations: 71\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -19.22095073308182\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.539353149717755\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.79530661056493\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -20.037907464226762\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -20.224061823163247\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -20.395533030805232\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -20.495372272914448\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -20.569858175069562\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -20.617979474964503\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -20.71015038251249\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -20.733548799122413\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -20.772491859502132\n",
      "Iteration:     13,   Func. Count:     76,   Neg. LLF: -20.78996261343157\n",
      "Iteration:     14,   Func. Count:     82,   Neg. LLF: -20.792260842083685\n",
      "Iteration:     15,   Func. Count:     87,   Neg. LLF: -20.79338018555428\n",
      "Iteration:     16,   Func. Count:     92,   Neg. LLF: -20.79386144026898\n",
      "Iteration:     17,   Func. Count:     97,   Neg. LLF: -20.79392884205035\n",
      "Iteration:     18,   Func. Count:    102,   Neg. LLF: -20.79392997055153\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -20.793929968397126\n",
      "            Iterations: 18\n",
      "            Function evaluations: 102\n",
      "            Gradient evaluations: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -19.37462481259961\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.15569823241943\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -22.63357270377114\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.815739654790935\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -22.96868587565898\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -22.972469728359794\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -22.972715058128557\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.972715107052096\n",
      "            Iterations: 7\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -19.60300388816877\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.88679274097055\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -20.180625443861587\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -20.431011388025528\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -20.793593237706357\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -21.00072290826897\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -21.190361120437363\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -21.362387912457763\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -21.51669127977925\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -21.6528042531829\n",
      "Iteration:     11,   Func. Count:     64,   Neg. LLF: -21.7716400496338\n",
      "Iteration:     12,   Func. Count:     70,   Neg. LLF: -22.18313362417051\n",
      "Iteration:     13,   Func. Count:     75,   Neg. LLF: -22.485785775289497\n",
      "Iteration:     14,   Func. Count:     80,   Neg. LLF: -22.491985041732644\n",
      "Iteration:     15,   Func. Count:     85,   Neg. LLF: -22.492318266994275\n",
      "Iteration:     16,   Func. Count:     90,   Neg. LLF: -22.492375999194138\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.492376040304407\n",
      "            Iterations: 18\n",
      "            Function evaluations: 95\n",
      "            Gradient evaluations: 16\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.864713925632127\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.91734828464263\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.94622799306516\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.980787255016022\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -22.983828516919576\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -23.83815323280974\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -23.89317627072092\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -23.951269726311583\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -23.960568972941616\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -23.96171010715583\n",
      "Iteration:     11,   Func. Count:     61,   Neg. LLF: -23.961737500090205\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.961737533971657\n",
      "            Iterations: 12\n",
      "            Function evaluations: 61\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.89708719233103\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.934495316425274\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -27.045366820785404\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -27.19547168476405\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -27.197374836873376\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -27.19770279911467\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -27.19771852548476\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -27.197736194472874\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -27.197736744218243\n",
      "            Iterations: 9\n",
      "            Function evaluations: 48\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -27.818658042437573\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -27.939597739397094\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -28.013066139004597\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -28.337408983043776\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -28.622816128629392\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -28.641138914898388\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -28.64438944339257\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -28.644692655080988\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -28.64469587017444\n",
      "            Iterations: 9\n",
      "            Function evaluations: 44\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.3336064233088\n",
      "Iteration:      2,   Func. Count:     14,   Neg. LLF: -26.371755870008617\n",
      "Iteration:      3,   Func. Count:     20,   Neg. LLF: -26.390646426255365\n",
      "Iteration:      4,   Func. Count:     25,   Neg. LLF: -26.443410478262088\n",
      "Iteration:      5,   Func. Count:     32,   Neg. LLF: -26.44381750724772\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.44381750641487\n",
      "            Iterations: 5\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 5\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.672611241393604\n",
      "Iteration:      2,   Func. Count:     14,   Neg. LLF: -25.698306115510697\n",
      "Iteration:      3,   Func. Count:     20,   Neg. LLF: -25.70422644717304\n",
      "Iteration:      4,   Func. Count:     25,   Neg. LLF: -25.723353962684502\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -25.72684450807505\n",
      "Iteration:      6,   Func. Count:     37,   Neg. LLF: -25.7278786768322\n",
      "Iteration:      7,   Func. Count:     42,   Neg. LLF: -25.728023656173157\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -25.72803585242444\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.728035852406034\n",
      "            Iterations: 8\n",
      "            Function evaluations: 47\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.72430500544819\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -25.730405828181052\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -25.7344669641361\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -25.73671692553301\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -25.74579107211045\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -25.756824485896487\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -25.757410244648774\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -25.75772504419189\n",
      "Iteration:      9,   Func. Count:     48,   Neg. LLF: -25.75772621560645\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.7577262207047\n",
      "            Iterations: 9\n",
      "            Function evaluations: 48\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.54502308318402\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: -25.54563269440809\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -25.62567564846127\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -25.630823423634382\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -25.630852821379502\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -25.630864214831494\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.630864214895833\n",
      "            Iterations: 7\n",
      "            Function evaluations: 42\n",
      "            Gradient evaluations: 6\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.62617775866567\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: -25.659592681795427\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -25.76943277451981\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -25.899655482742816\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -25.929650613412797\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -25.930518635650678\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -25.93052472952542\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.930524729539076\n",
      "            Iterations: 7\n",
      "            Function evaluations: 37\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.456294734299064\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: -25.464820532751567\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -25.471716661381446\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -25.480022856678826\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: -25.487028166689285\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -25.501580509649433\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -25.51876588957795\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -25.518816167030884\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.51881616721508\n",
      "            Iterations: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Function evaluations: 46\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.011715903082035\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: -26.017112606256923\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -26.02719011828477\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -26.039601166385985\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: -26.051285836037245\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -26.081038162452053\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -26.082031334544162\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.08203133465758\n",
      "            Iterations: 7\n",
      "            Function evaluations: 41\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.58082325402993\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: -24.585295767810656\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -24.586852915497698\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -24.588210673402674\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: -24.589307511702557\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -24.592975442814573\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -24.598176246353212\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -24.59976981210779\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -24.600092755712\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -24.60014024521517\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.6001408306631\n",
      "            Iterations: 10\n",
      "            Function evaluations: 59\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.033135760670937\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -23.033330725832876\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -23.118374698592618\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -23.234281879713688\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -23.241595608517514\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -23.242041167974907\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -23.242052124128993\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.242053104444526\n",
      "            Iterations: 7\n",
      "            Function evaluations: 40\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.989898261770282\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -22.991687221285307\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -23.16425672106773\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -23.226345347537453\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -23.299536113716684\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -23.30120382958208\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -23.301804946081262\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -23.30210124674646\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.30210185000586\n",
      "            Iterations: 8\n",
      "            Function evaluations: 46\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.985176219399552\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.06199027301865\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -23.062247630312157\n",
      "Iteration:      4,   Func. Count:     25,   Neg. LLF: -23.082666400880612\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: -23.168137208580053\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -23.168554586342502\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -23.168649272073175\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.168649789930726\n",
      "            Iterations: 7\n",
      "            Function evaluations: 41\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.87276312354388\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.91994514106935\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.94663828570116\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -23.170866293839058\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -23.173516240860913\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.173516253178263\n",
      "            Iterations: 5\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 5\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.832763924118208\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.945056650306856\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -23.11863170367638\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -23.308770692213024\n",
      "Iteration:      5,   Func. Count:     26,   Neg. LLF: -23.46212707106771\n",
      "Iteration:      6,   Func. Count:     31,   Neg. LLF: -23.462431861035764\n",
      "Iteration:      7,   Func. Count:     36,   Neg. LLF: -23.462547421322736\n",
      "Iteration:      8,   Func. Count:     41,   Neg. LLF: -23.462575509385548\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.462575535294494\n",
      "            Iterations: 9\n",
      "            Function evaluations: 46\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.781617529124564\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.86974518797558\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -22.909896413076215\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -23.290754232037184\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -23.29332740033355\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -23.29333343333792\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -23.293335087167897\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.293335109128318\n",
      "            Iterations: 7\n",
      "            Function evaluations: 39\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.129560297558765\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.196535607739804\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -23.242551012906517\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -23.53733929862493\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -23.539256019745263\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -23.539351890947774\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.539351907444374\n",
      "            Iterations: 6\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 6\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.073423388604155\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.140395430654955\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.188372558129526\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -23.540253591502477\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -23.555916305802565\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -23.55774206742199\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -23.557977132202538\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -23.558013234220123\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.55801326006602\n",
      "            Iterations: 8\n",
      "            Function evaluations: 42\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.061814607688678\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.14561334540123\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -23.231464111302593\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -23.347030884170657\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -23.384464612471426\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -23.412059117698032\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -23.465462889428185\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -23.474234322252823\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -23.475993656717627\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -23.476024316649834\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.476024331623332\n",
      "            Iterations: 10\n",
      "            Function evaluations: 54\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.87483680324873\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.00175610877389\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -23.4357678076178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -23.51556958098283\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -23.568117237837047\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -23.62986946864127\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -23.653718586302958\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -23.668058021455863\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -23.669306035986974\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -23.66941435498251\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.669414443817118\n",
      "            Iterations: 11\n",
      "            Function evaluations: 57\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.277236201112807\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.40981825213968\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -23.449428154910382\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -23.55083604434581\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.00718568336803\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -24.03371164307295\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -24.065381656214143\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -24.075977291932247\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -24.077756114384687\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -24.077774942390743\n",
      "Iteration:     11,   Func. Count:     62,   Neg. LLF: -24.077911368679587\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.077911464800362\n",
      "            Iterations: 12\n",
      "            Function evaluations: 62\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.959815592038158\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.139327825584694\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.22403097729767\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -23.362609733567954\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -24.142756967273435\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -24.18589107881703\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -24.332993250327423\n",
      "Iteration:      8,   Func. Count:     48,   Neg. LLF: -24.349004801253407\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -24.441869728788237\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -24.441893622227333\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.44189378971741\n",
      "            Iterations: 11\n",
      "            Function evaluations: 59\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.80749148896373\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.961829623202675\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -22.13691473296373\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -22.553333022922477\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: -22.575949984806698\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.67846803515193\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -22.679438389605753\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -22.680262477713676\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -22.680269133253976\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.68026925712737\n",
      "            Iterations: 10\n",
      "            Function evaluations: 50\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.800108677461104\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.00571296021754\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -21.11431646661987\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -22.655255197818484\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: -22.655815201259472\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.6562007303894\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.656202178250812\n",
      "            Iterations: 7\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 6\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.15407684861924\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.353150217416136\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.459996169540652\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -23.30133814521644\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -23.56004143213011\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -23.613122584003904\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -23.64051627489941\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -23.67482150121269\n",
      "Iteration:      9,   Func. Count:     47,   Neg. LLF: -23.679746725770656\n",
      "Iteration:     10,   Func. Count:     52,   Neg. LLF: -23.6876425349695\n",
      "Iteration:     11,   Func. Count:     57,   Neg. LLF: -23.687975319567524\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.687978109522575\n",
      "            Iterations: 11\n",
      "            Function evaluations: 58\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.881809615360776\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.025790525995422\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.107438294648247\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.39276209992482\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -23.132449137156335\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -23.23427613538396\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -23.263496590009648\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -23.267420827206703\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -23.26755414092714\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -23.268246476076712\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.268246558282595\n",
      "            Iterations: 11\n",
      "            Function evaluations: 55\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.795187523246966\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.981357910784155\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.088426634075194\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.252846787477964\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.355418852477808\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -22.8270952611042\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -23.140300287351607\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -23.221638902896636\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -23.230955039080328\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -23.230994800229364\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.230995675710822\n",
      "            Iterations: 10\n",
      "            Function evaluations: 56\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.95231951797991\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.677787285413512\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.114826574497584\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -23.42251113720054\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -23.896348070178426\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -23.99749038702179\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -24.252749333771046\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -24.422352366241924\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -24.500436512833037\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -24.513249223201477\n",
      "Iteration:     11,   Func. Count:     64,   Neg. LLF: -24.540895066118143\n",
      "Iteration:     12,   Func. Count:     69,   Neg. LLF: -24.548203321738654\n",
      "Iteration:     13,   Func. Count:     74,   Neg. LLF: -24.558061646733147\n",
      "Iteration:     14,   Func. Count:     79,   Neg. LLF: -24.559170944403647\n",
      "Iteration:     15,   Func. Count:     84,   Neg. LLF: -24.561929260739557\n",
      "Iteration:     16,   Func. Count:     89,   Neg. LLF: -24.56194197882661\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.56194196650712\n",
      "            Iterations: 17\n",
      "            Function evaluations: 89\n",
      "            Gradient evaluations: 16\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.10339514175319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.306443554866895\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.467321998096942\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.62905598543667\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.772673667048075\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -23.026822760393923\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -23.184014717260336\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -23.600788617425735\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -23.77065692983124\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -23.846414138501455\n",
      "Iteration:     11,   Func. Count:     61,   Neg. LLF: -23.876207872884734\n",
      "Iteration:     12,   Func. Count:     66,   Neg. LLF: -23.885727506408728\n",
      "Iteration:     13,   Func. Count:     71,   Neg. LLF: -23.88787445064652\n",
      "Iteration:     14,   Func. Count:     76,   Neg. LLF: -23.88794370853039\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.887943784291444\n",
      "            Iterations: 14\n",
      "            Function evaluations: 76\n",
      "            Gradient evaluations: 14\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.851151013140456\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.012196477547672\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.128912080123442\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.251686576008503\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -22.452635815195165\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -23.05086156433669\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -23.141230922002322\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -23.151454817037223\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -23.153998046003586\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -23.154344167674314\n",
      "Iteration:     11,   Func. Count:     59,   Neg. LLF: -23.154490063742593\n",
      "Iteration:     12,   Func. Count:     64,   Neg. LLF: -23.15451672763753\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.154516823176127\n",
      "            Iterations: 13\n",
      "            Function evaluations: 71\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.808707631812773\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.96251858702815\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.073917445082277\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.199947456590913\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.637983295633973\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -23.0521951190493\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -23.083015517997538\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -23.09633583241807\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -23.096921334813363\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -23.097012111658238\n",
      "Iteration:     11,   Func. Count:     60,   Neg. LLF: -23.097022559166593\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.097022617701352\n",
      "            Iterations: 12\n",
      "            Function evaluations: 71\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.961060135278597\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.15015157819987\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.302001830283864\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.449560011627014\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.639859679988675\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.748696988847033\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -23.019185613656273\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -23.40039374779728\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -23.510494310713966\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -23.514818631028074\n",
      "Iteration:     11,   Func. Count:     62,   Neg. LLF: -23.51763914832465\n",
      "Iteration:     12,   Func. Count:     67,   Neg. LLF: -23.517642322654897\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.517642386550683\n",
      "            Iterations: 12\n",
      "            Function evaluations: 67\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.998429762701956\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.19499559414905\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.334617334440377\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.482056363542004\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.83200957702546\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -23.340076892810877\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -23.41517319663285\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -23.41567319324531\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -23.415813036856566\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.415813120127325\n",
      "            Iterations: 10\n",
      "            Function evaluations: 56\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.802276624604076\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.01594492921679\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.15989844757839\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.316723092849507\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.620051766558348\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -23.101746774407943\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -23.18770855622531\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -23.20047340641581\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -23.20102680301021\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -23.201095111702706\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.201095225261973\n",
      "            Iterations: 11\n",
      "            Function evaluations: 59\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -14.779288493680042\n",
      "Iteration:      2,   Func. Count:     14,   Neg. LLF: -14.841645634887033\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -16.12689739159402\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -16.180870481464847\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -16.19988718291446\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -16.23385231760512\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -16.23846166885935\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -16.23882568878029\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -16.23883024700626\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -16.23883026828206\n",
      "            Iterations: 9\n",
      "            Function evaluations: 49\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -13.418220594792546\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.87108317233036\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -13.96694597742448\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -15.543265803632888\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -15.565446143818358\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -15.571685351998743\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -15.572195798160886\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -15.57220365946192\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -15.572203679300719\n",
      "            Iterations: 8\n",
      "            Function evaluations: 42\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -13.611327894276378\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.885619492283993\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -13.953841946096011\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -15.262901947365846\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -15.262957529011334\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -15.262960287680508\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -15.262960305054156\n",
      "            Iterations: 6\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -13.32113909347703\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.507062755027084\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -13.553022273955632\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -14.476471043138261\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -14.552734143000963\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -14.82122338506731\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -14.972068258809028\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -15.002136445009729\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -15.003297861277296\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -15.00336733853178\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -15.00336747899189\n",
      "            Iterations: 11\n",
      "            Function evaluations: 56\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -13.205911817644695\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.367858526297335\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -13.421641115975808\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -14.364180471150036\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -14.456941732740118\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -14.615052574817419\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -14.841344648634921\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -14.909673905847464\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -14.960187753070395\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -14.967088201089146\n",
      "Iteration:     11,   Func. Count:     61,   Neg. LLF: -14.968106787662354\n",
      "Iteration:     12,   Func. Count:     66,   Neg. LLF: -14.968125954521954\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -14.968126100879246\n",
      "            Iterations: 13\n",
      "            Function evaluations: 66\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -13.057882781029711\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.202500513018064\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -13.469436590185268\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -13.926251899375142\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -14.090930384083267\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -14.232474581514017\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -14.351144728115612\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -14.447344630369692\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -14.560563737200233\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -14.619062523472419\n",
      "Iteration:     11,   Func. Count:     62,   Neg. LLF: -14.619943822022762\n",
      "Iteration:     12,   Func. Count:     67,   Neg. LLF: -14.620128720507315\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -14.620128838249585\n",
      "            Iterations: 12\n",
      "            Function evaluations: 67\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -13.008121109570514\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.150475145590104\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -13.802811573503522\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -13.986821751429696\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -14.201684518012662\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -14.334907432044394\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -14.421409202089187\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -14.556656137637106\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -14.582822209657015\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -14.598781622510499\n",
      "Iteration:     11,   Func. Count:     61,   Neg. LLF: -14.59947852427106\n",
      "Iteration:     12,   Func. Count:     66,   Neg. LLF: -14.599497308294069\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -14.59949743710552\n",
      "            Iterations: 13\n",
      "            Function evaluations: 66\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -13.108216548642337\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.27701726714379\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -13.901219345289952\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -13.970243634500978\n",
      "Iteration:      5,   Func. Count:     26,   Neg. LLF: -14.309129047013348\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -14.530353226995125\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -14.722880394159858\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -14.786537764584935\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -14.87739198094188\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -14.883956739049102\n",
      "Iteration:     11,   Func. Count:     64,   Neg. LLF: -14.884283186741355\n",
      "Iteration:     12,   Func. Count:     69,   Neg. LLF: -14.896492044706733\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -14.896492190967216\n",
      "            Iterations: 13\n",
      "            Function evaluations: 69\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -13.144222746325763\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.344253389974531\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -13.964529423348175\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -14.02311313204404\n",
      "Iteration:      5,   Func. Count:     26,   Neg. LLF: -14.313901266318204\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -14.936550977011407\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -14.979576186006907\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -15.023856798761887\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -15.024145159366014\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -15.0241676469589\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -15.02416780474725\n",
      "            Iterations: 11\n",
      "            Function evaluations: 56\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -12.896700829953904\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.031280817218184\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -13.415324340105741\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -13.611261042818615\n",
      "Iteration:      5,   Func. Count:     26,   Neg. LLF: -14.304884506736974\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -14.305180694158944\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -14.305190462903614\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -14.305190581956412\n",
      "            Iterations: 8\n",
      "            Function evaluations: 44\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -12.721138600230056\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -12.861789329190698\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -13.10297663397095\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -13.31551856679506\n",
      "Iteration:      5,   Func. Count:     26,   Neg. LLF: -13.52856539276814\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -13.627670299194131\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -13.717035510713375\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -13.73018402511554\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -13.732176678934309\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -13.781101417650182\n",
      "Iteration:     11,   Func. Count:     60,   Neg. LLF: -13.781104076469441\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -13.78110497155058\n",
      "            Iterations: 12\n",
      "            Function evaluations: 61\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -12.982821454732655\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.28339834468661\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -13.524877754235838\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -13.613600680098777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -13.692262581515408\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -13.759574817084653\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -13.818356993074689\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -13.869683455727715\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -13.973993799153366\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -14.007160917777231\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -14.033537735405428\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -14.074872305063918\n",
      "Iteration:     13,   Func. Count:     76,   Neg. LLF: -14.094600965530423\n",
      "Iteration:     14,   Func. Count:     82,   Neg. LLF: -14.098516909721775\n",
      "Iteration:     15,   Func. Count:     87,   Neg. LLF: -14.101519036820223\n",
      "Iteration:     16,   Func. Count:     92,   Neg. LLF: -14.10157701856796\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -14.101577013311305\n",
      "            Iterations: 16\n",
      "            Function evaluations: 92\n",
      "            Gradient evaluations: 16\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -12.788302436332732\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.34490004006439\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -13.671825653042454\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -13.978169542141519\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -14.25521034632736\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -14.507540056889242\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -14.733103097414073\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -14.93357028617474\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -15.11001863828056\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -15.26314112962704\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -15.396377298815255\n",
      "Iteration:     12,   Func. Count:     70,   Neg. LLF: -15.745960421596681\n",
      "Iteration:     13,   Func. Count:     75,   Neg. LLF: -16.223281417102747\n",
      "Iteration:     14,   Func. Count:     80,   Neg. LLF: -16.232726302341806\n",
      "Iteration:     15,   Func. Count:     85,   Neg. LLF: -16.24106760347895\n",
      "Iteration:     16,   Func. Count:     90,   Neg. LLF: -16.241774231889917\n",
      "Iteration:     17,   Func. Count:     95,   Neg. LLF: -16.24178875730089\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -16.241788922582426\n",
      "            Iterations: 18\n",
      "            Function evaluations: 100\n",
      "            Gradient evaluations: 17\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -13.3989949903883\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -13.616243642884676\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -13.837484702637832\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -14.049375453455182\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -14.24691801009219\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -14.427353483328455\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -14.589094744957812\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -14.909219544514986\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -15.844615504129324\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -15.850332413750776\n",
      "Iteration:     11,   Func. Count:     62,   Neg. LLF: -15.914588205275845\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -15.925085789259946\n",
      "Iteration:     13,   Func. Count:     76,   Neg. LLF: -15.925994552201347\n",
      "Iteration:     14,   Func. Count:     81,   Neg. LLF: -15.92602244604255\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -15.92602255576135\n",
      "            Iterations: 16\n",
      "            Function evaluations: 81\n",
      "            Gradient evaluations: 14\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.952905294032078\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.195926725988926\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.25703505995164\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -19.464058484762514\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -19.511885173274337\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -19.552936569141806\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -19.554508851690517\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -19.573106650973497\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -19.591948016669072\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -19.59211991880863\n",
      "Iteration:     11,   Func. Count:     62,   Neg. LLF: -19.59222864481429\n",
      "Iteration:     12,   Func. Count:     68,   Neg. LLF: -19.59227554169196\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -19.592275541686057\n",
      "            Iterations: 12\n",
      "            Function evaluations: 68\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.931854517810535\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.128066810819423\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.229745406888192\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -19.589683982709115\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -20.012876991676304\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -20.046974239153098\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -20.109473911454106\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -20.109731190709013\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -20.109736174839888\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -20.10979191949953\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -20.109792077638147\n",
      "            Iterations: 11\n",
      "            Function evaluations: 58\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.89046430042689\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.087093000501472\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.216600161401843\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -19.515414578948064\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -20.189238978742274\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -20.20859787820189\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -20.23384149905015\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -20.317682342421428\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -20.31772393445412\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -20.317724091758915\n",
      "            Iterations: 10\n",
      "            Function evaluations: 51\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.980986379078285\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.212219323079516\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.392224015082224\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -19.56948308485887\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -19.715384497597352\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -19.848186318317918\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -20.352572479494867\n",
      "Iteration:      8,   Func. Count:     50,   Neg. LLF: -20.724726068846913\n",
      "Iteration:      9,   Func. Count:     56,   Neg. LLF: -20.788868090149073\n",
      "Iteration:     10,   Func. Count:     62,   Neg. LLF: -20.834286652886167\n",
      "Iteration:     11,   Func. Count:     67,   Neg. LLF: -21.02949461745935\n",
      "Iteration:     12,   Func. Count:     72,   Neg. LLF: -21.030521638781288\n",
      "Iteration:     13,   Func. Count:     77,   Neg. LLF: -21.035754133521415\n",
      "Iteration:     14,   Func. Count:     86,   Neg. LLF: -21.035830970939895\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -21.035831192282263\n",
      "            Iterations: 16\n",
      "            Function evaluations: 86\n",
      "            Gradient evaluations: 14\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.633022798988154\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -18.810831831840147\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -18.90687016945286\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -19.115253194134613\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -19.795333690110535\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -19.866705676553337\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -19.91684357605561\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -19.91820992988547\n",
      "Iteration:      9,   Func. Count:     48,   Neg. LLF: -19.925364925911204\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -19.926079577852978\n",
      "Iteration:     11,   Func. Count:     61,   Neg. LLF: -19.92617546446002\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -19.926175594044803\n",
      "            Iterations: 12\n",
      "            Function evaluations: 61\n",
      "            Gradient evaluations: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.204559791951638\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -18.335730445815138\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -18.386934464774182\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -19.051674166264522\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -19.136757172933624\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -19.13747788453999\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -19.184582042923314\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -19.184743009576735\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -19.187183801486974\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -19.187408955399892\n",
      "Iteration:     11,   Func. Count:     62,   Neg. LLF: -19.187410729341718\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -19.18741083827191\n",
      "            Iterations: 12\n",
      "            Function evaluations: 62\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.05749924739031\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -18.158769310571746\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -18.3084063469533\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -18.572985180173696\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -18.69035951219324\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -18.70247031650993\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -18.70309969338984\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -18.703220157816748\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -18.703220198851728\n",
      "            Iterations: 8\n",
      "            Function evaluations: 43\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -17.763330602636156\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -17.883402064569662\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -18.497506469780927\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -18.615418434746854\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -18.74525187099392\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -18.772330390347\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -18.77559060131559\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -18.793649386498497\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -18.793665459575077\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -18.79369174953478\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -18.79369187601913\n",
      "            Iterations: 11\n",
      "            Function evaluations: 56\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.234243469669604\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -18.36934541443825\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -18.98610841317384\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -19.099928532918668\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -19.20929684072478\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -19.210208353538793\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -19.228262931516518\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -19.229969164730004\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -19.231208173476467\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -19.231209933022214\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -19.231210066257525\n",
      "            Iterations: 11\n",
      "            Function evaluations: 57\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -18.382734032173154\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -18.515169155914784\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -19.052397820968018\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -19.150909201248385\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -19.179253173075903\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -19.19598938334798\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -19.201648859342583\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -19.218255701780564\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -19.21856131916571\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -19.218561416997716\n",
      "            Iterations: 10\n",
      "            Function evaluations: 51\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -17.008468313695715\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -17.188850706183363\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -17.33041356227177\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -18.236732307109804\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -18.547865610382793\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -18.634534467736827\n",
      "Iteration:      7,   Func. Count:     42,   Neg. LLF: -18.697800737408986\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -18.69814124328204\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -18.698187153726128\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -18.69818728581514\n",
      "            Iterations: 10\n",
      "            Function evaluations: 52\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -17.14608085138116\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -17.182503313143133\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -17.416111707272837\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -18.10278154430724\n",
      "Iteration:      5,   Func. Count:     32,   Neg. LLF: -18.294971157451833\n",
      "Iteration:      6,   Func. Count:     40,   Neg. LLF: -18.29642732281082\n",
      "Iteration:      7,   Func. Count:     45,   Neg. LLF: -18.378305322406547\n",
      "Iteration:      8,   Func. Count:     50,   Neg. LLF: -18.37833284187226\n",
      "Iteration:      9,   Func. Count:     55,   Neg. LLF: -18.378364464245667\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -18.378364580561982\n",
      "            Iterations: 10\n",
      "            Function evaluations: 55\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.500125334297067\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.61451682624019\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -20.617942602179472\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -20.702939798446437\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -20.766341894163467\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -20.839328682851715\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -20.985383435101845\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -20.988000409541765\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -20.991978860664652\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -20.992819764589072\n",
      "Iteration:     11,   Func. Count:     62,   Neg. LLF: -20.992990187147612\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -20.992991056538564\n",
      "            Iterations: 11\n",
      "            Function evaluations: 63\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -19.979366819441257\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.016532380189382\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -20.088290890528658\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -20.290128360077052\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -20.295670397934586\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -20.29641312898856\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -20.29698799112177\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -20.296989383819653\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -20.296989394547737\n",
      "            Iterations: 8\n",
      "            Function evaluations: 42\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -19.83887023487033\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -19.839437080322973\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -20.02565224385111\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -20.088146491501814\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -20.094839357572344\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -20.095580624968328\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -20.09564975161943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -20.0956546503287\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -20.095654661801976\n",
      "            Iterations: 8\n",
      "            Function evaluations: 43\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -19.764021062610155\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: -19.76951985776346\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.950914989852496\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -19.961038562749803\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -19.985713164634074\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -19.989731971771818\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -19.989940508787512\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -19.989948183461856\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -19.989948191511655\n",
      "            Iterations: 8\n",
      "            Function evaluations: 44\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -19.803698803612694\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -19.86213888306848\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -19.941966710066765\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -20.068645222627616\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -20.208800152594563\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -20.228381589522197\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -20.244259489367042\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -20.2486654965109\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -20.250579964136097\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -20.252531978423256\n",
      "Iteration:     11,   Func. Count:     63,   Neg. LLF: -20.254244855407546\n",
      "Iteration:     12,   Func. Count:     68,   Neg. LLF: -20.254293962741023\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -20.254294886469662\n",
      "            Iterations: 12\n",
      "            Function evaluations: 69\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.495438609326325\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.62094654678962\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -20.745174591434644\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -20.844684500602803\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -20.93967086834706\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -21.01988885267446\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -21.084056524826423\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -21.194052740168324\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -21.24069123193082\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -21.293106999105987\n",
      "Iteration:     11,   Func. Count:     63,   Neg. LLF: -21.309813995293005\n",
      "Iteration:     12,   Func. Count:     69,   Neg. LLF: -21.312161640706105\n",
      "Iteration:     13,   Func. Count:     74,   Neg. LLF: -21.313062565475438\n",
      "Iteration:     14,   Func. Count:     79,   Neg. LLF: -21.313093409963994\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -21.31309340324459\n",
      "            Iterations: 14\n",
      "            Function evaluations: 79\n",
      "            Gradient evaluations: 14\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.750344873393722\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.899183706933403\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -20.993369785947777\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -21.117673337388215\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -21.290885590361167\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -21.354668465162305\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -21.365440721908577\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -21.379738217088068\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -21.39244241038442\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -21.393624312943956\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -21.394107596222064\n",
      "Iteration:     12,   Func. Count:     70,   Neg. LLF: -21.394110728779264\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -21.394110728788718\n",
      "            Iterations: 12\n",
      "            Function evaluations: 70\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.936311772548745\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.115476573396815\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -21.245976698404178\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -21.379426072712523\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -21.485308715457247\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -21.568111616657095\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -21.688673721656745\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -21.69914040818106\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -21.724922495255175\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -21.73107008070014\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -21.740587018604902\n",
      "Iteration:     12,   Func. Count:     70,   Neg. LLF: -21.742911217803844\n",
      "Iteration:     13,   Func. Count:     76,   Neg. LLF: -21.743256156642722\n",
      "Iteration:     14,   Func. Count:     81,   Neg. LLF: -21.74325938450763\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -21.743259384482393\n",
      "            Iterations: 14\n",
      "            Function evaluations: 81\n",
      "            Gradient evaluations: 14\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.645794736559534\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.902367730354594\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.072183072172685\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.241369173033092\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.377349728076634\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.492991895229146\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -22.600049459548956\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -22.692738566247943\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -22.70989652530801\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -22.726782750865436\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -22.733789066662645\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -22.74108321039396\n",
      "Iteration:     13,   Func. Count:     76,   Neg. LLF: -22.747889594160863\n",
      "Iteration:     14,   Func. Count:     81,   Neg. LLF: -22.752685100069776\n",
      "Iteration:     15,   Func. Count:     86,   Neg. LLF: -22.75276407367877\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.752765023073696\n",
      "            Iterations: 15\n",
      "            Function evaluations: 87\n",
      "            Gradient evaluations: 15\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.578172616243208\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.84265428488543\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.065665277477322\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -22.33466361500819\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -22.41591367629705\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.422528489958697\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -22.47736618259645\n",
      "Iteration:      8,   Func. Count:     48,   Neg. LLF: -22.477810770305442\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -22.48718394693831\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -22.49051001363019\n",
      "Iteration:     11,   Func. Count:     63,   Neg. LLF: -22.491207944401374\n",
      "Iteration:     12,   Func. Count:     68,   Neg. LLF: -22.49194656928345\n",
      "Iteration:     13,   Func. Count:     73,   Neg. LLF: -22.49206464810041\n",
      "Iteration:     14,   Func. Count:     78,   Neg. LLF: -22.492070645711184\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.492070645703546\n",
      "            Iterations: 14\n",
      "            Function evaluations: 78\n",
      "            Gradient evaluations: 14\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.646800421518282\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.995244545232733\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.166536283824804\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -22.324592896395874\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -22.438514978027193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.477719161201318\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -22.514534869341055\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -22.525264714905845\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -22.529791079511426\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -22.530338342036096\n",
      "Iteration:     11,   Func. Count:     62,   Neg. LLF: -22.530610854909302\n",
      "Iteration:     12,   Func. Count:     67,   Neg. LLF: -22.53067699135459\n",
      "Iteration:     13,   Func. Count:     72,   Neg. LLF: -22.530679386319154\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.530679386339052\n",
      "            Iterations: 13\n",
      "            Function evaluations: 72\n",
      "            Gradient evaluations: 13\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.654878233144498\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.722957344412475\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.79820327976452\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.903584927801077\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.945988225604324\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.964820461065877\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -22.98139027707133\n",
      "Iteration:      8,   Func. Count:     48,   Neg. LLF: -22.98144295840965\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -22.98215753321138\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -22.982665761511583\n",
      "Iteration:     11,   Func. Count:     63,   Neg. LLF: -22.982668408756624\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.982668408758997\n",
      "            Iterations: 11\n",
      "            Function evaluations: 63\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.713337922803472\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -25.715891973776145\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -25.717084329448912\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -25.71990049765965\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -25.721135760585014\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -25.721379939967157\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -25.721416376090456\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -25.721420393742527\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.72142039373473\n",
      "            Iterations: 8\n",
      "            Function evaluations: 45\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.745880974302885\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: -25.755139634278038\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -26.081774490353745\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -26.086816313829594\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -26.089374381646277\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -26.08968056644196\n",
      "Iteration:      7,   Func. Count:     43,   Neg. LLF: -26.090250637112216\n",
      "Iteration:      8,   Func. Count:     48,   Neg. LLF: -26.090261712887887\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.090261741140004\n",
      "            Iterations: 9\n",
      "            Function evaluations: 48\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.418388921153422\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.461078558213845\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -26.487707580575567\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -26.792971379776397\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -26.803011515293285\n",
      "Iteration:      6,   Func. Count:     37,   Neg. LLF: -26.803052721047806\n",
      "Iteration:      7,   Func. Count:     44,   Neg. LLF: -26.803056200416073\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.803056229352066\n",
      "            Iterations: 8\n",
      "            Function evaluations: 44\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.285887579749346\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.31246410335782\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -26.33268658824101\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -26.640280876613758\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -26.64029913041423\n",
      "Iteration:      6,   Func. Count:     38,   Neg. LLF: -26.642187992354817\n",
      "Iteration:      7,   Func. Count:     43,   Neg. LLF: -26.642203948297254\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.642203973819303\n",
      "            Iterations: 8\n",
      "            Function evaluations: 43\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.27462777831608\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.307795188469782\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -26.329509823280375\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -26.65112854884778\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -26.651515379086035\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -26.65337498701761\n",
      "Iteration:      7,   Func. Count:     42,   Neg. LLF: -26.65337668300484\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -26.653379716236664\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.653379744370067\n",
      "            Iterations: 9\n",
      "            Function evaluations: 47\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.238598934594705\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.275824468110716\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -26.314434655798006\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -26.564765549824752\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -26.56488217003249\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -26.56690581230987\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -26.566946136790413\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -26.56727857950004\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -26.567572862555537\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -26.567821883785868\n",
      "Iteration:     11,   Func. Count:     63,   Neg. LLF: -26.567906999579396\n",
      "Iteration:     12,   Func. Count:     68,   Neg. LLF: -26.567909185824366\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.567909208187196\n",
      "            Iterations: 13\n",
      "            Function evaluations: 68\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.023458852356956\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.09750406160626\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -26.182366231807972\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -26.516664875098044\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -26.518986458107992\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -26.52009498514368\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -26.52011121525802\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.520111251401623\n",
      "            Iterations: 8\n",
      "            Function evaluations: 41\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.53992827153881\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.634581049792768\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -26.645061831908443\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -26.69946950495911\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -27.041949048910713\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -27.051397309093062\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -27.052198941798384\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -27.052246448634957\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -27.052252556401523\n",
      "Iteration:     10,   Func. Count:     60,   Neg. LLF: -27.052259587119455\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -27.05225962218367\n",
      "            Iterations: 11\n",
      "            Function evaluations: 60\n",
      "            Gradient evaluations: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.635769178495284\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.743021496900546\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -26.75109548368953\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -26.819168665909878\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -27.0134566571432\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -27.014289321972843\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -27.01511729799596\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -27.01512035043434\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -27.015125893680374\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -27.01512591276329\n",
      "            Iterations: 9\n",
      "            Function evaluations: 49\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.39405885158732\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.575039265326886\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -26.69636487572158\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -26.82391475328952\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -27.2913741939053\n",
      "Iteration:      6,   Func. Count:     37,   Neg. LLF: -27.366992652451813\n",
      "Iteration:      7,   Func. Count:     43,   Neg. LLF: -27.38585544440831\n",
      "Iteration:      8,   Func. Count:     49,   Neg. LLF: -27.4046791916683\n",
      "Iteration:      9,   Func. Count:     55,   Neg. LLF: -27.405058498733354\n",
      "Iteration:     10,   Func. Count:     60,   Neg. LLF: -27.40512477154165\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -27.405152078207028\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -27.405152168952448\n",
      "            Iterations: 12\n",
      "            Function evaluations: 65\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.77933091004906\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -25.903497985426814\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -26.601116756920586\n",
      "Iteration:      4,   Func. Count:     25,   Neg. LLF: -26.701283817775003\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -26.72901080571468\n",
      "Iteration:      6,   Func. Count:     37,   Neg. LLF: -26.738454488188935\n",
      "Iteration:      7,   Func. Count:     43,   Neg. LLF: -26.7457840372532\n",
      "Iteration:      8,   Func. Count:     48,   Neg. LLF: -26.820584576796108\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -26.8312782438996\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -26.832992402729865\n",
      "Iteration:     11,   Func. Count:     63,   Neg. LLF: -26.833083978586085\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.83308409865062\n",
      "            Iterations: 12\n",
      "            Function evaluations: 63\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.41908680790511\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -24.597528095122964\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.75405264544135\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -25.896190904119127\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -25.916477032622694\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -25.917962619688357\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -25.918002174026423\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.91800227978745\n",
      "            Iterations: 8\n",
      "            Function evaluations: 41\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.905257174954052\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -26.90839183729328\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -27.09649679616573\n",
      "Iteration:      4,   Func. Count:     25,   Neg. LLF: -27.178133156861417\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: -27.653860289654205\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -27.695258992177948\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -27.71465716329912\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -27.72361349810791\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -27.72435786347255\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -27.724372004695745\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -27.724372022680594\n",
      "            Iterations: 10\n",
      "            Function evaluations: 55\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.65848741028276\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.802141373629244\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -26.89177026948929\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -27.028107714335597\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -27.556670355712644\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -27.58242434630426\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -27.60046892777878\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -27.601796103052866\n",
      "Iteration:      9,   Func. Count:     48,   Neg. LLF: -27.60628977720461\n",
      "Iteration:     10,   Func. Count:     53,   Neg. LLF: -27.606883875446456\n",
      "Iteration:     11,   Func. Count:     58,   Neg. LLF: -27.60920730941917\n",
      "Iteration:     12,   Func. Count:     66,   Neg. LLF: -27.609208486838554\n",
      "Iteration:     13,   Func. Count:     74,   Neg. LLF: -27.60921586393529\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -27.60921593431788\n",
      "            Iterations: 14\n",
      "            Function evaluations: 74\n",
      "            Gradient evaluations: 13\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.544743311730695\n",
      "Iteration:      2,   Func. Count:     10,   Neg. LLF: -27.24549461480627\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -28.17902813990226\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -28.216584491082553\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -28.23329714885209\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -28.242632393956285\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -28.2444865185591\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -28.24457181109174\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -28.24457250953759\n",
      "            Iterations: 9\n",
      "            Function evaluations: 43\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.96091980464345\n",
      "Iteration:      2,   Func. Count:     10,   Neg. LLF: -28.298561404378667\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -28.932571537576845\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -28.99446925680222\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -29.047663444767053\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -29.060548864358328\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -29.07125828161236\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -29.072094093730062\n",
      "Iteration:      9,   Func. Count:     48,   Neg. LLF: -29.072127663645162\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -29.07212799335288\n",
      "            Iterations: 11\n",
      "            Function evaluations: 54\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.85492819768543\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -27.063050890288743\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -27.248500314699164\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -27.411191872604487\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -27.549886937886004\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -27.984580111110613\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -28.526358936761234\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -28.57094311286123\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -28.586683050551944\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -28.588782638165355\n",
      "Iteration:     11,   Func. Count:     66,   Neg. LLF: -28.588834330454684\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -28.590274497027757\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -28.590274625679918\n",
      "            Iterations: 14\n",
      "            Function evaluations: 71\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -27.123539859546007\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -27.36253163099245\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -27.574246455709126\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -27.950075766762865\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -28.096453894617643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -28.223013440623923\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -28.330814052987453\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -28.538858625360326\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -28.85162082449479\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -28.854718081834402\n",
      "Iteration:     11,   Func. Count:     66,   Neg. LLF: -28.855062416206437\n",
      "Iteration:     12,   Func. Count:     74,   Neg. LLF: -28.85655503573055\n",
      "Iteration:     13,   Func. Count:     79,   Neg. LLF: -28.942165187610644\n",
      "Iteration:     14,   Func. Count:     84,   Neg. LLF: -28.95290516922679\n",
      "Iteration:     15,   Func. Count:     89,   Neg. LLF: -28.95818837736807\n",
      "Iteration:     16,   Func. Count:     94,   Neg. LLF: -28.95833167091364\n",
      "Iteration:     17,   Func. Count:     99,   Neg. LLF: -28.95833290197801\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -28.958333022399707\n",
      "            Iterations: 19\n",
      "            Function evaluations: 99\n",
      "            Gradient evaluations: 17\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -27.42284175495867\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -27.70591884919624\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -27.95740185348602\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -28.1803713955857\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -28.908327141902028\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -29.449124856817917\n",
      "Iteration:      7,   Func. Count:     44,   Neg. LLF: -29.50816424534181\n",
      "Iteration:      8,   Func. Count:     53,   Neg. LLF: -29.511210091176483\n",
      "Iteration:      9,   Func. Count:     59,   Neg. LLF: -29.53232768979523\n",
      "Iteration:     10,   Func. Count:     64,   Neg. LLF: -29.562124077487034\n",
      "Iteration:     11,   Func. Count:     69,   Neg. LLF: -29.562125840335227\n",
      "Iteration:     12,   Func. Count:     74,   Neg. LLF: -29.562128638695594\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -29.562128765795116\n",
      "            Iterations: 14\n",
      "            Function evaluations: 74\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -27.250972290925137\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -27.50500701392775\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -27.701571562370688\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -27.891337076481374\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -28.028892766229614\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -28.9522518310196\n",
      "Iteration:      7,   Func. Count:     42,   Neg. LLF: -28.97211049466433\n",
      "Iteration:      8,   Func. Count:     51,   Neg. LLF: -29.00797625953013\n",
      "Iteration:      9,   Func. Count:     56,   Neg. LLF: -29.09147943139855\n",
      "Iteration:     10,   Func. Count:     61,   Neg. LLF: -29.103556887448853\n",
      "Iteration:     11,   Func. Count:     66,   Neg. LLF: -29.109555782092812\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -29.10978642943444\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -29.109789572545612\n",
      "            Iterations: 13\n",
      "            Function evaluations: 72\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -27.561080767947722\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -27.81228354176966\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -27.99557632190307\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -28.17719816738375\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -28.30571913934188\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -28.983988430918142\n",
      "Iteration:      7,   Func. Count:     44,   Neg. LLF: -29.131688619642684\n",
      "Iteration:      8,   Func. Count:     50,   Neg. LLF: -29.13448628332473\n",
      "Iteration:      9,   Func. Count:     57,   Neg. LLF: -29.138363240435663\n",
      "Iteration:     10,   Func. Count:     62,   Neg. LLF: -29.14568866341008\n",
      "Iteration:     11,   Func. Count:     67,   Neg. LLF: -29.145705116446763\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -29.14570521882205\n",
      "            Iterations: 12\n",
      "            Function evaluations: 67\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.0572925141447\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.184635389148323\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -26.21281478958773\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -26.300583229855373\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: -26.356356019826414\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -26.394687153991427\n",
      "Iteration:      7,   Func. Count:     42,   Neg. LLF: -26.4273703151665\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -26.49338068570748\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -26.493922223020892\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -26.494296404253912\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.49429641778587\n",
      "            Iterations: 10\n",
      "            Function evaluations: 57\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.1414605170768\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.446315971410215\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.73793675367147\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.998020933181873\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -23.225275860209745\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -24.092153171283332\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -24.299275953681633\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -24.324255199908393\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -24.33300918502814\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -24.334249496254834\n",
      "Iteration:     11,   Func. Count:     61,   Neg. LLF: -24.334253824861605\n",
      "Iteration:     12,   Func. Count:     66,   Neg. LLF: -24.334273413507763\n",
      "Iteration:     13,   Func. Count:     71,   Neg. LLF: -24.33427496891864\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.334274997927633\n",
      "            Iterations: 15\n",
      "            Function evaluations: 82\n",
      "            Gradient evaluations: 13\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.56210205459485\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.003318807516816\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -21.33090625177562\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -21.675913229834148\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -21.97727031740653\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.244002421417168\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -22.475170482476557\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -22.66955514864773\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -23.1935339511686\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -23.335566013264497\n",
      "Iteration:     11,   Func. Count:     63,   Neg. LLF: -23.462776772408215\n",
      "Iteration:     12,   Func. Count:     68,   Neg. LLF: -23.46298543337973\n",
      "Iteration:     13,   Func. Count:     73,   Neg. LLF: -23.463184342484517\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.463184370649607\n",
      "            Iterations: 13\n",
      "            Function evaluations: 73\n",
      "            Gradient evaluations: 13\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.932076307896004\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.405170835602785\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.75460095350301\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -23.10633520985906\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -23.359926665028116\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -24.134809620473597\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -24.16731689661447\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -24.194492511512514\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -24.202924371856383\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -24.204018466428234\n",
      "Iteration:     11,   Func. Count:     60,   Neg. LLF: -24.204045317070193\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.204045314845818\n",
      "            Iterations: 11\n",
      "            Function evaluations: 60\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.433514933252802\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.80123616124983\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.084405569463403\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.34171720473695\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.59903019145738\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.798492640801648\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -22.97555006538595\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -23.093335091406157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -23.40758727371019\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -23.515270645756033\n",
      "Iteration:     11,   Func. Count:     64,   Neg. LLF: -23.537739306149987\n",
      "Iteration:     12,   Func. Count:     70,   Neg. LLF: -23.552023424307862\n",
      "Iteration:     13,   Func. Count:     76,   Neg. LLF: -23.568954113618943\n",
      "Iteration:     14,   Func. Count:     82,   Neg. LLF: -23.570479302084102\n",
      "Iteration:     15,   Func. Count:     89,   Neg. LLF: -23.571255691392928\n",
      "Iteration:     16,   Func. Count:     94,   Neg. LLF: -23.571289191030715\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.57128979660033\n",
      "            Iterations: 16\n",
      "            Function evaluations: 95\n",
      "            Gradient evaluations: 16\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.246784317924323\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.57502194719828\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -21.835883712875155\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.054423273430654\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.285862760406314\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.462199155655714\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -22.83750694652225\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -23.13525400516122\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -23.197151058154766\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -23.19775619548262\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -23.199885775273717\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -23.202915152721026\n",
      "Iteration:     13,   Func. Count:     77,   Neg. LLF: -23.20307178971341\n",
      "Iteration:     14,   Func. Count:     82,   Neg. LLF: -23.203072826763226\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.20307282674773\n",
      "            Iterations: 14\n",
      "            Function evaluations: 82\n",
      "            Gradient evaluations: 14\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.15902697326581\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.471398689625037\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -21.722915000170893\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -21.968407082190005\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.181186253459664\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.332370954911763\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -22.676597071852285\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -22.916439422158327\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -23.021338638362923\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -23.02263967152879\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -23.022680953717447\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -23.02795754625641\n",
      "Iteration:     13,   Func. Count:     76,   Neg. LLF: -23.02809586886033\n",
      "Iteration:     14,   Func. Count:     82,   Neg. LLF: -23.02809978332418\n",
      "Iteration:     15,   Func. Count:     87,   Neg. LLF: -23.028101860617042\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.028101860628073\n",
      "            Iterations: 15\n",
      "            Function evaluations: 87\n",
      "            Gradient evaluations: 15\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.733841305448216\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.999076259378132\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -21.200309428017647\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -21.400575919363686\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -21.557259194660002\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -21.839365455615077\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -22.33278240670922\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -22.351749113503832\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -22.354657436801695\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -22.355781595744435\n",
      "Iteration:     11,   Func. Count:     60,   Neg. LLF: -22.35582324779102\n",
      "Iteration:     12,   Func. Count:     65,   Neg. LLF: -22.355826558326054\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.355826578027145\n",
      "            Iterations: 12\n",
      "            Function evaluations: 65\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.45746114374291\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.68051520619784\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -20.838711130191793\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -21.006935455213213\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -21.379515024721773\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -21.793075744668347\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -21.830155739398116\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -21.836768857518575\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -21.837247557789166\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -21.837274768622304\n",
      "Iteration:     11,   Func. Count:     59,   Neg. LLF: -21.83728460071968\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -21.83728462864193\n",
      "            Iterations: 11\n",
      "            Function evaluations: 59\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.39434359844805\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.59238153436264\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -20.731198957399133\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -21.10698244248636\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -21.528484540028725\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -21.53905625126052\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -21.54565671932237\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -21.555118333252953\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -21.555144559848483\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -21.555144584771057\n",
      "            Iterations: 9\n",
      "            Function evaluations: 49\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.45188246712136\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.67300542603348\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -20.84025260106639\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -21.00238861978386\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -21.28539582448548\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -21.68383119283962\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -21.82746840872907\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -21.847049126106707\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -21.84749491921027\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -21.847509354057422\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -21.847509384134774\n",
      "            Iterations: 10\n",
      "            Function evaluations: 55\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.652554157880356\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.907006534551115\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -21.09972767835638\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -21.29449073214482\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -21.455359384631677\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -21.59816358402708\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -21.71336768265125\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -21.88047012517933\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -21.925829594609255\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -21.980337288448524\n",
      "Iteration:     11,   Func. Count:     64,   Neg. LLF: -21.997314518886117\n",
      "Iteration:     12,   Func. Count:     70,   Neg. LLF: -22.006891841597774\n",
      "Iteration:     13,   Func. Count:     76,   Neg. LLF: -22.01066201263939\n",
      "Iteration:     14,   Func. Count:     82,   Neg. LLF: -22.010782045387636\n",
      "Iteration:     15,   Func. Count:     88,   Neg. LLF: -22.01169851916906\n",
      "Iteration:     16,   Func. Count:     93,   Neg. LLF: -22.011704583908422\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.01170458389529\n",
      "            Iterations: 16\n",
      "            Function evaluations: 93\n",
      "            Gradient evaluations: 16\n"
     ]
    }
   ],
   "source": [
    "previsto_p = []\n",
    "previsto_n = []\n",
    "\n",
    "real = []\n",
    "for i in range(13,len(treino) - 1):\n",
    "    inicio = i - 13\n",
    "    \n",
    "    model = None\n",
    "    model_fit = None\n",
    "    model = arch_model(treino[inicio:i].values,mean = 'Zero' ,vol='GARCH', p=1,q = 1, lags=3)\n",
    "    model_fit = model.fit()\n",
    "    yhat = model_fit.forecast(horizon=1)\n",
    "    \n",
    "    previsto_p.append(yhat.mean.dropna().values.ravel()[0]  + (yhat.variance.dropna().values.ravel()[0])*3)\n",
    "    previsto_n.append(yhat.mean.dropna().values.ravel()[0]  - (yhat.variance.dropna().values.ravel()[0])*3)\n",
    "    real.append(treino[i-1:i+1].values.ravel()[0])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Banda Superior</th>\n",
       "      <th>Banda Inferior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036134</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>-0.006823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001266</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>-0.004815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.003051</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>-0.004432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013478</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>-0.004430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>-0.003438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Real  Banda Superior  Banda Inferior\n",
       "0  0.036134        0.006823       -0.006823\n",
       "1 -0.001266        0.004815       -0.004815\n",
       "2 -0.003051        0.004432       -0.004432\n",
       "3  0.013478        0.004430       -0.004430\n",
       "4  0.007771        0.003438       -0.003438"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest_treino = pd.DataFrame(real)\n",
    "backtest_treino.columns = ['Real']\n",
    "backtest_treino['Banda Superior'] = previsto_p\n",
    "backtest_treino['Banda Inferior'] = previsto_n\n",
    "backtest_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(backtest_treino['Real'][:50])\n",
    "plt.plot(backtest_treino['Banda Superior'][:50])\n",
    "plt.plot(backtest_treino['Banda Inferior'][:50])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.615141324028805\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.82153948787846\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.910125349061204\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.209525182025914\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -24.332854518585926\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -24.343197330242543\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -24.343240938147353\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -24.343260711453002\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.34326072468617\n",
      "            Iterations: 8\n",
      "            Function evaluations: 43\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.47634108687547\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.655170236362125\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.76665582776587\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -24.773579303381986\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -24.80504957404476\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -24.845970147714205\n",
      "Iteration:      7,   Func. Count:     42,   Neg. LLF: -24.845982409316484\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.845982592494718\n",
      "            Iterations: 8\n",
      "            Function evaluations: 42\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.79590718556372\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -24.004871108695113\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.157790791388653\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -25.54162787970793\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -25.585921267951548\n",
      "Iteration:      6,   Func. Count:     37,   Neg. LLF: -25.598479455068063\n",
      "Iteration:      7,   Func. Count:     46,   Neg. LLF: -25.612911878616735\n",
      "Iteration:      8,   Func. Count:     51,   Neg. LLF: -25.823333163478235\n",
      "Iteration:      9,   Func. Count:     56,   Neg. LLF: -25.823396448189378\n",
      "Iteration:     10,   Func. Count:     61,   Neg. LLF: -25.823440735751568\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.823440968734737\n",
      "            Iterations: 11\n",
      "            Function evaluations: 61\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.349745967134023\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.519712316015692\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.617935947485474\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -24.422136242166296\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -24.49402027179137\n",
      "Iteration:      6,   Func. Count:     37,   Neg. LLF: -24.4961437758922\n",
      "Iteration:      7,   Func. Count:     43,   Neg. LLF: -24.506091967716063\n",
      "Iteration:      8,   Func. Count:     48,   Neg. LLF: -24.50806245186142\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -24.508106159495014\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.508106784740686\n",
      "            Iterations: 10\n",
      "            Function evaluations: 54\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.444782960643078\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.63265755926323\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.76326892159178\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -24.685031797554064\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -24.73245703823457\n",
      "Iteration:      6,   Func. Count:     37,   Neg. LLF: -24.739599198205056\n",
      "Iteration:      7,   Func. Count:     43,   Neg. LLF: -24.7413117680559\n",
      "Iteration:      8,   Func. Count:     48,   Neg. LLF: -24.744852887176037\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -24.74488122457474\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.7448813243982\n",
      "            Iterations: 10\n",
      "            Function evaluations: 53\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.754630355976484\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.96315790369021\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.10005010882427\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -25.006585340185147\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -25.0777171207664\n",
      "Iteration:      6,   Func. Count:     37,   Neg. LLF: -25.083973522464163\n",
      "Iteration:      7,   Func. Count:     43,   Neg. LLF: -25.107970401374367\n",
      "Iteration:      8,   Func. Count:     49,   Neg. LLF: -25.10812692523518\n",
      "Iteration:      9,   Func. Count:     54,   Neg. LLF: -25.10812870216614\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.10812879611418\n",
      "            Iterations: 10\n",
      "            Function evaluations: 54\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.254862175999882\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -24.48657122543928\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.634883347461013\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -25.558657198377716\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -25.625565697669273\n",
      "Iteration:      6,   Func. Count:     38,   Neg. LLF: -25.62618505714286\n",
      "Iteration:      7,   Func. Count:     44,   Neg. LLF: -25.645820650927707\n",
      "Iteration:      8,   Func. Count:     49,   Neg. LLF: -25.646533816593884\n",
      "Iteration:      9,   Func. Count:     54,   Neg. LLF: -25.646555996488694\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.646556086129475\n",
      "            Iterations: 10\n",
      "            Function evaluations: 54\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.98682682108702\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -24.19747839158292\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.319078834952855\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -25.04793122236809\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -25.107937136198373\n",
      "Iteration:      6,   Func. Count:     38,   Neg. LLF: -25.11026390074844\n",
      "Iteration:      7,   Func. Count:     44,   Neg. LLF: -25.115521001254223\n",
      "Iteration:      8,   Func. Count:     49,   Neg. LLF: -25.115611035731416\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.11561110431812\n",
      "            Iterations: 9\n",
      "            Function evaluations: 49\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.023412193804777\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -24.262520119673702\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.41538243773512\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.668337094498526\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -24.973308002404657\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -24.973860729543325\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -24.974683146485678\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -24.97987015587284\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -24.979879239048948\n",
      "Iteration:     10,   Func. Count:     60,   Neg. LLF: -24.979882124909853\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.979882160181155\n",
      "            Iterations: 11\n",
      "            Function evaluations: 60\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.57475749773081\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.82752819983902\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.991128816474937\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.152061216701398\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -24.7186809855355\n",
      "Iteration:      6,   Func. Count:     37,   Neg. LLF: -24.737820265050065\n",
      "Iteration:      7,   Func. Count:     43,   Neg. LLF: -24.759680572901146\n",
      "Iteration:      8,   Func. Count:     48,   Neg. LLF: -24.760596074864317\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -24.76062865015732\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -24.760632327944332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.760632385494837\n",
      "            Iterations: 11\n",
      "            Function evaluations: 58\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.56035167537927\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.775836683152527\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.90565502876094\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.041998034596567\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -24.634816333010686\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -24.661722879382268\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -24.664623962009728\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -24.669375125463453\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -24.669475353078067\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -24.669613284687053\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.669613347336337\n",
      "            Iterations: 11\n",
      "            Function evaluations: 57\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.802182859790932\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -22.94295594737883\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.064100436450598\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -23.847030103111322\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -23.89806926540824\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -23.90384930280665\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -23.90445988487753\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -23.904470619566858\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.9044706912118\n",
      "            Iterations: 9\n",
      "            Function evaluations: 46\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.300119346823436\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -26.304083325449543\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -26.42887812571236\n",
      "Iteration:      4,   Func. Count:     26,   Neg. LLF: -26.43794002357128\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -26.480026523508368\n",
      "Iteration:      6,   Func. Count:     37,   Neg. LLF: -26.517206177036662\n",
      "Iteration:      7,   Func. Count:     43,   Neg. LLF: -26.52641874298445\n",
      "Iteration:      8,   Func. Count:     48,   Neg. LLF: -26.52652420118678\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -26.526562332654976\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.52656322499856\n",
      "            Iterations: 9\n",
      "            Function evaluations: 54\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -26.021894159422587\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -26.11347883079499\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -26.192406260761487\n",
      "Iteration:      4,   Func. Count:     21,   Neg. LLF: -26.317599064099618\n",
      "Iteration:      5,   Func. Count:     26,   Neg. LLF: -26.348143970466356\n",
      "Iteration:      6,   Func. Count:     31,   Neg. LLF: -26.36179825772636\n",
      "Iteration:      7,   Func. Count:     36,   Neg. LLF: -26.367262199365722\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -26.367593858599506\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -26.368072588091874\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -26.368075361779447\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.36807537893503\n",
      "            Iterations: 11\n",
      "            Function evaluations: 55\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.043807453435296\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -25.044206879761976\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -25.081415609343207\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -25.145316592215202\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -25.147561043179838\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -25.152080044534248\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -25.15218575645388\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -25.152189314631343\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.15218932221439\n",
      "            Iterations: 8\n",
      "            Function evaluations: 44\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.980680149370045\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -24.99525040846158\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -25.020660447301616\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -25.117634339106512\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -25.121946132785865\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -25.123521871085686\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -25.124889427726416\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -25.126498219456217\n",
      "Iteration:      9,   Func. Count:     47,   Neg. LLF: -25.126950255507957\n",
      "Iteration:     10,   Func. Count:     52,   Neg. LLF: -25.12713037152642\n",
      "Iteration:     11,   Func. Count:     60,   Neg. LLF: -25.12713577312035\n",
      "Iteration:     12,   Func. Count:     67,   Neg. LLF: -25.12715682119386\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.127157554703164\n",
      "            Iterations: 13\n",
      "            Function evaluations: 68\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.669088322528335\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -25.74270507333113\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -25.748967215551964\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -25.784689226483906\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -25.946371084110236\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -25.958283504509296\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -25.960570950364573\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -25.96074240329533\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -25.96090195297618\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -25.960947690827687\n",
      "Iteration:     11,   Func. Count:     59,   Neg. LLF: -25.960952001048508\n",
      "Iteration:     12,   Func. Count:     64,   Neg. LLF: -25.960953025990793\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.960953047846736\n",
      "            Iterations: 12\n",
      "            Function evaluations: 64\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.13748113851076\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -24.144061435607856\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -24.14591830173295\n",
      "Iteration:      4,   Func. Count:     25,   Neg. LLF: -24.14785260691646\n",
      "Iteration:      5,   Func. Count:     31,   Neg. LLF: -24.149543030174947\n",
      "Iteration:      6,   Func. Count:     37,   Neg. LLF: -24.154080000987943\n",
      "Iteration:      7,   Func. Count:     43,   Neg. LLF: -24.16089912480322\n",
      "Iteration:      8,   Func. Count:     48,   Neg. LLF: -24.171748470279617\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -24.17194673775421\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -24.172603631233503\n",
      "Iteration:     11,   Func. Count:     64,   Neg. LLF: -24.172651949584036\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.172651949737\n",
      "            Iterations: 11\n",
      "            Function evaluations: 64\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.365177660261512\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -24.372864876633177\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -24.3765490651841\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.376628460494196\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -24.37694366695728\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -24.377279266361498\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -24.37749426178475\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -24.377768877919234\n",
      "Iteration:      9,   Func. Count:     48,   Neg. LLF: -24.37780578771052\n",
      "Iteration:     10,   Func. Count:     53,   Neg. LLF: -24.377806814099873\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.377806814864133\n",
      "            Iterations: 10\n",
      "            Function evaluations: 53\n",
      "            Gradient evaluations: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.310338261323786\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -24.311396766806062\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -24.326870998696446\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.327953833436602\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -24.331683895753326\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -24.334166642214434\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -24.33626258553364\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -24.34116834700448\n",
      "Iteration:      9,   Func. Count:     48,   Neg. LLF: -24.34306684402039\n",
      "Iteration:     10,   Func. Count:     53,   Neg. LLF: -24.343358678986068\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.343359637535613\n",
      "            Iterations: 10\n",
      "            Function evaluations: 54\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.43208606046296\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: -24.45015962811283\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.650230137462753\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -24.743532602827013\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -24.790867098120355\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -24.79216059049234\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -24.792176002517948\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.79217600254507\n",
      "            Iterations: 7\n",
      "            Function evaluations: 37\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.433463455653108\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: -23.479792463585202\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -23.49110320498734\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -23.50136920745159\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: -23.51095990000077\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -23.534592747759238\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -23.5543390257766\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -23.56519894638108\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -23.57442066261887\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -23.574684646414433\n",
      "Iteration:     11,   Func. Count:     63,   Neg. LLF: -23.574791465430927\n",
      "Iteration:     12,   Func. Count:     68,   Neg. LLF: -23.574792607459198\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.574792607450874\n",
      "            Iterations: 12\n",
      "            Function evaluations: 68\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.542668966985648\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: -23.604587656283048\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -23.612372383566267\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -23.629759306064745\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -23.65121621363212\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -23.651966100806384\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -23.652085598798894\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -23.6520968982802\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.652096898254264\n",
      "            Iterations: 8\n",
      "            Function evaluations: 45\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.72611462614976\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: -22.743431035540038\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -22.744998344641143\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.75648231644746\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -22.75670190800117\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -22.756894280350497\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -22.756897443353736\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.756897443386077\n",
      "            Iterations: 7\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.889396245815306\n",
      "Iteration:      2,   Func. Count:     14,   Neg. LLF: -24.923968210144615\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -25.00339181900052\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -25.061727667639836\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -25.1039186479328\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -25.112969684525954\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -25.11361423564961\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.113627110873846\n",
      "            Iterations: 7\n",
      "            Function evaluations: 40\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.7238633375793\n",
      "Iteration:      2,   Func. Count:     14,   Neg. LLF: -24.74410383436488\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -24.75299031440293\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -24.801031203522015\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.825686065455432\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -24.835060346921097\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -24.836464019402996\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.83647157525068\n",
      "            Iterations: 7\n",
      "            Function evaluations: 41\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.71124783056194\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -24.711637997709243\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -24.727610756409977\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.7280378032466\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -24.72846290948941\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.72846346356947\n",
      "            Iterations: 5\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 5\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.480915042445883\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -25.48796531114583\n",
      "Iteration:      3,   Func. Count:     19,   Neg. LLF: -25.489353332397943\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: -25.505986634772437\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: -25.506487560845954\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -25.508783617485022\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -25.509895521723937\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -25.51020881660188\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -25.510220893093813\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.510220893140552\n",
      "            Iterations: 9\n",
      "            Function evaluations: 50\n",
      "            Gradient evaluations: 9\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.473926978661904\n",
      "Iteration:      2,   Func. Count:     13,   Neg. LLF: -25.47439742135872\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: -25.48417631638339\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -25.48431022957197\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -25.484439078762136\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.48443907903238\n",
      "            Iterations: 5\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 5\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.575485735767323\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -25.632940115018968\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -25.71575749865448\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -25.861959275235062\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -26.05189509079993\n",
      "Iteration:      6,   Func. Count:     36,   Neg. LLF: -26.255502806716084\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -26.31545418851257\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -26.547823158449393\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -26.552630730169113\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -26.553257037643903\n",
      "Iteration:     11,   Func. Count:     62,   Neg. LLF: -26.553320812108073\n",
      "Iteration:     12,   Func. Count:     67,   Neg. LLF: -26.553327587983528\n",
      "Iteration:     13,   Func. Count:     72,   Neg. LLF: -26.55332906619019\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.553329057365673\n",
      "            Iterations: 13\n",
      "            Function evaluations: 72\n",
      "            Gradient evaluations: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -27.45092289766999\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -27.641128895625\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -27.760921552253723\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -27.97464813395061\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -28.146898376191395\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -28.30910641837886\n",
      "Iteration:      7,   Func. Count:     43,   Neg. LLF: -28.44076692499998\n",
      "Iteration:      8,   Func. Count:     49,   Neg. LLF: -28.48014000163212\n",
      "Iteration:      9,   Func. Count:     55,   Neg. LLF: -28.529739640028406\n",
      "Iteration:     10,   Func. Count:     60,   Neg. LLF: -28.550033393906794\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -28.565262044909066\n",
      "Iteration:     12,   Func. Count:     70,   Neg. LLF: -28.566053913714075\n",
      "Iteration:     13,   Func. Count:     75,   Neg. LLF: -28.566130184696714\n",
      "Iteration:     14,   Func. Count:     80,   Neg. LLF: -28.566133003751894\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -28.566132999371053\n",
      "            Iterations: 14\n",
      "            Function evaluations: 80\n",
      "            Gradient evaluations: 14\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -27.119519553220453\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -27.288657498791842\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -27.36857447724618\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -27.568795919044543\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -27.69856161896097\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -27.735127631721305\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -27.742341773792127\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -27.774905615301908\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -27.784437026501575\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -27.78458544675561\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -27.78791926296935\n",
      "Iteration:     12,   Func. Count:     70,   Neg. LLF: -27.788214555803947\n",
      "Iteration:     13,   Func. Count:     75,   Neg. LLF: -27.78821727571087\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -27.78821727567098\n",
      "            Iterations: 13\n",
      "            Function evaluations: 75\n",
      "            Gradient evaluations: 13\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -27.237818633067917\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -27.389776574302555\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -27.602087293354696\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -27.672867996463484\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -27.740592267846566\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -27.840997375773398\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -27.883290929756356\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -27.900439372418855\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -27.932789430345945\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -27.946649907436374\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -27.951778820011448\n",
      "Iteration:     12,   Func. Count:     70,   Neg. LLF: -27.956630880411353\n",
      "Iteration:     13,   Func. Count:     75,   Neg. LLF: -27.95672651880659\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -27.956727337049763\n",
      "            Iterations: 13\n",
      "            Function evaluations: 76\n",
      "            Gradient evaluations: 13\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -27.245091073517376\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -27.506938020215763\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -27.771413900900832\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -27.93425153568216\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -28.384832149884037\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -28.394025953883673\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -28.443167785661576\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -28.45458345696423\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -28.487443878956626\n",
      "Iteration:     10,   Func. Count:     60,   Neg. LLF: -28.487776231101634\n",
      "Iteration:     11,   Func. Count:     66,   Neg. LLF: -28.490650776497002\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -28.49067023831255\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -28.49067083487678\n",
      "            Iterations: 12\n",
      "            Function evaluations: 72\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -25.634374041046264\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -25.82621073663304\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -26.013079036631016\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -26.513113063073625\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -26.63384567216809\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -26.7542315155618\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -27.161481264989483\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -27.24374926686098\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -27.30303577984718\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -27.331391295376314\n",
      "Iteration:     11,   Func. Count:     63,   Neg. LLF: -27.333822668500247\n",
      "Iteration:     12,   Func. Count:     68,   Neg. LLF: -27.335777255144002\n",
      "Iteration:     13,   Func. Count:     73,   Neg. LLF: -27.33580304640118\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -27.335803032036146\n",
      "            Iterations: 14\n",
      "            Function evaluations: 73\n",
      "            Gradient evaluations: 13\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.698134398041184\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.146864841395498\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.526441061062272\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -25.79913026234415\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -25.828260778379907\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -25.986148486001326\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -25.999583236900264\n",
      "Iteration:      8,   Func. Count:     48,   Neg. LLF: -26.03039315083997\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -26.04227475372912\n",
      "Iteration:     10,   Func. Count:     58,   Neg. LLF: -26.043093775474993\n",
      "Iteration:     11,   Func. Count:     63,   Neg. LLF: -26.043123381926204\n",
      "Iteration:     12,   Func. Count:     68,   Neg. LLF: -26.043124392049812\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.04312436891359\n",
      "            Iterations: 12\n",
      "            Function evaluations: 68\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -24.16988303688047\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -24.691743571150717\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -25.26352144990063\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -25.604588711851882\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -25.837641113167805\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -26.89291705299616\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -26.907002414269943\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -26.91811698994833\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -26.918215602367777\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -26.918217608822005\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.918217599517305\n",
      "            Iterations: 10\n",
      "            Function evaluations: 57\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.488016504280715\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.88709852072818\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.212295505070113\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.49405698744702\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.916856947331794\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -25.140226899176497\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -25.337135066847424\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -25.508817181129842\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -25.65673466991896\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -25.781647678550364\n",
      "Iteration:     11,   Func. Count:     64,   Neg. LLF: -26.045854626231595\n",
      "Iteration:     12,   Func. Count:     69,   Neg. LLF: -26.24421505785043\n",
      "Iteration:     13,   Func. Count:     74,   Neg. LLF: -26.306281561355778\n",
      "Iteration:     14,   Func. Count:     80,   Neg. LLF: -26.360542521598468\n",
      "Iteration:     15,   Func. Count:     85,   Neg. LLF: -26.362537492718825\n",
      "Iteration:     16,   Func. Count:     90,   Neg. LLF: -26.363493325494858\n",
      "Iteration:     17,   Func. Count:     95,   Neg. LLF: -26.363537954034868\n",
      "Iteration:     18,   Func. Count:    100,   Neg. LLF: -26.36354789584697\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.363547924367957\n",
      "            Iterations: 19\n",
      "            Function evaluations: 111\n",
      "            Gradient evaluations: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.457617237123465\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.823888263592448\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -24.372625289431273\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -26.093977330998264\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -26.185383308045736\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -26.189055029669024\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -26.198570772759957\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -26.199233191852493\n",
      "Iteration:      9,   Func. Count:     48,   Neg. LLF: -26.1993440869757\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -26.19934412708632\n",
      "Iteration:     11,   Func. Count:     62,   Neg. LLF: -26.199374925312725\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.199374967839418\n",
      "            Iterations: 12\n",
      "            Function evaluations: 62\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.452486876449523\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.807062905077462\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -25.8269721855067\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -25.96080007321313\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -26.23077129952967\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -26.249817148171168\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -26.25018431754265\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -26.250474005602072\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.25047407831502\n",
      "            Iterations: 9\n",
      "            Function evaluations: 45\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.338786158190366\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.682610179613242\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.97814416205935\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.248068562721556\n",
      "Iteration:      5,   Func. Count:     28,   Neg. LLF: -25.182936512385773\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -25.707894905028564\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -25.81163623562771\n",
      "Iteration:      8,   Func. Count:     45,   Neg. LLF: -25.854393522821137\n",
      "Iteration:      9,   Func. Count:     50,   Neg. LLF: -25.865521238650572\n",
      "Iteration:     10,   Func. Count:     55,   Neg. LLF: -25.881465156958864\n",
      "Iteration:     11,   Func. Count:     60,   Neg. LLF: -25.882852520620858\n",
      "Iteration:     12,   Func. Count:     65,   Neg. LLF: -25.88291292960778\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.8829132489463\n",
      "            Iterations: 13\n",
      "            Function evaluations: 71\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.334580126093616\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.686190007129973\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -25.707152835793845\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -25.78352616925183\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -26.152055635237875\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -26.152742031534874\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -26.152763351563735\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.152763402404062\n",
      "            Iterations: 7\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 7\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.350123218628347\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.706706326882937\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.022392992896535\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.30499978008274\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.559297298041606\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -24.78834032153456\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -24.994027525717897\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -25.177474191477437\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -25.339239271997755\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -25.479418312171386\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -25.597919292353502\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -25.921502778088357\n",
      "Iteration:     13,   Func. Count:     76,   Neg. LLF: -26.013027953195422\n",
      "Iteration:     14,   Func. Count:     82,   Neg. LLF: -26.048781120440854\n",
      "Iteration:     15,   Func. Count:     87,   Neg. LLF: -26.05197346491561\n",
      "Iteration:     16,   Func. Count:     92,   Neg. LLF: -26.05278004280601\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.052790143400877\n",
      "            Iterations: 19\n",
      "            Function evaluations: 93\n",
      "            Gradient evaluations: 16\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.319838032582172\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.684652106475397\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.008805467486376\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.300217523640768\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.563998700686245\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -24.80352505173002\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -25.02104000882891\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -25.21802541333959\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -25.39543777670903\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -25.553859217280632\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -25.693580141414476\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -25.814619123797417\n",
      "Iteration:     13,   Func. Count:     77,   Neg. LLF: -25.91689534473718\n",
      "Iteration:     14,   Func. Count:     82,   Neg. LLF: -26.076383318892432\n",
      "Iteration:     15,   Func. Count:     87,   Neg. LLF: -26.332204320271163\n",
      "Iteration:     16,   Func. Count:     92,   Neg. LLF: -26.366907030685034\n",
      "Iteration:     17,   Func. Count:     98,   Neg. LLF: -26.40413741647845\n",
      "Iteration:     18,   Func. Count:    103,   Neg. LLF: -26.404592528326884\n",
      "Iteration:     19,   Func. Count:    108,   Neg. LLF: -26.4047514844915\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -26.40475153037764\n",
      "            Iterations: 21\n",
      "            Function evaluations: 108\n",
      "            Gradient evaluations: 19\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.594070901469536\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.999548936117336\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.359893322641703\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.684278693183835\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.979161931778236\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -25.248153438208774\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -25.491955538763115\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -25.716349358122184\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: -25.716349420652573\n",
      "            Iterations: 12\n",
      "            Function evaluations: 47\n",
      "            Gradient evaluations: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\arch\\univariate\\base.py:571: ConvergenceWarning: \n",
      "The optimizer returned code 8. The message is:\n",
      "Positive directional derivative for linesearch\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.808985841154684\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.134563735740606\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.36922425294093\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -23.599349591629398\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -23.734184461165963\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -23.917861616707334\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -24.116820021194616\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -24.173135772567733\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -24.192567379927034\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -24.198808985278763\n",
      "Iteration:     11,   Func. Count:     59,   Neg. LLF: -24.199138760808633\n",
      "Iteration:     12,   Func. Count:     64,   Neg. LLF: -24.199153293906537\n",
      "Iteration:     13,   Func. Count:     69,   Neg. LLF: -24.19915457367437\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.199154580431653\n",
      "            Iterations: 13\n",
      "            Function evaluations: 69\n",
      "            Gradient evaluations: 13\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -21.4640294784984\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -21.836543190459608\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -22.177395636201183\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -22.484480831563513\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -22.755609005566846\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -22.98777705645904\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -23.18075568614902\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -23.444559450027892\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -23.720410091067762\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -23.727683248448773\n",
      "Iteration:     11,   Func. Count:     62,   Neg. LLF: -23.823782578860047\n",
      "Iteration:     12,   Func. Count:     68,   Neg. LLF: -23.84357534300702\n",
      "Iteration:     13,   Func. Count:     73,   Neg. LLF: -23.843645145568328\n",
      "Iteration:     14,   Func. Count:     78,   Neg. LLF: -23.843665807230895\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -23.84366583812277\n",
      "            Iterations: 15\n",
      "            Function evaluations: 78\n",
      "            Gradient evaluations: 14\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -20.2350012177752\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -20.604248753327454\n",
      "Iteration:      3,   Func. Count:     16,   Neg. LLF: -22.34018910991902\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -22.46718764467636\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -22.918415183921017\n",
      "Iteration:      6,   Func. Count:     33,   Neg. LLF: -22.92988676779202\n",
      "Iteration:      7,   Func. Count:     38,   Neg. LLF: -22.930211719926188\n",
      "Iteration:      8,   Func. Count:     43,   Neg. LLF: -22.93021918787526\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -22.9302192157943\n",
      "            Iterations: 9\n",
      "            Function evaluations: 50\n",
      "            Gradient evaluations: 8\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.491759789889894\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.92270129640848\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.177573091264055\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: -24.950514801738922\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: -24.983366697514345\n",
      "Iteration:      6,   Func. Count:     32,   Neg. LLF: -25.107603585956554\n",
      "Iteration:      7,   Func. Count:     37,   Neg. LLF: -25.117853397512363\n",
      "Iteration:      8,   Func. Count:     42,   Neg. LLF: -25.12350177616074\n",
      "Iteration:      9,   Func. Count:     47,   Neg. LLF: -25.123637587508323\n",
      "Iteration:     10,   Func. Count:     52,   Neg. LLF: -25.123638626708782\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.123638640212842\n",
      "            Iterations: 10\n",
      "            Function evaluations: 52\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.51037291396095\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.90313403729652\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.186769974409742\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.44320382139342\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.630210976322648\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -25.027653459783544\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -25.2974389061241\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: -25.31318606761176\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: -25.315843011895815\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: -25.31598724704349\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.315987975093133\n",
      "            Iterations: 10\n",
      "            Function evaluations: 57\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.49168429943183\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.871318775957178\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -24.145456139175536\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.39806377273471\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.57709535596181\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -24.987257107263048\n",
      "Iteration:      7,   Func. Count:     40,   Neg. LLF: -25.26414276019887\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -25.26672171591377\n",
      "Iteration:      9,   Func. Count:     52,   Neg. LLF: -25.268116366244822\n",
      "Iteration:     10,   Func. Count:     57,   Neg. LLF: -25.2682211454146\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -25.268221168161375\n",
      "            Iterations: 10\n",
      "            Function evaluations: 57\n",
      "            Gradient evaluations: 10\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.40608995952593\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.749610915679874\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.99767449483244\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.225655374415958\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.38076210306532\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -24.695792031469153\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -24.900109403293648\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -24.95255697288868\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -24.969202603753043\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -24.973753467327757\n",
      "Iteration:     11,   Func. Count:     59,   Neg. LLF: -24.97395728509934\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.97395807131457\n",
      "            Iterations: 11\n",
      "            Function evaluations: 60\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.29978882213564\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.629945313690875\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.873697114380303\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.09170180549652\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.246883771640576\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -24.71423387887738\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -24.837750650550348\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -24.886940504503286\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -24.897709036934618\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -24.899970714403675\n",
      "Iteration:     11,   Func. Count:     59,   Neg. LLF: -24.900028747269946\n",
      "Iteration:     12,   Func. Count:     64,   Neg. LLF: -24.900034121086662\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.90003415034953\n",
      "            Iterations: 13\n",
      "            Function evaluations: 75\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.334947058289586\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.66758744605852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.914942349663846\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -24.134801474009418\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.29534773593835\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -24.734567401803375\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -24.85057254560624\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -24.91348837876542\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -24.926827007233058\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -24.931515594139952\n",
      "Iteration:     11,   Func. Count:     59,   Neg. LLF: -24.931701598000195\n",
      "Iteration:     12,   Func. Count:     64,   Neg. LLF: -24.931703277562477\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.931703303913093\n",
      "            Iterations: 13\n",
      "            Function evaluations: 71\n",
      "            Gradient evaluations: 12\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.15253719164636\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.471720009762645\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.70602848686677\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -23.9204551455142\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.067998730056033\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -24.611009072176365\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -24.654403316210633\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -24.690746941238412\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -24.695740152096967\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -24.69654863244572\n",
      "Iteration:     11,   Func. Count:     59,   Neg. LLF: -24.696565774535607\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.69656582057919\n",
      "            Iterations: 12\n",
      "            Function evaluations: 64\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -23.217991412307533\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.54071658748094\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.775208698977952\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -23.992615578317412\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -24.139665698866928\n",
      "Iteration:      6,   Func. Count:     34,   Neg. LLF: -24.598016143746644\n",
      "Iteration:      7,   Func. Count:     39,   Neg. LLF: -24.67270795190623\n",
      "Iteration:      8,   Func. Count:     44,   Neg. LLF: -24.690450519805914\n",
      "Iteration:      9,   Func. Count:     49,   Neg. LLF: -24.693369229086265\n",
      "Iteration:     10,   Func. Count:     54,   Neg. LLF: -24.69350795222347\n",
      "Iteration:     11,   Func. Count:     59,   Neg. LLF: -24.693508990985467\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.69350902179011\n",
      "            Iterations: 12\n",
      "            Function evaluations: 70\n",
      "            Gradient evaluations: 11\n",
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: -22.923344733745203\n",
      "Iteration:      2,   Func. Count:     11,   Neg. LLF: -23.233102169532277\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: -23.452989749770243\n",
      "Iteration:      4,   Func. Count:     23,   Neg. LLF: -23.669833514798157\n",
      "Iteration:      5,   Func. Count:     29,   Neg. LLF: -23.807234044853587\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: -23.9066438840726\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: -23.954678930798444\n",
      "Iteration:      8,   Func. Count:     47,   Neg. LLF: -24.04374774902781\n",
      "Iteration:      9,   Func. Count:     53,   Neg. LLF: -24.06377011744234\n",
      "Iteration:     10,   Func. Count:     59,   Neg. LLF: -24.075431490129787\n",
      "Iteration:     11,   Func. Count:     65,   Neg. LLF: -24.08892695448185\n",
      "Iteration:     12,   Func. Count:     71,   Neg. LLF: -24.096160723588905\n",
      "Iteration:     13,   Func. Count:     76,   Neg. LLF: -24.09734919482295\n",
      "Iteration:     14,   Func. Count:     81,   Neg. LLF: -24.09860934594817\n",
      "Iteration:     15,   Func. Count:     86,   Neg. LLF: -24.098655676608857\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -24.098656399662868\n",
      "            Iterations: 15\n",
      "            Function evaluations: 87\n",
      "            Gradient evaluations: 15\n"
     ]
    }
   ],
   "source": [
    "previsto_p_ = []\n",
    "previsto_n_ = []\n",
    "\n",
    "real_ = []\n",
    "for i in range(13,len(teste) - 1):\n",
    "    inicio = i - 13\n",
    "    \n",
    "    model = None\n",
    "    model_fit = None\n",
    "    model = arch_model(teste[inicio:i].values, mean='Zero', vol='GARCH', p=1,q = 1)\n",
    "    model_fit = model.fit()\n",
    "    yhat = model_fit.forecast(horizon=1)\n",
    "    \n",
    "    previsto_p_.append(yhat.mean.dropna().values.ravel()[0]  + (yhat.variance.dropna().values.ravel()[0] * 2))\n",
    "    previsto_n_.append(yhat.mean.dropna().values.ravel()[0]  - (yhat.variance.dropna().values.ravel()[0] * 2))\n",
    "    real_.append(teste[i-1:i+1].values.ravel()[0])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backtest_treino = pd.DataFrame(real_)\n",
    "backtest_treino.columns = ['Real']\n",
    "backtest_treino['Banda Superior'] = previsto_p_\n",
    "backtest_treino['Banda Inferior'] = previsto_n_\n",
    "plt.plot(backtest_treino['Real'])\n",
    "plt.plot(backtest_treino['Banda Superior'])\n",
    "plt.plot(backtest_treino['Banda Inferior'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indice Cambial - 100 = Média de 2014</th>\n",
       "      <th>Indice Ibovespa - 100 = Média de 2014</th>\n",
       "      <th>Indice IPCA - 100 = Média de 2014</th>\n",
       "      <th>Índice M1 - 100 = Média de 2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>149.740047</td>\n",
       "      <td>20.781614</td>\n",
       "      <td>433.386838</td>\n",
       "      <td>33.704050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>151.013780</td>\n",
       "      <td>19.526093</td>\n",
       "      <td>302.407705</td>\n",
       "      <td>33.348234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>142.501675</td>\n",
       "      <td>21.412223</td>\n",
       "      <td>236.918138</td>\n",
       "      <td>32.925495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>122.493110</td>\n",
       "      <td>23.849186</td>\n",
       "      <td>186.837881</td>\n",
       "      <td>31.919443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>125.125843</td>\n",
       "      <td>25.492189</td>\n",
       "      <td>117.495987</td>\n",
       "      <td>31.197922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Indice Cambial - 100 = Média de 2014  \\\n",
       "Data                                               \n",
       "31/01/2003                            149.740047   \n",
       "28/02/2003                            151.013780   \n",
       "31/03/2003                            142.501675   \n",
       "30/04/2003                            122.493110   \n",
       "31/05/2003                            125.125843   \n",
       "\n",
       "            Indice Ibovespa - 100 = Média de 2014  \\\n",
       "Data                                                \n",
       "31/01/2003                              20.781614   \n",
       "28/02/2003                              19.526093   \n",
       "31/03/2003                              21.412223   \n",
       "30/04/2003                              23.849186   \n",
       "31/05/2003                              25.492189   \n",
       "\n",
       "            Indice IPCA - 100 = Média de 2014  Índice M1 - 100 = Média de 2014  \n",
       "Data                                                                            \n",
       "31/01/2003                         433.386838                        33.704050  \n",
       "28/02/2003                         302.407705                        33.348234  \n",
       "31/03/2003                         236.918138                        32.925495  \n",
       "30/04/2003                         186.837881                        31.919443  \n",
       "31/05/2003                         117.495987                        31.197922  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31/01/2003</th>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>58.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/06/2003</th>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/07/2003</th>\n",
       "      <td>61.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/08/2003</th>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/09/2003</th>\n",
       "      <td>61.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/10/2003</th>\n",
       "      <td>65.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/11/2003</th>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/12/2003</th>\n",
       "      <td>62.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/01/2004</th>\n",
       "      <td>59.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29/02/2004</th>\n",
       "      <td>53.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2004</th>\n",
       "      <td>65.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2004</th>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2004</th>\n",
       "      <td>61.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/06/2004</th>\n",
       "      <td>61.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/07/2004</th>\n",
       "      <td>66.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/08/2004</th>\n",
       "      <td>65.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/09/2004</th>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/10/2004</th>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/11/2004</th>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/12/2004</th>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/01/2005</th>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2005</th>\n",
       "      <td>51.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2005</th>\n",
       "      <td>58.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2005</th>\n",
       "      <td>57.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2005</th>\n",
       "      <td>57.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/06/2005</th>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/07/2016</th>\n",
       "      <td>83.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/08/2016</th>\n",
       "      <td>85.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/09/2016</th>\n",
       "      <td>80.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/10/2016</th>\n",
       "      <td>80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/11/2016</th>\n",
       "      <td>85.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/12/2016</th>\n",
       "      <td>82.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/01/2017</th>\n",
       "      <td>85.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2017</th>\n",
       "      <td>75.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2017</th>\n",
       "      <td>91.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2017</th>\n",
       "      <td>77.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2017</th>\n",
       "      <td>88.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/06/2017</th>\n",
       "      <td>87.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/07/2017</th>\n",
       "      <td>92.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/08/2017</th>\n",
       "      <td>96.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/09/2017</th>\n",
       "      <td>93.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/10/2017</th>\n",
       "      <td>95.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/11/2017</th>\n",
       "      <td>98.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/12/2017</th>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/01/2018</th>\n",
       "      <td>91.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/02/2018</th>\n",
       "      <td>80.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2018</th>\n",
       "      <td>90.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2018</th>\n",
       "      <td>89.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2018</th>\n",
       "      <td>86.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/06/2018</th>\n",
       "      <td>92.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/07/2018</th>\n",
       "      <td>94.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/08/2018</th>\n",
       "      <td>102.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/09/2018</th>\n",
       "      <td>91.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/10/2018</th>\n",
       "      <td>101.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/11/2018</th>\n",
       "      <td>99.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/12/2018</th>\n",
       "      <td>89.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Vendas reais - varejo - materiais de construção - índice (média 2014 = 100)\n",
       "Data                                                                                   \n",
       "31/01/2003                                               63.4                          \n",
       "28/02/2003                                               60.5                          \n",
       "31/03/2003                                               58.6                          \n",
       "30/04/2003                                               58.3                          \n",
       "31/05/2003                                               61.1                          \n",
       "30/06/2003                                               56.5                          \n",
       "31/07/2003                                               61.8                          \n",
       "31/08/2003                                               60.5                          \n",
       "30/09/2003                                               61.5                          \n",
       "31/10/2003                                               65.7                          \n",
       "30/11/2003                                               62.5                          \n",
       "31/12/2003                                               62.8                          \n",
       "31/01/2004                                               59.1                          \n",
       "29/02/2004                                               53.9                          \n",
       "31/03/2004                                               65.5                          \n",
       "30/04/2004                                               59.4                          \n",
       "31/05/2004                                               61.7                          \n",
       "30/06/2004                                               61.8                          \n",
       "31/07/2004                                               66.3                          \n",
       "31/08/2004                                               65.5                          \n",
       "30/09/2004                                               63.4                          \n",
       "31/10/2004                                               63.1                          \n",
       "30/11/2004                                               65.9                          \n",
       "31/12/2004                                               65.4                          \n",
       "31/01/2005                                               59.8                          \n",
       "28/02/2005                                               51.5                          \n",
       "31/03/2005                                               58.8                          \n",
       "30/04/2005                                               57.5                          \n",
       "31/05/2005                                               57.3                          \n",
       "30/06/2005                                               58.4                          \n",
       "...                                                       ...                          \n",
       "31/07/2016                                               83.2                          \n",
       "31/08/2016                                               85.7                          \n",
       "30/09/2016                                               80.6                          \n",
       "31/10/2016                                               80.5                          \n",
       "30/11/2016                                               85.7                          \n",
       "31/12/2016                                               82.7                          \n",
       "31/01/2017                                               85.5                          \n",
       "28/02/2017                                               75.8                          \n",
       "31/03/2017                                               91.7                          \n",
       "30/04/2017                                               77.7                          \n",
       "31/05/2017                                               88.1                          \n",
       "30/06/2017                                               87.3                          \n",
       "31/07/2017                                               92.4                          \n",
       "31/08/2017                                               96.8                          \n",
       "30/09/2017                                               93.1                          \n",
       "31/10/2017                                               95.4                          \n",
       "30/11/2017                                               98.2                          \n",
       "31/12/2017                                               90.0                          \n",
       "31/01/2018                                               91.8                          \n",
       "28/02/2018                                               80.2                          \n",
       "31/03/2018                                               90.4                          \n",
       "30/04/2018                                               89.8                          \n",
       "31/05/2018                                               86.5                          \n",
       "30/06/2018                                               92.2                          \n",
       "31/07/2018                                               94.3                          \n",
       "31/08/2018                                              102.5                          \n",
       "30/09/2018                                               91.6                          \n",
       "31/10/2018                                              101.7                          \n",
       "30/11/2018                                               99.5                          \n",
       "31/12/2018                                               89.5                          \n",
       "\n",
       "[192 rows x 1 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vendasvarejoconscivil_.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_var = pd.concat((vendasvarejoconscivil_.iloc[:,0:1].diff( ),dataset_x.diff()), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_var.columns = ['Vendas','DOL','IBOV', 'IPCA','M1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vendas</th>\n",
       "      <th>DOL</th>\n",
       "      <th>IBOV</th>\n",
       "      <th>IPCA</th>\n",
       "      <th>M1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28/02/2003</th>\n",
       "      <td>-2.9</td>\n",
       "      <td>1.273733</td>\n",
       "      <td>-1.255520</td>\n",
       "      <td>-130.979133</td>\n",
       "      <td>-0.355815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/03/2003</th>\n",
       "      <td>-1.9</td>\n",
       "      <td>-8.512105</td>\n",
       "      <td>1.886129</td>\n",
       "      <td>-65.489567</td>\n",
       "      <td>-0.422739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/04/2003</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-20.008565</td>\n",
       "      <td>2.436963</td>\n",
       "      <td>-50.080257</td>\n",
       "      <td>-1.006051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/05/2003</th>\n",
       "      <td>2.8</td>\n",
       "      <td>2.632733</td>\n",
       "      <td>1.643003</td>\n",
       "      <td>-69.341894</td>\n",
       "      <td>-0.721522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/06/2003</th>\n",
       "      <td>-4.6</td>\n",
       "      <td>-2.818741</td>\n",
       "      <td>-0.852842</td>\n",
       "      <td>-146.388443</td>\n",
       "      <td>1.643811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Vendas        DOL      IBOV        IPCA        M1\n",
       "Data                                                         \n",
       "28/02/2003    -2.9   1.273733 -1.255520 -130.979133 -0.355815\n",
       "31/03/2003    -1.9  -8.512105  1.886129  -65.489567 -0.422739\n",
       "30/04/2003    -0.3 -20.008565  2.436963  -50.080257 -1.006051\n",
       "31/05/2003     2.8   2.632733  1.643003  -69.341894 -0.721522\n",
       "30/06/2003    -4.6  -2.818741 -0.852842 -146.388443  1.643811"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_var = dados_var.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:171: ValueWarning: No frequency information was provided, so inferred frequency M will be used.\n",
      "  % freq, ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model = VAR(dados_var)\n",
    "model_fit = model.fit(maxlags=15, ic='aic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Summary of Regression Results   \n",
       "==================================\n",
       "Model:                         VAR\n",
       "Method:                        OLS\n",
       "Date:           Thu, 03, Oct, 2019\n",
       "Time:                     18:50:14\n",
       "--------------------------------------------------------------------\n",
       "No. of Equations:         5.00000    BIC:                    25.5966\n",
       "Nobs:                     177.000    HQIC:                   21.8099\n",
       "Log likelihood:          -2602.29    FPE:                2.84141e+08\n",
       "AIC:                      19.2263    Det(Omega_mle):     5.26190e+07\n",
       "--------------------------------------------------------------------\n",
       "Results for equation Vendas\n",
       "=============================================================================\n",
       "                coefficient       std. error           t-stat            prob\n",
       "-----------------------------------------------------------------------------\n",
       "const             -0.313713         0.445636           -0.704           0.481\n",
       "L1.Vendas         -0.669289         0.091506           -7.314           0.000\n",
       "L1.DOL            -0.007379         0.091619           -0.081           0.936\n",
       "L1.IBOV            0.057069         0.066794            0.854           0.393\n",
       "L1.IPCA            0.000933         0.008198            0.114           0.909\n",
       "L1.M1              0.288782         0.155142            1.861           0.063\n",
       "L2.Vendas         -0.340124         0.111723           -3.044           0.002\n",
       "L2.DOL            -0.003827         0.090681           -0.042           0.966\n",
       "L2.IBOV            0.013898         0.068067            0.204           0.838\n",
       "L2.IPCA           -0.000751         0.009230           -0.081           0.935\n",
       "L2.M1             -0.244021         0.161926           -1.507           0.132\n",
       "L3.Vendas          0.029655         0.112450            0.264           0.792\n",
       "L3.DOL             0.049287         0.091419            0.539           0.590\n",
       "L3.IBOV           -0.025183         0.069940           -0.360           0.719\n",
       "L3.IPCA           -0.020694         0.010313           -2.007           0.045\n",
       "L3.M1             -0.175415         0.162304           -1.081           0.280\n",
       "L4.Vendas         -0.027255         0.106031           -0.257           0.797\n",
       "L4.DOL             0.021640         0.092702            0.233           0.815\n",
       "L4.IBOV            0.027188         0.071174            0.382           0.702\n",
       "L4.IPCA           -0.009113         0.010963           -0.831           0.406\n",
       "L4.M1             -0.077827         0.161551           -0.482           0.630\n",
       "L5.Vendas         -0.121879         0.106779           -1.141           0.254\n",
       "L5.DOL            -0.096906         0.094947           -1.021           0.307\n",
       "L5.IBOV            0.100577         0.071488            1.407           0.159\n",
       "L5.IPCA           -0.020354         0.011850           -1.718           0.086\n",
       "L5.M1             -0.005386         0.157319           -0.034           0.973\n",
       "L6.Vendas         -0.206474         0.108318           -1.906           0.057\n",
       "L6.DOL             0.080916         0.095443            0.848           0.397\n",
       "L6.IBOV            0.045038         0.072131            0.624           0.532\n",
       "L6.IPCA           -0.019869         0.012824           -1.549           0.121\n",
       "L6.M1              0.071460         0.161040            0.444           0.657\n",
       "L7.Vendas         -0.174200         0.109180           -1.596           0.111\n",
       "L7.DOL            -0.059514         0.096481           -0.617           0.537\n",
       "L7.IBOV           -0.027724         0.071916           -0.386           0.700\n",
       "L7.IPCA           -0.018344         0.012985           -1.413           0.158\n",
       "L7.M1              0.183880         0.165241            1.113           0.266\n",
       "L8.Vendas         -0.112194         0.109320           -1.026           0.305\n",
       "L8.DOL             0.074497         0.091594            0.813           0.416\n",
       "L8.IBOV            0.016002         0.071665            0.223           0.823\n",
       "L8.IPCA           -0.021166         0.013321           -1.589           0.112\n",
       "L8.M1              0.310276         0.170354            1.821           0.069\n",
       "L9.Vendas          0.060418         0.111590            0.541           0.588\n",
       "L9.DOL            -0.176853         0.094205           -1.877           0.060\n",
       "L9.IBOV           -0.027945         0.070904           -0.394           0.693\n",
       "L9.IPCA           -0.026523         0.013777           -1.925           0.054\n",
       "L9.M1              0.283376         0.168695            1.680           0.093\n",
       "L10.Vendas         0.011906         0.111695            0.107           0.915\n",
       "L10.DOL            0.134035         0.095725            1.400           0.161\n",
       "L10.IBOV           0.200171         0.073335            2.730           0.006\n",
       "L10.IPCA          -0.030147         0.012878           -2.341           0.019\n",
       "L10.M1             0.255966         0.170802            1.499           0.134\n",
       "L11.Vendas        -0.021098         0.111308           -0.190           0.850\n",
       "L11.DOL            0.010914         0.096082            0.114           0.910\n",
       "L11.IBOV          -0.049657         0.075258           -0.660           0.509\n",
       "L11.IPCA          -0.016902         0.012260           -1.379           0.168\n",
       "L11.M1             0.639640         0.176020            3.634           0.000\n",
       "L12.Vendas         0.339829         0.113596            2.992           0.003\n",
       "L12.DOL            0.034068         0.090996            0.374           0.708\n",
       "L12.IBOV           0.081758         0.073986            1.105           0.269\n",
       "L12.IPCA          -0.009415         0.011489           -0.820           0.412\n",
       "L12.M1            -0.005179         0.182726           -0.028           0.977\n",
       "L13.Vendas         0.277067         0.111887            2.476           0.013\n",
       "L13.DOL            0.014301         0.089724            0.159           0.873\n",
       "L13.IBOV          -0.087157         0.073744           -1.182           0.237\n",
       "L13.IPCA           0.002355         0.009620            0.245           0.807\n",
       "L13.M1            -0.298157         0.171909           -1.734           0.083\n",
       "L14.Vendas         0.260601         0.097904            2.662           0.008\n",
       "L14.DOL           -0.080682         0.089593           -0.901           0.368\n",
       "L14.IBOV          -0.045254         0.072887           -0.621           0.535\n",
       "L14.IPCA          -0.014002         0.008141           -1.720           0.085\n",
       "L14.M1            -0.279075         0.161984           -1.723           0.085\n",
       "=============================================================================\n",
       "\n",
       "Results for equation DOL\n",
       "=============================================================================\n",
       "                coefficient       std. error           t-stat            prob\n",
       "-----------------------------------------------------------------------------\n",
       "const              0.833732         0.578773            1.441           0.150\n",
       "L1.Vendas         -0.179650         0.118845           -1.512           0.131\n",
       "L1.DOL            -0.096343         0.118991           -0.810           0.418\n",
       "L1.IBOV           -0.007914         0.086749           -0.091           0.927\n",
       "L1.IPCA           -0.008930         0.010648           -0.839           0.402\n",
       "L1.M1             -0.089517         0.201492           -0.444           0.657\n",
       "L2.Vendas          0.041175         0.145101            0.284           0.777\n",
       "L2.DOL             0.067604         0.117773            0.574           0.566\n",
       "L2.IBOV           -0.043572         0.088402           -0.493           0.622\n",
       "L2.IPCA            0.010169         0.011987            0.848           0.396\n",
       "L2.M1             -0.194772         0.210303           -0.926           0.354\n",
       "L3.Vendas          0.146501         0.146045            1.003           0.316\n",
       "L3.DOL            -0.112241         0.118731           -0.945           0.344\n",
       "L3.IBOV           -0.097800         0.090835           -1.077           0.282\n",
       "L3.IPCA            0.014313         0.013394            1.069           0.285\n",
       "L3.M1             -0.506638         0.210794           -2.403           0.016\n",
       "L4.Vendas          0.268657         0.137708            1.951           0.051\n",
       "L4.DOL             0.254668         0.120397            2.115           0.034\n",
       "L4.IBOV            0.204426         0.092438            2.211           0.027\n",
       "L4.IPCA            0.002120         0.014238            0.149           0.882\n",
       "L4.M1             -0.530527         0.209816           -2.529           0.011\n",
       "L5.Vendas          0.343597         0.138680            2.478           0.013\n",
       "L5.DOL             0.202965         0.123313            1.646           0.100\n",
       "L5.IBOV            0.120672         0.092845            1.300           0.194\n",
       "L5.IPCA           -0.004658         0.015391           -0.303           0.762\n",
       "L5.M1             -0.246260         0.204320           -1.205           0.228\n",
       "L6.Vendas          0.230698         0.140680            1.640           0.101\n",
       "L6.DOL             0.172507         0.123957            1.392           0.164\n",
       "L6.IBOV            0.136495         0.093681            1.457           0.145\n",
       "L6.IPCA            0.008661         0.016655            0.520           0.603\n",
       "L6.M1             -0.187238         0.209152           -0.895           0.371\n",
       "L7.Vendas          0.249829         0.141798            1.762           0.078\n",
       "L7.DOL             0.131719         0.125306            1.051           0.293\n",
       "L7.IBOV            0.206535         0.093401            2.211           0.027\n",
       "L7.IPCA            0.030496         0.016865            1.808           0.071\n",
       "L7.M1             -0.238641         0.214608           -1.112           0.266\n",
       "L8.Vendas          0.167038         0.141981            1.176           0.239\n",
       "L8.DOL            -0.176392         0.118959           -1.483           0.138\n",
       "L8.IBOV           -0.075048         0.093076           -0.806           0.420\n",
       "L8.IPCA            0.028222         0.017301            1.631           0.103\n",
       "L8.M1             -0.280450         0.221248           -1.268           0.205\n",
       "L9.Vendas          0.142905         0.144929            0.986           0.324\n",
       "L9.DOL            -0.193615         0.122349           -1.582           0.114\n",
       "L9.IBOV           -0.073156         0.092087           -0.794           0.427\n",
       "L9.IPCA            0.024691         0.017894            1.380           0.168\n",
       "L9.M1             -0.064239         0.219094           -0.293           0.769\n",
       "L10.Vendas         0.199492         0.145064            1.375           0.169\n",
       "L10.DOL           -0.154445         0.124324           -1.242           0.214\n",
       "L10.IBOV          -0.053670         0.095245           -0.564           0.573\n",
       "L10.IPCA           0.025296         0.016725            1.512           0.130\n",
       "L10.M1            -0.146376         0.221830           -0.660           0.509\n",
       "L11.Vendas         0.008754         0.144562            0.061           0.952\n",
       "L11.DOL            0.019741         0.124787            0.158           0.874\n",
       "L11.IBOV           0.021549         0.097743            0.220           0.826\n",
       "L11.IPCA           0.029596         0.015922            1.859           0.063\n",
       "L11.M1            -0.189917         0.228607           -0.831           0.406\n",
       "L12.Vendas         0.133158         0.147534            0.903           0.367\n",
       "L12.DOL           -0.266589         0.118182           -2.256           0.024\n",
       "L12.IBOV          -0.186772         0.096090           -1.944           0.052\n",
       "L12.IPCA           0.006219         0.014921            0.417           0.677\n",
       "L12.M1             0.062171         0.237317            0.262           0.793\n",
       "L13.Vendas         0.151137         0.145315            1.040           0.298\n",
       "L13.DOL           -0.240345         0.116530           -2.063           0.039\n",
       "L13.IBOV          -0.057928         0.095776           -0.605           0.545\n",
       "L13.IPCA           0.000072         0.012494            0.006           0.995\n",
       "L13.M1            -0.275732         0.223268           -1.235           0.217\n",
       "L14.Vendas        -0.018068         0.127154           -0.142           0.887\n",
       "L14.DOL            0.330711         0.116360            2.842           0.004\n",
       "L14.IBOV           0.094998         0.094662            1.004           0.316\n",
       "L14.IPCA          -0.013826         0.010573           -1.308           0.191\n",
       "L14.M1            -0.103894         0.210378           -0.494           0.621\n",
       "=============================================================================\n",
       "\n",
       "Results for equation IBOV\n",
       "=============================================================================\n",
       "                coefficient       std. error           t-stat            prob\n",
       "-----------------------------------------------------------------------------\n",
       "const              0.066511         0.787253            0.084           0.933\n",
       "L1.Vendas          0.058963         0.161653            0.365           0.715\n",
       "L1.DOL             0.154038         0.161853            0.952           0.341\n",
       "L1.IBOV            0.192535         0.117997            1.632           0.103\n",
       "L1.IPCA           -0.006083         0.014483           -0.420           0.674\n",
       "L1.M1             -0.358645         0.274071           -1.309           0.191\n",
       "L2.Vendas         -0.123604         0.197368           -0.626           0.531\n",
       "L2.DOL             0.099981         0.160196            0.624           0.533\n",
       "L2.IBOV           -0.078764         0.120246           -0.655           0.512\n",
       "L2.IPCA           -0.021935         0.016305           -1.345           0.179\n",
       "L2.M1              0.109508         0.286056            0.383           0.702\n",
       "L3.Vendas         -0.028625         0.198652           -0.144           0.885\n",
       "L3.DOL             0.094106         0.161499            0.583           0.560\n",
       "L3.IBOV            0.188126         0.123554            1.523           0.128\n",
       "L3.IPCA           -0.024913         0.018218           -1.367           0.171\n",
       "L3.M1              0.109023         0.286724            0.380           0.704\n",
       "L4.Vendas          0.008346         0.187312            0.045           0.964\n",
       "L4.DOL            -0.045848         0.163765           -0.280           0.780\n",
       "L4.IBOV           -0.028856         0.125735           -0.229           0.818\n",
       "L4.IPCA           -0.025532         0.019367           -1.318           0.187\n",
       "L4.M1              0.806383         0.285394            2.826           0.005\n",
       "L5.Vendas         -0.029864         0.188634           -0.158           0.874\n",
       "L5.DOL            -0.189939         0.167731           -1.132           0.257\n",
       "L5.IBOV           -0.234473         0.126289           -1.857           0.063\n",
       "L5.IPCA           -0.012115         0.020935           -0.579           0.563\n",
       "L5.M1              0.622138         0.277918            2.239           0.025\n",
       "L6.Vendas         -0.119277         0.191354           -0.623           0.533\n",
       "L6.DOL             0.074281         0.168608            0.441           0.660\n",
       "L6.IBOV           -0.004191         0.127426           -0.033           0.974\n",
       "L6.IPCA           -0.026895         0.022654           -1.187           0.235\n",
       "L6.M1              0.346333         0.284491            1.217           0.223\n",
       "L7.Vendas         -0.109787         0.192876           -0.569           0.569\n",
       "L7.DOL            -0.140009         0.170443           -0.821           0.411\n",
       "L7.IBOV           -0.126337         0.127045           -0.994           0.320\n",
       "L7.IPCA           -0.048293         0.022939           -2.105           0.035\n",
       "L7.M1              0.674498         0.291912            2.311           0.021\n",
       "L8.Vendas         -0.317308         0.193123           -1.643           0.100\n",
       "L8.DOL             0.051367         0.161809            0.317           0.751\n",
       "L8.IBOV            0.051742         0.126603            0.409           0.683\n",
       "L8.IPCA           -0.017640         0.023533           -0.750           0.453\n",
       "L8.M1              0.246743         0.300944            0.820           0.412\n",
       "L9.Vendas         -0.198662         0.197134           -1.008           0.314\n",
       "L9.DOL             0.111012         0.166421            0.667           0.505\n",
       "L9.IBOV           -0.194831         0.125258           -1.555           0.120\n",
       "L9.IPCA           -0.038531         0.024339           -1.583           0.113\n",
       "L9.M1              0.310269         0.298014            1.041           0.298\n",
       "L10.Vendas        -0.274617         0.197318           -1.392           0.164\n",
       "L10.DOL            0.187963         0.169106            1.112           0.266\n",
       "L10.IBOV           0.149475         0.129553            1.154           0.249\n",
       "L10.IPCA          -0.035435         0.022750           -1.558           0.119\n",
       "L10.M1            -0.260764         0.301736           -0.864           0.387\n",
       "L11.Vendas        -0.165521         0.196635           -0.842           0.400\n",
       "L11.DOL            0.024850         0.169737            0.146           0.884\n",
       "L11.IBOV           0.018896         0.132950            0.142           0.887\n",
       "L11.IPCA          -0.024871         0.021658           -1.148           0.251\n",
       "L11.M1            -0.147562         0.310954           -0.475           0.635\n",
       "L12.Vendas        -0.066118         0.200678           -0.329           0.742\n",
       "L12.DOL            0.204923         0.160753            1.275           0.202\n",
       "L12.IBOV           0.244558         0.130702            1.871           0.061\n",
       "L12.IPCA          -0.009029         0.020296           -0.445           0.656\n",
       "L12.M1            -0.468590         0.322801           -1.452           0.147\n",
       "L13.Vendas         0.078314         0.197659            0.396           0.692\n",
       "L13.DOL            0.274607         0.158505            1.732           0.083\n",
       "L13.IBOV          -0.003340         0.130275           -0.026           0.980\n",
       "L13.IPCA           0.004971         0.016995            0.292           0.770\n",
       "L13.M1             0.022489         0.303692            0.074           0.941\n",
       "L14.Vendas         0.295311         0.172956            1.707           0.088\n",
       "L14.DOL           -0.361774         0.158274           -2.286           0.022\n",
       "L14.IBOV          -0.220873         0.128761           -1.715           0.086\n",
       "L14.IPCA           0.013512         0.014382            0.940           0.347\n",
       "L14.M1            -0.006415         0.286159           -0.022           0.982\n",
       "=============================================================================\n",
       "\n",
       "Results for equation IPCA\n",
       "=============================================================================\n",
       "                coefficient       std. error           t-stat            prob\n",
       "-----------------------------------------------------------------------------\n",
       "const            -13.232618         5.238261           -2.526           0.012\n",
       "L1.Vendas         -0.935423         1.075617           -0.870           0.384\n",
       "L1.DOL             0.553385         1.076944            0.514           0.607\n",
       "L1.IBOV            0.195342         0.785132            0.249           0.804\n",
       "L1.IPCA           -0.437412         0.096369           -4.539           0.000\n",
       "L1.M1              1.762296         1.823628            0.966           0.334\n",
       "L2.Vendas          0.416182         1.313257            0.317           0.751\n",
       "L2.DOL             2.245928         1.065920            2.107           0.035\n",
       "L2.IBOV            1.529792         0.800097            1.912           0.056\n",
       "L2.IPCA           -0.565141         0.108491           -5.209           0.000\n",
       "L2.M1              1.942402         1.903374            1.021           0.307\n",
       "L3.Vendas         -1.109632         1.321803           -0.839           0.401\n",
       "L3.DOL            -1.050922         1.074590           -0.978           0.328\n",
       "L3.IBOV           -0.244199         0.822112           -0.297           0.766\n",
       "L3.IPCA           -0.356188         0.121222           -2.938           0.003\n",
       "L3.M1              1.440298         1.907815            0.755           0.450\n",
       "L4.Vendas          0.239575         1.246346            0.192           0.848\n",
       "L4.DOL             0.938969         1.089670            0.862           0.389\n",
       "L4.IBOV            0.273224         0.836624            0.327           0.744\n",
       "L4.IPCA           -0.426743         0.128863           -3.312           0.001\n",
       "L4.M1              1.016620         1.898967            0.535           0.592\n",
       "L5.Vendas          0.167793         1.255143            0.134           0.894\n",
       "L5.DOL             0.319161         1.116059            0.286           0.775\n",
       "L5.IBOV            0.566139         0.840308            0.674           0.500\n",
       "L5.IPCA           -0.481017         0.139296           -3.453           0.001\n",
       "L5.M1              0.978587         1.849223            0.529           0.597\n",
       "L6.Vendas          0.210990         1.273239            0.166           0.868\n",
       "L6.DOL            -0.148125         1.121889           -0.132           0.895\n",
       "L6.IBOV           -0.040494         0.847870           -0.048           0.962\n",
       "L6.IPCA           -0.418185         0.150736           -2.774           0.006\n",
       "L6.M1             -0.227308         1.892957           -0.120           0.904\n",
       "L7.Vendas          1.512362         1.283365            1.178           0.239\n",
       "L7.DOL             0.969777         1.134098            0.855           0.392\n",
       "L7.IBOV            0.363161         0.845338            0.430           0.667\n",
       "L7.IPCA           -0.433058         0.152635           -2.837           0.005\n",
       "L7.M1             -1.640310         1.942337           -0.845           0.398\n",
       "L8.Vendas          2.140173         1.285014            1.665           0.096\n",
       "L8.DOL             1.489845         1.076654            1.384           0.166\n",
       "L8.IBOV            0.747774         0.842397            0.888           0.375\n",
       "L8.IPCA           -0.531333         0.156583           -3.393           0.001\n",
       "L8.M1             -1.827872         2.002436           -0.913           0.361\n",
       "L9.Vendas          1.488067         1.311698            1.134           0.257\n",
       "L9.DOL             1.577620         1.107336            1.425           0.154\n",
       "L9.IBOV            0.703642         0.833446            0.844           0.399\n",
       "L9.IPCA           -0.284533         0.161948           -1.757           0.079\n",
       "L9.M1             -1.159795         1.982936           -0.585           0.559\n",
       "L10.Vendas         2.147494         1.312922            1.636           0.102\n",
       "L10.DOL            1.832692         1.125208            1.629           0.103\n",
       "L10.IBOV           0.886501         0.862023            1.028           0.304\n",
       "L10.IPCA          -0.170084         0.151372           -1.124           0.261\n",
       "L10.M1             2.997350         2.007705            1.493           0.135\n",
       "L11.Vendas         1.514255         1.308378            1.157           0.247\n",
       "L11.DOL            0.356803         1.129402            0.316           0.752\n",
       "L11.IBOV           0.680065         0.884631            0.769           0.442\n",
       "L11.IPCA           0.009769         0.144107            0.068           0.946\n",
       "L11.M1             1.677911         2.069040            0.811           0.417\n",
       "L12.Vendas         0.570738         1.335277            0.427           0.669\n",
       "L12.DOL            0.577145         1.069623            0.540           0.589\n",
       "L12.IBOV          -0.774330         0.869673           -0.890           0.373\n",
       "L12.IPCA          -0.130276         0.135047           -0.965           0.335\n",
       "L12.M1             3.908197         2.147868            1.820           0.069\n",
       "L13.Vendas         1.260154         1.315190            0.958           0.338\n",
       "L13.DOL           -0.960197         1.054667           -0.910           0.363\n",
       "L13.IBOV          -0.233873         0.866829           -0.270           0.787\n",
       "L13.IPCA          -0.113381         0.113080           -1.003           0.316\n",
       "L13.M1             2.165641         2.020718            1.072           0.284\n",
       "L14.Vendas        -0.859491         1.150822           -0.747           0.455\n",
       "L14.DOL            0.217796         1.053131            0.207           0.836\n",
       "L14.IBOV           0.089422         0.856755            0.104           0.917\n",
       "L14.IPCA          -0.161046         0.095694           -1.683           0.092\n",
       "L14.M1             2.868936         1.904056            1.507           0.132\n",
       "=============================================================================\n",
       "\n",
       "Results for equation M1\n",
       "=============================================================================\n",
       "                coefficient       std. error           t-stat            prob\n",
       "-----------------------------------------------------------------------------\n",
       "const              0.180624         0.275824            0.655           0.513\n",
       "L1.Vendas          0.137031         0.056637            2.419           0.016\n",
       "L1.DOL            -0.031342         0.056707           -0.553           0.580\n",
       "L1.IBOV            0.003729         0.041342            0.090           0.928\n",
       "L1.IPCA           -0.012877         0.005074           -2.538           0.011\n",
       "L1.M1             -0.320488         0.096024           -3.338           0.001\n",
       "L2.Vendas          0.210914         0.069150            3.050           0.002\n",
       "L2.DOL            -0.093904         0.056127           -1.673           0.094\n",
       "L2.IBOV            0.034443         0.042130            0.818           0.414\n",
       "L2.IPCA           -0.007076         0.005713           -1.239           0.215\n",
       "L2.M1             -0.228332         0.100223           -2.278           0.023\n",
       "L3.Vendas          0.051023         0.069600            0.733           0.464\n",
       "L3.DOL             0.126952         0.056583            2.244           0.025\n",
       "L3.IBOV            0.120625         0.043289            2.787           0.005\n",
       "L3.IPCA           -0.016061         0.006383           -2.516           0.012\n",
       "L3.M1             -0.040576         0.100457           -0.404           0.686\n",
       "L4.Vendas          0.161141         0.065627            2.455           0.014\n",
       "L4.DOL             0.014547         0.057377            0.254           0.800\n",
       "L4.IBOV            0.032034         0.044053            0.727           0.467\n",
       "L4.IPCA           -0.000315         0.006785           -0.046           0.963\n",
       "L4.M1              0.077240         0.099991            0.772           0.440\n",
       "L5.Vendas          0.138465         0.066090            2.095           0.036\n",
       "L5.DOL            -0.029645         0.058767           -0.504           0.614\n",
       "L5.IBOV            0.006285         0.044247            0.142           0.887\n",
       "L5.IPCA           -0.012013         0.007335           -1.638           0.101\n",
       "L5.M1              0.112510         0.097372            1.155           0.248\n",
       "L6.Vendas          0.057312         0.067043            0.855           0.393\n",
       "L6.DOL            -0.038985         0.059074           -0.660           0.509\n",
       "L6.IBOV            0.007684         0.044645            0.172           0.863\n",
       "L6.IPCA           -0.015971         0.007937           -2.012           0.044\n",
       "L6.M1              0.196242         0.099675            1.969           0.049\n",
       "L7.Vendas          0.069988         0.067576            1.036           0.300\n",
       "L7.DOL             0.023189         0.059717            0.388           0.698\n",
       "L7.IBOV           -0.002297         0.044512           -0.052           0.959\n",
       "L7.IPCA           -0.007743         0.008037           -0.963           0.335\n",
       "L7.M1              0.040278         0.102275            0.394           0.694\n",
       "L8.Vendas          0.034824         0.067663            0.515           0.607\n",
       "L8.DOL             0.011271         0.056692            0.199           0.842\n",
       "L8.IBOV            0.002122         0.044357            0.048           0.962\n",
       "L8.IPCA           -0.003149         0.008245           -0.382           0.703\n",
       "L8.M1             -0.119718         0.105439           -1.135           0.256\n",
       "L9.Vendas          0.088808         0.069068            1.286           0.199\n",
       "L9.DOL             0.044906         0.058307            0.770           0.441\n",
       "L9.IBOV            0.017857         0.043886            0.407           0.684\n",
       "L9.IPCA           -0.004327         0.008527           -0.507           0.612\n",
       "L9.M1             -0.122533         0.104413           -1.174           0.241\n",
       "L10.Vendas        -0.048160         0.069133           -0.697           0.486\n",
       "L10.DOL            0.029115         0.059249            0.491           0.623\n",
       "L10.IBOV          -0.013290         0.045390           -0.293           0.770\n",
       "L10.IPCA           0.003565         0.007971            0.447           0.655\n",
       "L10.M1            -0.365269         0.105717           -3.455           0.001\n",
       "L11.Vendas         0.069864         0.068893            1.014           0.311\n",
       "L11.DOL            0.048923         0.059469            0.823           0.411\n",
       "L11.IBOV           0.038884         0.046581            0.835           0.404\n",
       "L11.IPCA           0.003109         0.007588            0.410           0.682\n",
       "L11.M1            -0.207130         0.108947           -1.901           0.057\n",
       "L12.Vendas         0.080264         0.070310            1.142           0.254\n",
       "L12.DOL            0.019781         0.056322            0.351           0.725\n",
       "L12.IBOV           0.060632         0.045793            1.324           0.185\n",
       "L12.IPCA           0.007009         0.007111            0.986           0.324\n",
       "L12.M1             0.301632         0.113097            2.667           0.008\n",
       "L13.Vendas         0.112070         0.069252            1.618           0.106\n",
       "L13.DOL            0.034005         0.055534            0.612           0.540\n",
       "L13.IBOV          -0.007963         0.045643           -0.174           0.862\n",
       "L13.IPCA           0.006205         0.005954            1.042           0.297\n",
       "L13.M1             0.115788         0.106402            1.088           0.277\n",
       "L14.Vendas        -0.005797         0.060597           -0.096           0.924\n",
       "L14.DOL           -0.072111         0.055453           -1.300           0.193\n",
       "L14.IBOV          -0.039012         0.045113           -0.865           0.387\n",
       "L14.IPCA           0.002511         0.005039            0.498           0.618\n",
       "L14.M1             0.032667         0.100259            0.326           0.745\n",
       "=============================================================================\n",
       "\n",
       "Correlation matrix of residuals\n",
       "            Vendas       DOL      IBOV      IPCA        M1\n",
       "Vendas    1.000000 -0.127851  0.001426 -0.035387  0.012031\n",
       "DOL      -0.127851  1.000000 -0.603339  0.075693  0.115891\n",
       "IBOV      0.001426 -0.603339  1.000000 -0.007785 -0.047684\n",
       "IPCA     -0.035387  0.075693 -0.007785  1.000000  0.018244\n",
       "M1        0.012031  0.115891 -0.047684  0.018244  1.000000\n",
       "\n"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "irf = model_fit.irf(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "irf.plot(orth=True, response='Vendas')\n",
    "plt.savefig('Impulso_resposta.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
